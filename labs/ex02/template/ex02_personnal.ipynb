{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# Useful starting lines\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "from helpers import *\n",
    "\n",
    "height, weight, gender = load_data(sub_sample=False, add_outlier=False)\n",
    "x, mean_x, std_x = standardize(height)\n",
    "y, tx = build_model_data(x, weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10000,), (10000, 2))"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape, tx.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NB: throughout this laboratory the data has the following format: \n",
    "  * there are **N = 10000** data entries\n",
    "  * **y** represents the column vector containing weight information -- that which we wish to predict/the output (see also the first page of $\\texttt{exercise02.pdf}$). Its **shape** is **(N,)**.\n",
    "  * **tx** represents the matrix $\\tilde{X}$ formed by laterally concatenating a column vector of 1s to the column vector of height information -- the input data (see also the first page of $\\texttt{exercise02.pdf}$). Its **shape** is **(N,2)**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Computing the Cost Function\n",
    "Fill in the `compute_loss` function below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_loss(y, tx, w, MSE = True):\n",
    "    \"\"\"Calculate the loss using either MSE or MAE.\n",
    "\n",
    "    Args:\n",
    "        y: numpy array of shape=(N, )\n",
    "        tx: numpy array of shape=(N,2)\n",
    "        w: numpy array of shape=(2,). The vector of model parameters.\n",
    "\n",
    "    Returns:\n",
    "        the value of the loss (a scalar), corresponding to the input parameters w.\n",
    "    \"\"\"\n",
    "    e = y - tx @ w\n",
    "    if MSE:\n",
    "        loss = 1/(2*len(y)) *np.linalg.norm(e)**2\n",
    "    else:\n",
    "        loss = 1/(2*len(y)) * sum(abs(e))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35.6469610010525"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = [2,1]\n",
    "loss = compute_loss(y, tx, w, MSE=False)\n",
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Grid Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fill in the function `grid_search()` below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from costs import *\n",
    "\n",
    "\n",
    "def grid_search(y, tx, grid_w0, grid_w1):\n",
    "    \"\"\"Algorithm for grid search.\n",
    "\n",
    "    Args:\n",
    "        y: numpy array of shape=(N, )\n",
    "        tx: numpy array of shape=(N,2)\n",
    "        grid_w0: numpy array of shape=(num_grid_pts_w0, ). A 1D array containing num_grid_pts_w0 values of parameter w0 to be tested in the grid search.\n",
    "        grid_w1: numpy array of shape=(num_grid_pts_w1, ). A 1D array containing num_grid_pts_w1 values of parameter w1 to be tested in the grid search.\n",
    "\n",
    "    Returns:\n",
    "        losses: numpy array of shape=(num_grid_pts_w0, num_grid_pts_w1). A 2D array containing the loss value for each combination of w0 and w1\n",
    "    \"\"\"\n",
    "\n",
    "    losses = np.zeros((len(grid_w0), len(grid_w1)))\n",
    "    for i in range(len(grid_w0)):\n",
    "        for j in range(len(grid_w1)):\n",
    "            w = [grid_w0[i], grid_w1[j]]\n",
    "            losses[i][j] = compute_loss(y, tx,w,)\n",
    "    return losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us play with the grid search demo now!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid Search: loss*=15.765788547059048, w0*=72.88135593220338, w1*=12.711864406779654, execution time=0.145 seconds\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from grid_search import generate_w, get_best_parameters\n",
    "from plots import grid_visualization\n",
    "\n",
    "# Generate the grid of parameters to be swept\n",
    "grid_w0, grid_w1 = generate_w(num_intervals=60)\n",
    "\n",
    "# Start the grid search\n",
    "start_time = datetime.datetime.now()\n",
    "grid_losses = grid_search(y, tx, grid_w0, grid_w1)\n",
    "\n",
    "# Select the best combinaison\n",
    "loss_star, w0_star, w1_star = get_best_parameters(grid_w0, grid_w1, grid_losses)\n",
    "end_time = datetime.datetime.now()\n",
    "execution_time = (end_time - start_time).total_seconds()\n",
    "\n",
    "# Print the results\n",
    "print(\n",
    "    \"Grid Search: loss*={l}, w0*={w0}, w1*={w1}, execution time={t:.3f} seconds\".format(\n",
    "        l=loss_star, w0=w0_star, w1=w1_star, t=execution_time\n",
    "    )\n",
    ")\n",
    "\n",
    "# Plot the results\n",
    "fig = grid_visualization(grid_losses, grid_w0, grid_w1, mean_x, std_x, height, weight)\n",
    "fig.set_size_inches(10.0, 6.0)\n",
    "fig.savefig(\"grid_plot\")  # Optional saving"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, please fill in the functions `compute_gradient` below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_gradient(y, tx, w):\n",
    "    \"\"\"Computes the gradient at w.\n",
    "\n",
    "    Args:\n",
    "        y: numpy array of shape=(N, )\n",
    "        tx: numpy array of shape=(N,2)\n",
    "        w: numpy array of shape=(2, ). The vector of model parameters.\n",
    "\n",
    "    Returns:\n",
    "        An numpy array of shape (2, ) (same shape as w), containing the gradient of the loss at w.\n",
    "    \"\"\"\n",
    "    return -1/len(y) * (tx.T @ (y - tx @ w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The gradient using w0 is: [26.706  6.52 ] and using w1 is: [-23.294  -3.48 ]\n"
     ]
    }
   ],
   "source": [
    "w0 = [100,20]\n",
    "w1 = [50,10]\n",
    "result_w0 = compute_gradient(y,tx,w0)\n",
    "result_w1 = compute_gradient(y,tx,w1)\n",
    "np.set_printoptions(precision=3)\n",
    "print(f'The gradient using w0 is: {result_w0} and using w1 is: {result_w1}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please fill in the functions `gradient_descent` below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(y, tx, initial_w, max_iters, gamma):\n",
    "    \"\"\"The Gradient Descent (GD) algorithm.\n",
    "\n",
    "    Args:\n",
    "        y: numpy array of shape=(N, )\n",
    "        tx: numpy array of shape=(N,2)\n",
    "        initial_w: numpy array of shape=(2, ). The initial guess (or the initialization) for the model parameters\n",
    "        max_iters: a scalar denoting the total number of iterations of GD\n",
    "        gamma: a scalar denoting the stepsize\n",
    "\n",
    "    Returns:\n",
    "        losses: a list of length max_iters containing the loss value (scalar) for each iteration of GD\n",
    "        ws: a list of length max_iters containing the model parameters as numpy arrays of shape (2, ), for each iteration of GD\n",
    "    \"\"\"\n",
    "    # Define parameters to store w and loss\n",
    "    ws = [initial_w]\n",
    "    losses = []\n",
    "    w = initial_w\n",
    "    for n_iter in range(max_iters):\n",
    "        loss = compute_loss(y,tx,w)\n",
    "        w = w - gamma * compute_gradient(y,tx,w)\n",
    "        # store w and loss\n",
    "        ws.append(w)\n",
    "        losses.append(loss)\n",
    "        print(\n",
    "            \"GD iter. {bi}/{ti}: loss={l}, w0={w0}, w1={w1}\".format(\n",
    "                bi=n_iter, ti=max_iters - 1, l=loss, w0=w[0], w1=w[1]\n",
    "            )\n",
    "        )\n",
    "\n",
    "    return losses, ws"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test your gradient descent function through gradient descent demo shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GD iter. 0/49: loss=1062606.4462798766, w0=-34.03547019810537, w1=112.13174119148891\n",
      "GD iter. 1/49: loss=10641.29649178879, w0=62.56098278208415, w1=23.344915310638783\n",
      "GD iter. 2/49: loss=121.64499390802628, w0=72.2206280801031, w1=14.466232722553986\n",
      "GD iter. 3/49: loss=16.448478929221324, w0=73.18659260990498, w1=13.578364463745542\n",
      "GD iter. 4/49: loss=15.39651377943332, w0=73.28318906288517, w1=13.489577637864699\n",
      "GD iter. 5/49: loss=15.385994127935446, w0=73.29284870818319, w1=13.480698955276614\n",
      "GD iter. 6/49: loss=15.385888931420459, w0=73.29381467271298, w1=13.479811087017804\n",
      "GD iter. 7/49: loss=15.38588787945531, w0=73.29391126916597, w1=13.479722300191924\n",
      "GD iter. 8/49: loss=15.385887868935662, w0=73.29392092881127, w1=13.479713421509336\n",
      "GD iter. 9/49: loss=15.385887868830464, w0=73.29392189477579, w1=13.479712533641077\n",
      "GD iter. 10/49: loss=15.385887868829416, w0=73.29392199137226, w1=13.479712444854252\n",
      "GD iter. 11/49: loss=15.385887868829403, w0=73.29392200103189, w1=13.47971243597557\n",
      "GD iter. 12/49: loss=15.385887868829398, w0=73.29392200199786, w1=13.4797124350877\n",
      "GD iter. 13/49: loss=15.385887868829398, w0=73.29392200209445, w1=13.479712434998914\n",
      "GD iter. 14/49: loss=15.385887868829398, w0=73.29392200210411, w1=13.479712434990036\n",
      "GD iter. 15/49: loss=15.385887868829403, w0=73.29392200210508, w1=13.479712434989148\n",
      "GD iter. 16/49: loss=15.385887868829403, w0=73.29392200210518, w1=13.47971243498906\n",
      "GD iter. 17/49: loss=15.385887868829398, w0=73.29392200210519, w1=13.47971243498905\n",
      "GD iter. 18/49: loss=15.385887868829398, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 19/49: loss=15.385887868829398, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 20/49: loss=15.385887868829398, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 21/49: loss=15.385887868829398, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 22/49: loss=15.385887868829398, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 23/49: loss=15.385887868829398, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 24/49: loss=15.385887868829398, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 25/49: loss=15.385887868829398, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 26/49: loss=15.385887868829398, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 27/49: loss=15.385887868829398, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 28/49: loss=15.385887868829398, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 29/49: loss=15.385887868829398, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 30/49: loss=15.385887868829398, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 31/49: loss=15.385887868829398, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 32/49: loss=15.385887868829398, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 33/49: loss=15.385887868829398, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 34/49: loss=15.385887868829398, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 35/49: loss=15.385887868829398, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 36/49: loss=15.385887868829398, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 37/49: loss=15.385887868829398, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 38/49: loss=15.385887868829398, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 39/49: loss=15.385887868829398, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 40/49: loss=15.385887868829398, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 41/49: loss=15.385887868829398, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 42/49: loss=15.385887868829398, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 43/49: loss=15.385887868829398, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 44/49: loss=15.385887868829398, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 45/49: loss=15.385887868829398, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 46/49: loss=15.385887868829398, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 47/49: loss=15.385887868829398, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 48/49: loss=15.385887868829398, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 49/49: loss=15.385887868829398, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD: execution time=0.028 seconds\n"
     ]
    }
   ],
   "source": [
    "# from gradient_descent import *\n",
    "from plots import gradient_descent_visualization\n",
    "\n",
    "# Define the parameters of the algorithm.\n",
    "max_iters = 50\n",
    "gamma = 0.9\n",
    "\n",
    "# Initialization\n",
    "w_initial = np.array([-1000,1000])\n",
    "\n",
    "# Start gradient descent.\n",
    "start_time = datetime.datetime.now()\n",
    "gd_losses, gd_ws = gradient_descent(y, tx, w_initial, max_iters, gamma)\n",
    "end_time = datetime.datetime.now()\n",
    "\n",
    "# Print result\n",
    "exection_time = (end_time - start_time).total_seconds()\n",
    "print(\"GD: execution time={t:.3f} seconds\".format(t=exection_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b98368bc1194ab4808fb1900ef334e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=1, description='n_iter', max=51, min=1), Output()), _dom_classes=('widge…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.plot_figure(n_iter)>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Time Visualization\n",
    "from ipywidgets import IntSlider, interact\n",
    "\n",
    "\n",
    "def plot_figure(n_iter):\n",
    "    fig = gradient_descent_visualization(\n",
    "        gd_losses,\n",
    "        gd_ws,\n",
    "        grid_losses,\n",
    "        grid_w0,\n",
    "        grid_w1,\n",
    "        mean_x,\n",
    "        std_x,\n",
    "        height,\n",
    "        weight,\n",
    "        n_iter,\n",
    "    )\n",
    "    fig.set_size_inches(10.0, 6.0)\n",
    "\n",
    "\n",
    "interact(plot_figure, n_iter=IntSlider(min=1, max=len(gd_ws)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 4. Stochastic gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_stoch_gradient(y, tx, w):\n",
    "    \"\"\"Compute a stochastic gradient at w from a data sample batch of size B, where B < N, and their corresponding labels.\n",
    "\n",
    "    Args:\n",
    "        y: numpy array of shape=(B, )\n",
    "        tx: numpy array of shape=(B,2)\n",
    "        w: numpy array of shape=(2, ). The vector of model parameters.\n",
    "\n",
    "    Returns:\n",
    "        A numpy array of shape (2, ) (same shape as w), containing the stochastic gradient of the loss at w.\n",
    "    \"\"\"\n",
    "\n",
    "    # ***************************************************\n",
    "    # INSERT YOUR CODE HERE\n",
    "    # TODO: implement stochastic gradient computation. It's the same as the usual gradient.\n",
    "    return -1/len(y) * (tx.T @ (y - tx @ w))\n",
    "    # ***************************************************\n",
    "\n",
    "\n",
    "def stochastic_gradient_descent(y, tx, initial_w, batch_size, max_iters, gamma):\n",
    "    \"\"\"The Stochastic Gradient Descent algorithm (SGD).\n",
    "\n",
    "    Args:\n",
    "        y: numpy array of shape=(N, )\n",
    "        tx: numpy array of shape=(N,2)\n",
    "        initial_w: numpy array of shape=(2, ). The initial guess (or the initialization) for the model parameters\n",
    "        batch_size: a scalar denoting the number of data points in a mini-batch used for computing the stochastic gradient\n",
    "        max_iters: a scalar denoting the total number of iterations of SGD\n",
    "        gamma: a scalar denoting the stepsize\n",
    "\n",
    "    Returns:\n",
    "        losses: a list of length max_iters containing the loss value (scalar) for each iteration of SGD\n",
    "        ws: a list of length max_iters containing the model parameters as numpy arrays of shape (2, ), for each iteration of SGD\n",
    "    \"\"\"\n",
    "\n",
    "    # Define parameters to store w and loss\n",
    "    ws = [initial_w]\n",
    "    losses = []\n",
    "    w = initial_w\n",
    "\n",
    "    for n_iter in range(max_iters):\n",
    "        # ***************************************************\n",
    "        # INSERT YOUR CODE HERE\n",
    "        # TODO: implement stochastic gradient descent.\n",
    "        for y_batched, tx_batched in batch_iter(y=y,tx=tx,batch_size=batch_size):\n",
    "            loss = compute_loss(y_batched,tx_batched,w)\n",
    "            w = w - gamma * compute_stoch_gradient(y_batched,tx_batched,w)\n",
    "        # ***************************************************\n",
    "        # store w and loss\n",
    "        ws.append(w)\n",
    "        losses.append(loss)\n",
    "        print(\n",
    "            \"SGD iter. {bi}/{ti}: loss={l}, w0={w0}, w1={w1}\".format(\n",
    "                bi=n_iter, ti=max_iters - 1, l=loss, w0=w[0], w1=w[1]\n",
    "            )\n",
    "        )\n",
    "    return losses, ws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD iter. 0/49: loss=3011.934585584498, w0=7.761358883062293, w1=2.1531092371991565\n",
      "SGD iter. 1/49: loss=3488.8521105855875, w0=16.11462424528513, w1=13.100548327874042\n",
      "SGD iter. 2/49: loss=1201.3413662480536, w0=21.016341018514797, w1=20.600287119106653\n",
      "SGD iter. 3/49: loss=1632.0395079228306, w0=26.729552913627444, w1=24.826644705258243\n",
      "SGD iter. 4/49: loss=1510.9091171996988, w0=32.226659638441326, w1=25.284124204133924\n",
      "SGD iter. 5/49: loss=204.08625234451057, w0=34.2469875937224, w1=27.77490367249612\n",
      "SGD iter. 6/49: loss=148.8665359214803, w0=35.972481934028856, w1=29.19515761685512\n",
      "SGD iter. 7/49: loss=230.43180150087818, w0=38.119255333812255, w1=29.516036803934988\n",
      "SGD iter. 8/49: loss=78.11628594190076, w0=39.369185619403424, w1=31.592931310759525\n",
      "SGD iter. 9/49: loss=27.20578082612258, w0=38.63154368965536, w1=29.62772211155841\n",
      "SGD iter. 10/49: loss=1181.5035898631752, w0=43.49262091566849, w1=25.3273522224004\n",
      "SGD iter. 11/49: loss=55.889260940346276, w0=44.54987453652156, w1=27.08346961855854\n",
      "SGD iter. 12/49: loss=101.74691472245777, w0=45.97638717034194, w1=27.65096442354215\n",
      "SGD iter. 13/49: loss=467.9195421390846, w0=49.035535882448244, w1=25.890483345117886\n",
      "SGD iter. 14/49: loss=1049.4647814880643, w0=53.616943485986845, w1=22.021209381587617\n",
      "SGD iter. 15/49: loss=1.284465301377375, w0=53.77722232435158, w1=22.289917612552404\n",
      "SGD iter. 16/49: loss=148.86133668572825, w0=55.502686532532834, w1=21.408523911907515\n",
      "SGD iter. 17/49: loss=90.11108886309873, w0=56.84515507118168, w1=21.39114544662708\n",
      "SGD iter. 18/49: loss=135.01233179674472, w0=58.48839779090841, w1=20.80337322202089\n",
      "SGD iter. 19/49: loss=55.98282611400532, w0=59.54653602492139, w1=21.535763114824576\n",
      "SGD iter. 20/49: loss=114.71942531197628, w0=61.061259929215346, w1=21.22540208657096\n",
      "SGD iter. 21/49: loss=454.97676269694756, w0=64.07780352312194, w1=16.123178908993996\n",
      "SGD iter. 22/49: loss=56.86252435626115, w0=65.14422299365182, w1=17.553269198297304\n",
      "SGD iter. 23/49: loss=107.10002336348991, w0=66.60778046340482, w1=15.479526604623715\n",
      "SGD iter. 24/49: loss=15.56783231740976, w0=67.16577387407219, w1=16.374930969503612\n",
      "SGD iter. 25/49: loss=21.864781980315495, w0=67.82705720185712, w1=15.722320394866802\n",
      "SGD iter. 26/49: loss=0.1447603124666132, w0=67.77325008105204, w1=15.666994490348339\n",
      "SGD iter. 27/49: loss=98.8208781079681, w0=69.17910126882383, w1=15.937216607479005\n",
      "SGD iter. 28/49: loss=0.06901413160177379, w0=69.21625342397041, w1=15.909164785102378\n",
      "SGD iter. 29/49: loss=1.3305050347671288, w0=69.37937945100272, w1=15.971578492149924\n",
      "SGD iter. 30/49: loss=12.201439367053842, w0=69.8733721506867, w1=16.421143636103217\n",
      "SGD iter. 31/49: loss=23.096046582213976, w0=70.55301980325697, w1=15.351942119255845\n",
      "SGD iter. 32/49: loss=91.74679598478357, w0=71.90761786899296, w1=12.993058955773233\n",
      "SGD iter. 33/49: loss=6.311397056188224, w0=72.2629035865834, w1=13.249345547384193\n",
      "SGD iter. 34/49: loss=7.323701987929252, w0=71.88018431641454, w1=13.428171416560165\n",
      "SGD iter. 35/49: loss=3.30753410741821, w0=71.62298656730238, w1=13.715147298875364\n",
      "SGD iter. 36/49: loss=2.337658572321157, w0=71.83921138420928, w1=14.0025134440219\n",
      "SGD iter. 37/49: loss=5.643100731929672, w0=72.17516080694817, w1=13.182379324278404\n",
      "SGD iter. 38/49: loss=0.7200735180513048, w0=72.05515468060028, w1=13.224969763770714\n",
      "SGD iter. 39/49: loss=0.14237137978925674, w0=72.001793387552, w1=13.263243669134466\n",
      "SGD iter. 40/49: loss=5.545606529834072, w0=72.3348281163667, w1=13.276317106455318\n",
      "SGD iter. 41/49: loss=0.2886626850898491, w0=72.41081004646719, w1=13.267756418009519\n",
      "SGD iter. 42/49: loss=7.510000043929004, w0=72.02325359783218, w1=13.311505536359117\n",
      "SGD iter. 43/49: loss=6.728703239074886, w0=71.65641021874309, w1=13.073842802254006\n",
      "SGD iter. 44/49: loss=2.635713228136735, w0=71.8860060910116, w1=13.252389080307333\n",
      "SGD iter. 45/49: loss=1.483129452073101, w0=72.05823439600663, w1=13.036232113979324\n",
      "SGD iter. 46/49: loss=0.3054053917456493, w0=72.13638878062395, w1=12.845438282843487\n",
      "SGD iter. 47/49: loss=33.204960450633735, w0=71.32146595666288, w1=12.789759500327072\n",
      "SGD iter. 48/49: loss=11.672314074906465, w0=71.80462874651546, w1=13.170540656673632\n",
      "SGD iter. 49/49: loss=47.0332160578451, w0=70.83475023806355, w1=13.418660724270815\n",
      "SGD: execution time=0.035 seconds\n"
     ]
    }
   ],
   "source": [
    "# from stochastic_gradient_descent import *\n",
    "\n",
    "# Define the parameters of the algorithm.\n",
    "max_iters = 50\n",
    "gamma = 0.1\n",
    "batch_size = 1\n",
    "\n",
    "# Initialization\n",
    "w_initial = np.array([0, 0])\n",
    "\n",
    "# Start SGD.\n",
    "start_time = datetime.datetime.now()\n",
    "sgd_losses, sgd_ws = stochastic_gradient_descent(\n",
    "    y, tx, w_initial, batch_size, max_iters, gamma\n",
    ")\n",
    "end_time = datetime.datetime.now()\n",
    "\n",
    "# Print result\n",
    "exection_time = (end_time - start_time).total_seconds()\n",
    "print(\"SGD: execution time={t:.3f} seconds\".format(t=exection_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3b550fccdee4fd4a6aac424bcb9cb4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=1, description='n_iter', max=51, min=1), Output()), _dom_classes=('widge…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.plot_figure(n_iter)>"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Time Visualization\n",
    "from ipywidgets import IntSlider, interact\n",
    "\n",
    "\n",
    "def plot_figure(n_iter):\n",
    "    fig = gradient_descent_visualization(\n",
    "        sgd_losses,\n",
    "        sgd_ws,\n",
    "        grid_losses,\n",
    "        grid_w0,\n",
    "        grid_w1,\n",
    "        mean_x,\n",
    "        std_x,\n",
    "        height,\n",
    "        weight,\n",
    "        n_iter,\n",
    "    )\n",
    "    fig.set_size_inches(10.0, 6.0)\n",
    "\n",
    "\n",
    "interact(plot_figure, n_iter=IntSlider(min=1, max=len(sgd_ws)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Effect of Outliers and MAE Cost Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "from helpers import *\n",
    "\n",
    "# ***************************************************\n",
    "# INSERT YOUR CODE HERE\n",
    "# TODO: reload the data by subsampling first, then by subsampling and adding outliers\n",
    "height, weight, gender = load_data(sub_sample=True, add_outlier=True)\n",
    "\n",
    "# ***************************************************\n",
    "\n",
    "x, mean_x, std_x = standardize(height)\n",
    "y, tx = build_model_data(x, weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((202,), (202, 2))"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape, tx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GD iter. 0/49: loss=2869.8351145358533, w0=51.847464098448484, w1=7.724426406192441\n",
      "GD iter. 1/49: loss=318.282124701595, w0=67.401703327983, w1=10.041754328050121\n",
      "GD iter. 2/49: loss=88.64235561651259, w0=72.06797509684336, w1=10.736952704607413\n",
      "GD iter. 3/49: loss=67.9747763988552, w0=73.46785662750146, w1=10.945512217574594\n",
      "GD iter. 4/49: loss=66.11469426926604, w0=73.88782108669889, w1=11.00808007146475\n",
      "GD iter. 5/49: loss=65.947286877603, w0=74.01381042445813, w1=11.026850427631796\n",
      "GD iter. 6/49: loss=65.93222021235334, w0=74.05160722578589, w1=11.03248153448191\n",
      "GD iter. 7/49: loss=65.93086421248087, w0=74.06294626618423, w1=11.034170866536943\n",
      "GD iter. 8/49: loss=65.93074217249236, w0=74.06634797830372, w1=11.034677666153454\n",
      "GD iter. 9/49: loss=65.93073118889338, w0=74.06736849193958, w1=11.034829706038407\n",
      "GD iter. 10/49: loss=65.93073020036948, w0=74.06767464603033, w1=11.034875318003893\n",
      "GD iter. 11/49: loss=65.93073011140233, w0=74.06776649225756, w1=11.034889001593537\n",
      "GD iter. 12/49: loss=65.93073010339529, w0=74.06779404612573, w1=11.034893106670431\n",
      "GD iter. 13/49: loss=65.93073010267466, w0=74.06780231228618, w1=11.034894338193501\n",
      "GD iter. 14/49: loss=65.93073010260979, w0=74.06780479213431, w1=11.034894707650421\n",
      "GD iter. 15/49: loss=65.93073010260396, w0=74.06780553608876, w1=11.034894818487498\n",
      "GD iter. 16/49: loss=65.93073010260342, w0=74.06780575927509, w1=11.03489485173862\n",
      "GD iter. 17/49: loss=65.93073010260338, w0=74.06780582623098, w1=11.034894861713957\n",
      "GD iter. 18/49: loss=65.93073010260338, w0=74.06780584631775, w1=11.034894864706558\n",
      "GD iter. 19/49: loss=65.93073010260338, w0=74.06780585234378, w1=11.034894865604338\n",
      "GD iter. 20/49: loss=65.93073010260338, w0=74.06780585415159, w1=11.034894865873671\n",
      "GD iter. 21/49: loss=65.9307301026034, w0=74.06780585469393, w1=11.03489486595447\n",
      "GD iter. 22/49: loss=65.93073010260338, w0=74.06780585485663, w1=11.034894865978712\n",
      "GD iter. 23/49: loss=65.93073010260338, w0=74.06780585490544, w1=11.034894865985985\n",
      "GD iter. 24/49: loss=65.93073010260338, w0=74.0678058549201, w1=11.034894865988164\n",
      "GD iter. 25/49: loss=65.93073010260338, w0=74.06780585492449, w1=11.034894865988818\n",
      "GD iter. 26/49: loss=65.93073010260338, w0=74.06780585492581, w1=11.034894865989017\n",
      "GD iter. 27/49: loss=65.93073010260338, w0=74.06780585492619, w1=11.034894865989077\n",
      "GD iter. 28/49: loss=65.93073010260338, w0=74.06780585492632, w1=11.034894865989095\n",
      "GD iter. 29/49: loss=65.93073010260336, w0=74.06780585492635, w1=11.034894865989099\n",
      "GD iter. 30/49: loss=65.93073010260338, w0=74.06780585492636, w1=11.034894865989102\n",
      "GD iter. 31/49: loss=65.93073010260338, w0=74.06780585492636, w1=11.0348948659891\n",
      "GD iter. 32/49: loss=65.93073010260338, w0=74.06780585492636, w1=11.0348948659891\n",
      "GD iter. 33/49: loss=65.93073010260338, w0=74.06780585492636, w1=11.0348948659891\n",
      "GD iter. 34/49: loss=65.93073010260338, w0=74.06780585492636, w1=11.0348948659891\n",
      "GD iter. 35/49: loss=65.93073010260338, w0=74.06780585492636, w1=11.0348948659891\n",
      "GD iter. 36/49: loss=65.93073010260338, w0=74.06780585492636, w1=11.0348948659891\n",
      "GD iter. 37/49: loss=65.93073010260338, w0=74.06780585492636, w1=11.0348948659891\n",
      "GD iter. 38/49: loss=65.93073010260338, w0=74.06780585492636, w1=11.0348948659891\n",
      "GD iter. 39/49: loss=65.93073010260338, w0=74.06780585492636, w1=11.0348948659891\n",
      "GD iter. 40/49: loss=65.93073010260338, w0=74.06780585492636, w1=11.0348948659891\n",
      "GD iter. 41/49: loss=65.93073010260338, w0=74.06780585492636, w1=11.0348948659891\n",
      "GD iter. 42/49: loss=65.93073010260338, w0=74.06780585492636, w1=11.0348948659891\n",
      "GD iter. 43/49: loss=65.93073010260338, w0=74.06780585492636, w1=11.0348948659891\n",
      "GD iter. 44/49: loss=65.93073010260338, w0=74.06780585492636, w1=11.0348948659891\n",
      "GD iter. 45/49: loss=65.93073010260338, w0=74.06780585492636, w1=11.0348948659891\n",
      "GD iter. 46/49: loss=65.93073010260338, w0=74.06780585492636, w1=11.0348948659891\n",
      "GD iter. 47/49: loss=65.93073010260338, w0=74.06780585492636, w1=11.0348948659891\n",
      "GD iter. 48/49: loss=65.93073010260338, w0=74.06780585492636, w1=11.0348948659891\n",
      "GD iter. 49/49: loss=65.93073010260338, w0=74.06780585492636, w1=11.0348948659891\n",
      "GD: execution time=0.003 seconds\n"
     ]
    }
   ],
   "source": [
    "from plots import gradient_descent_visualization\n",
    "\n",
    "# Define the parameters of the algorithm.\n",
    "max_iters = 50\n",
    "gamma = 0.7\n",
    "\n",
    "# Initialization\n",
    "w_initial = np.array([0, 0])\n",
    "\n",
    "# Start gradient descent.\n",
    "start_time = datetime.datetime.now()\n",
    "\n",
    "# ***************************************************\n",
    "# INSERT YOUR CODE HERE\n",
    "# TODO: fit the model to the subsampled data / subsampled data with outliers and visualize the cloud of points\n",
    "#       and the model fit\n",
    "gd_losses, gd_ws = gradient_descent(y, tx, w_initial, max_iters, gamma)\n",
    "# ***************************************************\n",
    "\n",
    "\n",
    "end_time = datetime.datetime.now()\n",
    "\n",
    "# Print result\n",
    "exection_time = (end_time - start_time).total_seconds()\n",
    "print(\"GD: execution time={t:.3f} seconds\".format(t=exection_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "341b623fc711417aa7018f5ca02122fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=1, description='n_iter', max=51, min=1), Output()), _dom_classes=('widge…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.plot_figure(n_iter)>"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Time Visualization\n",
    "from ipywidgets import IntSlider, interact\n",
    "\n",
    "\n",
    "def plot_figure(n_iter):\n",
    "    fig = gradient_descent_visualization(\n",
    "        gd_losses,\n",
    "        gd_ws,\n",
    "        grid_losses,\n",
    "        grid_w0,\n",
    "        grid_w1,\n",
    "        mean_x,\n",
    "        std_x,\n",
    "        height,\n",
    "        weight,\n",
    "        n_iter,\n",
    "    )\n",
    "    fig.set_size_inches(10.0, 6.0)\n",
    "\n",
    "\n",
    "interact(plot_figure, n_iter=IntSlider(min=1, max=len(gd_ws)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 6. Subgradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_subgradient_mae(y, tx, w):\n",
    "    \"\"\"Compute a subgradient of the MAE at w.\n",
    "\n",
    "    Args:\n",
    "        y: numpy array of shape=(N, )\n",
    "        tx: numpy array of shape=(N,2)\n",
    "        w: numpy array of shape=(2, ). The vector of model parameters.\n",
    "\n",
    "    Returns:\n",
    "        A numpy array of shape (2, ) (same shape as w), containing the subgradient of the MAE at w.\n",
    "    \"\"\"\n",
    "    e = y - (tx @ w)\n",
    "    subgradient = (-tx.T @ np.sign(e))/len(y)\n",
    "    return subgradient\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subgradient_descent(y, tx, initial_w, max_iters, gamma):\n",
    "    \"\"\"The SubGradient Descent (SubGD) algorithm.\n",
    "\n",
    "    Args:\n",
    "        y: numpy array of shape=(N, )\n",
    "        tx: numpy array of shape=(N,2)\n",
    "        initial_w: numpy array of shape=(2, ). The initial guess (or the initialization) for the model parameters\n",
    "        max_iters: a scalar denoting the total number of iterations of GD\n",
    "        gamma: a scalar denoting the stepsize\n",
    "\n",
    "    Returns:\n",
    "        losses: a list of length max_iters containing the loss value (scalar) for each iteration of SubGD\n",
    "        ws: a list of length max_iters containing the model parameters as numpy arrays of shape (2, ), for each iteration of SubGD\n",
    "    \"\"\"\n",
    "    # Define parameters to store w and loss\n",
    "    ws = [initial_w]\n",
    "    losses = []\n",
    "    w = initial_w\n",
    "    for n_iter in range(max_iters):\n",
    "        w = w - gamma * compute_subgradient_mae(y,tx,w)\n",
    "        loss = compute_loss(y,tx,w,MSE=False)\n",
    "        ws.append(w)\n",
    "        losses.append(loss)\n",
    "        print(\n",
    "            \"SubGD iter. {bi}/{ti}: loss={l}, w0={w0}, w1={w1}\".format(\n",
    "                bi=n_iter, ti=max_iters - 1, l=loss, w0=w[0], w1=w[1]\n",
    "            )\n",
    "        )\n",
    "\n",
    "    return losses, ws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SubGD iter. 0/499: loss=36.6839029274632, w0=0.7, w1=8.756471895211877e-16\n",
      "SubGD iter. 1/499: loss=36.33390292746317, w0=1.4, w1=1.7512943790423754e-15\n",
      "SubGD iter. 2/499: loss=35.983902927463205, w0=2.0999999999999996, w1=2.626941568563563e-15\n",
      "SubGD iter. 3/499: loss=35.63390292746321, w0=2.8, w1=3.502588758084751e-15\n",
      "SubGD iter. 4/499: loss=35.28390292746316, w0=3.5, w1=4.378235947605939e-15\n",
      "SubGD iter. 5/499: loss=34.933902927463194, w0=4.2, w1=5.253883137127127e-15\n",
      "SubGD iter. 6/499: loss=34.58390292746317, w0=4.9, w1=6.1295303266483146e-15\n",
      "SubGD iter. 7/499: loss=34.233902927463205, w0=5.6000000000000005, w1=7.0051775161695025e-15\n",
      "SubGD iter. 8/499: loss=33.88390292746321, w0=6.300000000000001, w1=7.88082470569069e-15\n",
      "SubGD iter. 9/499: loss=33.53390292746315, w0=7.000000000000001, w1=8.756471895211878e-15\n",
      "SubGD iter. 10/499: loss=33.183902927463194, w0=7.700000000000001, w1=9.632119084733065e-15\n",
      "SubGD iter. 11/499: loss=32.83390292746318, w0=8.4, w1=1.0507766274254253e-14\n",
      "SubGD iter. 12/499: loss=32.483902927463205, w0=9.1, w1=1.1383413463775441e-14\n",
      "SubGD iter. 13/499: loss=32.133902927463204, w0=9.799999999999999, w1=1.2259060653296629e-14\n",
      "SubGD iter. 14/499: loss=31.78390292746316, w0=10.499999999999998, w1=1.3134707842817817e-14\n",
      "SubGD iter. 15/499: loss=31.433902927463198, w0=11.199999999999998, w1=1.4010355032339005e-14\n",
      "SubGD iter. 16/499: loss=31.083902927463182, w0=11.899999999999997, w1=1.488600222186019e-14\n",
      "SubGD iter. 17/499: loss=30.73390292746321, w0=12.599999999999996, w1=1.576164941138138e-14\n",
      "SubGD iter. 18/499: loss=30.3839029274632, w0=13.299999999999995, w1=1.6637296600902567e-14\n",
      "SubGD iter. 19/499: loss=30.033902927463156, w0=13.999999999999995, w1=1.7512943790423755e-14\n",
      "SubGD iter. 20/499: loss=29.683902927463212, w0=14.699999999999994, w1=1.8388590979944943e-14\n",
      "SubGD iter. 21/499: loss=29.33390292746319, w0=15.399999999999993, w1=1.926423816946613e-14\n",
      "SubGD iter. 22/499: loss=28.983902927463205, w0=16.099999999999994, w1=2.013988535898732e-14\n",
      "SubGD iter. 23/499: loss=28.6339029274632, w0=16.799999999999994, w1=2.1015532548508507e-14\n",
      "SubGD iter. 24/499: loss=28.28390292746316, w0=17.499999999999993, w1=2.1891179738029695e-14\n",
      "SubGD iter. 25/499: loss=27.933902927463212, w0=18.199999999999992, w1=2.2766826927550882e-14\n",
      "SubGD iter. 26/499: loss=27.58390292746319, w0=18.89999999999999, w1=2.364247411707207e-14\n",
      "SubGD iter. 27/499: loss=27.233902927463213, w0=19.59999999999999, w1=2.4518121306593258e-14\n",
      "SubGD iter. 28/499: loss=26.8839029274632, w0=20.29999999999999, w1=2.5393768496114446e-14\n",
      "SubGD iter. 29/499: loss=26.533902927463174, w0=20.99999999999999, w1=2.6269415685635634e-14\n",
      "SubGD iter. 30/499: loss=26.18390292746322, w0=21.69999999999999, w1=2.7145062875156822e-14\n",
      "SubGD iter. 31/499: loss=25.833902927463193, w0=22.399999999999988, w1=2.802071006467801e-14\n",
      "SubGD iter. 32/499: loss=25.483902927463205, w0=23.099999999999987, w1=2.8896357254199195e-14\n",
      "SubGD iter. 33/499: loss=25.1339029274632, w0=23.799999999999986, w1=2.977200444372038e-14\n",
      "SubGD iter. 34/499: loss=24.78390292746319, w0=24.499999999999986, w1=3.064765163324157e-14\n",
      "SubGD iter. 35/499: loss=24.433902927463215, w0=25.199999999999985, w1=3.152329882276276e-14\n",
      "SubGD iter. 36/499: loss=24.083902927463193, w0=25.899999999999984, w1=3.2398946012283946e-14\n",
      "SubGD iter. 37/499: loss=23.733902927463195, w0=26.599999999999984, w1=3.3274593201805134e-14\n",
      "SubGD iter. 38/499: loss=23.383902927463204, w0=27.299999999999983, w1=3.415024039132632e-14\n",
      "SubGD iter. 39/499: loss=23.033902927463192, w0=27.999999999999982, w1=3.502588758084751e-14\n",
      "SubGD iter. 40/499: loss=22.68390292746321, w0=28.69999999999998, w1=3.59015347703687e-14\n",
      "SubGD iter. 41/499: loss=22.333902927463203, w0=29.39999999999998, w1=3.6777181959889886e-14\n",
      "SubGD iter. 42/499: loss=21.983902927463195, w0=30.09999999999998, w1=3.7652829149411074e-14\n",
      "SubGD iter. 43/499: loss=21.633902927463204, w0=30.79999999999998, w1=3.852847633893226e-14\n",
      "SubGD iter. 44/499: loss=21.28390292746319, w0=31.49999999999998, w1=3.940412352845345e-14\n",
      "SubGD iter. 45/499: loss=20.933902927463198, w0=32.19999999999998, w1=4.027977071797464e-14\n",
      "SubGD iter. 46/499: loss=20.583902927463193, w0=32.899999999999984, w1=4.1155417907495825e-14\n",
      "SubGD iter. 47/499: loss=20.2339029274632, w0=33.59999999999999, w1=4.2031065097017013e-14\n",
      "SubGD iter. 48/499: loss=19.88390292746319, w0=34.29999999999999, w1=4.29067122865382e-14\n",
      "SubGD iter. 49/499: loss=19.533902927463195, w0=34.99999999999999, w1=4.378235947605939e-14\n",
      "SubGD iter. 50/499: loss=19.183902927463187, w0=35.699999999999996, w1=4.465800666558058e-14\n",
      "SubGD iter. 51/499: loss=18.83390292746319, w0=36.4, w1=4.5533653855101765e-14\n",
      "SubGD iter. 52/499: loss=18.483902927463184, w0=37.1, w1=4.640930104462295e-14\n",
      "SubGD iter. 53/499: loss=18.133902927463183, w0=37.800000000000004, w1=4.728494823414414e-14\n",
      "SubGD iter. 54/499: loss=17.78390292746319, w0=38.50000000000001, w1=4.816059542366533e-14\n",
      "SubGD iter. 55/499: loss=17.433902927463183, w0=39.20000000000001, w1=4.9036242613186517e-14\n",
      "SubGD iter. 56/499: loss=17.083902927463182, w0=39.90000000000001, w1=4.9911889802707705e-14\n",
      "SubGD iter. 57/499: loss=16.73390292746318, w0=40.600000000000016, w1=5.078753699222889e-14\n",
      "SubGD iter. 58/499: loss=16.38390292746318, w0=41.30000000000002, w1=5.166318418175008e-14\n",
      "SubGD iter. 59/499: loss=16.03390292746318, w0=42.00000000000002, w1=5.253883137127127e-14\n",
      "SubGD iter. 60/499: loss=15.683902927463174, w0=42.700000000000024, w1=5.3414478560792456e-14\n",
      "SubGD iter. 61/499: loss=15.33390292746318, w0=43.40000000000003, w1=5.4290125750313644e-14\n",
      "SubGD iter. 62/499: loss=14.983902927463175, w0=44.10000000000003, w1=5.516577293983483e-14\n",
      "SubGD iter. 63/499: loss=14.633902927463177, w0=44.80000000000003, w1=5.604142012935602e-14\n",
      "SubGD iter. 64/499: loss=14.283902927463178, w0=45.500000000000036, w1=5.691706731887721e-14\n",
      "SubGD iter. 65/499: loss=13.933902927463167, w0=46.20000000000004, w1=5.779271450839839e-14\n",
      "SubGD iter. 66/499: loss=13.586635104834459, w0=46.90000000000004, w1=5.866836169791957e-14\n",
      "SubGD iter. 67/499: loss=13.245225781875607, w0=47.59306930693074, w1=0.01114784567828894\n",
      "SubGD iter. 68/499: loss=12.908606161385098, w0=48.279207920792125, w1=0.03308574108991741\n",
      "SubGD iter. 69/499: loss=12.577519717328222, w0=48.96534653465351, w1=0.055023636501545875\n",
      "SubGD iter. 70/499: loss=12.262051706947382, w0=49.63069306930698, w1=0.1053832638830964\n",
      "SubGD iter. 71/499: loss=11.949647673017784, w0=50.28910891089114, w1=0.16746568532795278\n",
      "SubGD iter. 72/499: loss=11.642196462828569, w0=50.947524752475296, w1=0.22954810677280915\n",
      "SubGD iter. 73/499: loss=11.343438222090922, w0=51.59207920792084, w1=0.312425129327494\n",
      "SubGD iter. 74/499: loss=11.053133784820279, w0=52.22277227722777, w1=0.41195013288401805\n",
      "SubGD iter. 75/499: loss=10.76890941400422, w0=52.84653465346539, w1=0.5208167847923948\n",
      "SubGD iter. 76/499: loss=10.493169937314228, w0=53.4564356435644, w1=0.6457900912636185\n",
      "SubGD iter. 77/499: loss=10.222780468310223, w0=54.0594059405941, w1=0.7796904498577408\n",
      "SubGD iter. 78/499: loss=9.955955079478917, w0=54.655445544554496, w1=0.9197570104995888\n",
      "SubGD iter. 79/499: loss=9.694822045281622, w0=55.24455445544559, w1=1.067092029785011\n",
      "SubGD iter. 80/499: loss=9.443994532197943, w0=55.819801980198065, w1=1.2261255948210965\n",
      "SubGD iter. 81/499: loss=9.207980250927127, w0=56.36732673267331, w1=1.410709342622233\n",
      "SubGD iter. 82/499: loss=8.977449271520188, w0=56.900990099009945, w1=1.605853732220289\n",
      "SubGD iter. 83/499: loss=8.75287882828991, w0=57.42772277227727, w1=1.808762802293982\n",
      "SubGD iter. 84/499: loss=8.537478713465806, w0=57.933663366336674, w1=2.0285064197514897\n",
      "SubGD iter. 85/499: loss=8.32648364875495, w0=58.43267326732677, w1=2.2494370848672975\n",
      "SubGD iter. 86/499: loss=8.124270365748359, w0=58.91089108910895, w1=2.4837982986028537\n",
      "SubGD iter. 87/499: loss=7.924552606327075, w0=59.382178217821824, w1=2.7260245553531703\n",
      "SubGD iter. 88/499: loss=7.733459895615649, w0=59.83960396039608, w1=2.978742333469156\n",
      "SubGD iter. 89/499: loss=7.554147310756099, w0=60.262376237623805, w1=3.251528669355458\n",
      "SubGD iter. 90/499: loss=7.377448172961413, w0=60.67821782178222, w1=3.5270865794243\n",
      "SubGD iter. 91/499: loss=7.202264480810142, w0=61.087128712871326, w1=3.806459183951836\n",
      "SubGD iter. 92/499: loss=7.027893514063638, w0=61.49603960396043, w1=4.085831788479371\n",
      "SubGD iter. 93/499: loss=6.857310455802809, w0=61.891089108910926, w1=4.373839384328629\n",
      "SubGD iter. 94/499: loss=6.690618153642077, w0=62.27920792079211, w1=4.666037469532069\n",
      "SubGD iter. 95/499: loss=6.529410807583118, w0=62.65346534653469, w1=4.959829093241791\n",
      "SubGD iter. 96/499: loss=6.370125862169614, w0=63.02079207920796, w1=5.257057192056662\n",
      "SubGD iter. 97/499: loss=6.211609444378057, w0=63.38118811881192, w1=5.5604343163524295\n",
      "SubGD iter. 98/499: loss=6.053780865950577, w0=63.74158415841588, w1=5.863811440648197\n",
      "SubGD iter. 99/499: loss=5.900311048699066, w0=64.08811881188123, w1=6.172402175278572\n",
      "SubGD iter. 100/499: loss=5.747520897323205, w0=64.42772277227726, w1=6.4863693105165225\n",
      "SubGD iter. 101/499: loss=5.594730745947353, w0=64.7673267326733, w1=6.800336445754473\n",
      "SubGD iter. 102/499: loss=5.441940594571494, w0=65.10693069306933, w1=7.1143035809924235\n",
      "SubGD iter. 103/499: loss=5.292296704156596, w0=65.44653465346536, w1=7.428270716230374\n",
      "SubGD iter. 104/499: loss=5.147908267159466, w0=65.76534653465349, w1=7.747893210218651\n",
      "SubGD iter. 105/499: loss=5.005676040610676, w0=66.070297029703, w1=8.073669686866932\n",
      "SubGD iter. 106/499: loss=4.864042163334058, w0=66.37524752475251, w1=8.399446163515213\n",
      "SubGD iter. 107/499: loss=4.724062730561248, w0=66.6663366336634, w1=8.73297028041742\n",
      "SubGD iter. 108/499: loss=4.585520552048326, w0=66.9574257425743, w1=9.066494397319628\n",
      "SubGD iter. 109/499: loss=4.451828065579475, w0=67.23465346534658, w1=9.398630319470323\n",
      "SubGD iter. 110/499: loss=4.318135579110621, w0=67.51188118811886, w1=9.730766241621017\n",
      "SubGD iter. 111/499: loss=4.18807596015118, w0=67.78910891089114, w1=10.062902163771712\n",
      "SubGD iter. 112/499: loss=4.070270419375745, w0=68.06633663366343, w1=10.363999289979459\n",
      "SubGD iter. 113/499: loss=3.9592722507986293, w0=68.32970297029709, w1=10.66046690927365\n",
      "SubGD iter. 114/499: loss=3.852639864188492, w0=68.59306930693076, w1=10.943174379960851\n",
      "SubGD iter. 115/499: loss=3.7468479155893117, w0=68.85643564356442, w1=11.225881850648053\n",
      "SubGD iter. 116/499: loss=3.6449962028716993, w0=69.11287128712878, w1=11.504395843582245\n",
      "SubGD iter. 117/499: loss=3.548617017890767, w0=69.35544554455453, w1=11.78820189306779\n",
      "SubGD iter. 118/499: loss=3.4599526473344535, w0=69.58415841584166, w1=12.06091146519101\n",
      "SubGD iter. 119/499: loss=3.375286763657721, w0=69.80594059405948, w1=12.324245668386087\n",
      "SubGD iter. 120/499: loss=3.2923724054028254, w0=70.0277227722773, w1=12.587579871581164\n",
      "SubGD iter. 121/499: loss=3.2151716381738966, w0=70.25643564356443, w1=12.824765405096523\n",
      "SubGD iter. 122/499: loss=3.1390357409451686, w0=70.47821782178225, w1=13.065616959310187\n",
      "SubGD iter. 123/499: loss=3.0668316646316547, w0=70.69306930693077, w1=13.302953389983951\n",
      "SubGD iter. 124/499: loss=3.002920399171509, w0=70.89405940594067, w1=13.525403099312957\n",
      "SubGD iter. 125/499: loss=2.942510912611603, w0=71.08811881188126, w1=13.742945617944251\n",
      "SubGD iter. 126/499: loss=2.8858176261348234, w0=71.27524752475254, w1=13.953548196006883\n",
      "SubGD iter. 127/499: loss=2.8335810308951257, w0=71.46237623762383, w1=14.164150774069515\n",
      "SubGD iter. 128/499: loss=2.793363382996567, w0=71.62178217821788, w1=14.349779559473214\n",
      "SubGD iter. 129/499: loss=2.76192390608019, w0=71.75346534653471, w1=14.516890107612351\n",
      "SubGD iter. 130/499: loss=2.740046854295932, w0=71.87128712871292, w1=14.670791185324227\n",
      "SubGD iter. 131/499: loss=2.726544001751007, w0=71.95445544554461, w1=14.780276456654562\n",
      "SubGD iter. 132/499: loss=2.7136963154314486, w0=72.0376237623763, w1=14.889761727984897\n",
      "SubGD iter. 133/499: loss=2.7036612228413737, w0=72.10693069306937, w1=14.985916181776767\n",
      "SubGD iter. 134/499: loss=2.6936261302512974, w0=72.17623762376245, w1=15.082070635568638\n",
      "SubGD iter. 135/499: loss=2.685230390169346, w0=72.24554455445552, w1=15.178225089360508\n",
      "SubGD iter. 136/499: loss=2.6787032616673674, w0=72.30099009900998, w1=15.25972348971595\n",
      "SubGD iter. 137/499: loss=2.672964632011289, w0=72.34950495049513, w1=15.335091856448178\n",
      "SubGD iter. 138/499: loss=2.667857329758735, w0=72.39801980198028, w1=15.410460223180406\n",
      "SubGD iter. 139/499: loss=2.665021955232679, w0=72.43267326732682, w1=15.469961786755766\n",
      "SubGD iter. 140/499: loss=2.6628382141366127, w0=72.46039603960405, w1=15.51864528583285\n",
      "SubGD iter. 141/499: loss=2.6610883632632945, w0=72.48811881188128, w1=15.561592159086528\n",
      "SubGD iter. 142/499: loss=2.660055654821555, w0=72.5019801980199, w1=15.597828332032567\n",
      "SubGD iter. 143/499: loss=2.659239142449219, w0=72.52277227722782, w1=15.624722856626754\n",
      "SubGD iter. 144/499: loss=2.6586200242825733, w0=72.55049504950505, w1=15.642690329098041\n",
      "SubGD iter. 145/499: loss=2.6582032739757726, w0=72.56435643564366, w1=15.664356578291132\n",
      "SubGD iter. 146/499: loss=2.6577785613330693, w0=72.58514851485158, w1=15.677095775361325\n",
      "SubGD iter. 147/499: loss=2.657353848690369, w0=72.6059405940595, w1=15.689834972431518\n",
      "SubGD iter. 148/499: loss=2.6569384404610816, w0=72.62673267326743, w1=15.70257416950171\n",
      "SubGD iter. 149/499: loss=2.656526123435691, w0=72.64059405940604, w1=15.724240418694801\n",
      "SubGD iter. 150/499: loss=2.6561889195121915, w0=72.66138613861396, w1=15.736979615764994\n",
      "SubGD iter. 151/499: loss=2.656066114862521, w0=72.66831683168327, w1=15.74811029423132\n",
      "SubGD iter. 152/499: loss=2.6559433102128485, w0=72.67524752475258, w1=15.759240972697647\n",
      "SubGD iter. 153/499: loss=2.655841783049218, w0=72.68217821782189, w1=15.770371651163973\n",
      "SubGD iter. 154/499: loss=2.65583062564566, w0=72.68217821782189, w1=15.774323911906727\n",
      "SubGD iter. 155/499: loss=2.655819468242105, w0=72.68217821782189, w1=15.77827617264948\n",
      "SubGD iter. 156/499: loss=2.6558083108385477, w0=72.68217821782189, w1=15.782228433392234\n",
      "SubGD iter. 157/499: loss=2.655797153434994, w0=72.68217821782189, w1=15.786180694134988\n",
      "SubGD iter. 158/499: loss=2.655785996031434, w0=72.68217821782189, w1=15.790132954877741\n",
      "SubGD iter. 159/499: loss=2.65577483862788, w0=72.68217821782189, w1=15.794085215620495\n",
      "SubGD iter. 160/499: loss=2.655763681224322, w0=72.68217821782189, w1=15.798037476363248\n",
      "SubGD iter. 161/499: loss=2.655752523820768, w0=72.68217821782189, w1=15.801989737106002\n",
      "SubGD iter. 162/499: loss=2.65574136641721, w0=72.68217821782189, w1=15.805941997848755\n",
      "SubGD iter. 163/499: loss=2.6557302090136568, w0=72.68217821782189, w1=15.809894258591509\n",
      "SubGD iter. 164/499: loss=2.655719051610098, w0=72.68217821782189, w1=15.813846519334263\n",
      "SubGD iter. 165/499: loss=2.655707894206543, w0=72.68217821782189, w1=15.817798780077016\n",
      "SubGD iter. 166/499: loss=2.6556967368029856, w0=72.68217821782189, w1=15.82175104081977\n",
      "SubGD iter. 167/499: loss=2.6556855793994303, w0=72.68217821782189, w1=15.825703301562523\n",
      "SubGD iter. 168/499: loss=2.6556744219958737, w0=72.68217821782189, w1=15.829655562305277\n",
      "SubGD iter. 169/499: loss=2.6556632645923184, w0=72.68217821782189, w1=15.83360782304803\n",
      "SubGD iter. 170/499: loss=2.6556521071887618, w0=72.68217821782189, w1=15.837560083790784\n",
      "SubGD iter. 171/499: loss=2.655640949785204, w0=72.68217821782189, w1=15.841512344533538\n",
      "SubGD iter. 172/499: loss=2.655629792381649, w0=72.68217821782189, w1=15.845464605276291\n",
      "SubGD iter. 173/499: loss=2.655618634978094, w0=72.68217821782189, w1=15.849416866019045\n",
      "SubGD iter. 174/499: loss=2.6556074775745357, w0=72.68217821782189, w1=15.853369126761798\n",
      "SubGD iter. 175/499: loss=2.6555963201709805, w0=72.68217821782189, w1=15.857321387504552\n",
      "SubGD iter. 176/499: loss=2.655585162767426, w0=72.68217821782189, w1=15.861273648247305\n",
      "SubGD iter. 177/499: loss=2.655574005363867, w0=72.68217821782189, w1=15.865225908990059\n",
      "SubGD iter. 178/499: loss=2.655562847960312, w0=72.68217821782189, w1=15.869178169732812\n",
      "SubGD iter. 179/499: loss=2.6555516905567558, w0=72.68217821782189, w1=15.873130430475566\n",
      "SubGD iter. 180/499: loss=2.655540533153201, w0=72.68217821782189, w1=15.87708269121832\n",
      "SubGD iter. 181/499: loss=2.6555293757496425, w0=72.68217821782189, w1=15.881034951961073\n",
      "SubGD iter. 182/499: loss=2.6555182183460846, w0=72.68217821782189, w1=15.884987212703827\n",
      "SubGD iter. 183/499: loss=2.65550706094253, w0=72.68217821782189, w1=15.88893947344658\n",
      "SubGD iter. 184/499: loss=2.655495903538975, w0=72.68217821782189, w1=15.892891734189334\n",
      "SubGD iter. 185/499: loss=2.655484746135418, w0=72.68217821782189, w1=15.896843994932087\n",
      "SubGD iter. 186/499: loss=2.655473588731861, w0=72.68217821782189, w1=15.900796255674841\n",
      "SubGD iter. 187/499: loss=2.6554624313283046, w0=72.68217821782189, w1=15.904748516417595\n",
      "SubGD iter. 188/499: loss=2.6554512739247493, w0=72.68217821782189, w1=15.908700777160348\n",
      "SubGD iter. 189/499: loss=2.65545685303069, w0=72.68217821782189, w1=15.912653037903102\n",
      "SubGD iter. 190/499: loss=2.6554461185931344, w0=72.67524752475258, w1=15.910526938117364\n",
      "SubGD iter. 191/499: loss=2.6554349611895796, w0=72.67524752475258, w1=15.914479198860118\n",
      "SubGD iter. 192/499: loss=2.6554313180269173, w0=72.67524752475258, w1=15.918431459602871\n",
      "SubGD iter. 193/499: loss=2.6554298058579633, w0=72.66831683168327, w1=15.916305359817134\n",
      "SubGD iter. 194/499: loss=2.6554186484544084, w0=72.66831683168327, w1=15.920257620559887\n",
      "SubGD iter. 195/499: loss=2.65540749105085, w0=72.66831683168327, w1=15.924209881302641\n",
      "SubGD iter. 196/499: loss=2.6554117850950854, w0=72.66831683168327, w1=15.928162142045394\n",
      "SubGD iter. 197/499: loss=2.6554023357192387, w0=72.66138613861396, w1=15.926036042259657\n",
      "SubGD iter. 198/499: loss=2.6553911783156807, w0=72.66138613861396, w1=15.92998830300241\n",
      "SubGD iter. 199/499: loss=2.655386250091312, w0=72.66138613861396, w1=15.933940563745164\n",
      "SubGD iter. 200/499: loss=2.6553860229840676, w0=72.65445544554466, w1=15.931814463959427\n",
      "SubGD iter. 201/499: loss=2.6553748655805087, w0=72.65445544554466, w1=15.93576672470218\n",
      "SubGD iter. 202/499: loss=2.6553637081769543, w0=72.65445544554466, w1=15.939718985444934\n",
      "SubGD iter. 203/499: loss=2.6553667171594806, w0=72.65445544554466, w1=15.943671246187687\n",
      "SubGD iter. 204/499: loss=2.6553585528453385, w0=72.64752475247535, w1=15.94154514640195\n",
      "SubGD iter. 205/499: loss=2.6553473954417823, w0=72.64752475247535, w1=15.945497407144703\n",
      "SubGD iter. 206/499: loss=2.6553411821557047, w0=72.64752475247535, w1=15.949449667887457\n",
      "SubGD iter. 207/499: loss=2.6553422401101687, w0=72.64059405940604, w1=15.94732356810172\n",
      "SubGD iter. 208/499: loss=2.655331082706613, w0=72.64059405940604, w1=15.951275828844473\n",
      "SubGD iter. 209/499: loss=2.655319925303056, w0=72.64059405940604, w1=15.955228089587226\n",
      "SubGD iter. 210/499: loss=2.6553216492238745, w0=72.64059405940604, w1=15.95918035032998\n",
      "SubGD iter. 211/499: loss=2.655314769971441, w0=72.63366336633673, w1=15.957054250544243\n",
      "SubGD iter. 212/499: loss=2.655303612567885, w0=72.63366336633673, w1=15.961006511286996\n",
      "SubGD iter. 213/499: loss=2.6552961142201, w0=72.63366336633673, w1=15.96495877202975\n",
      "SubGD iter. 214/499: loss=2.6553165915495143, w0=72.62673267326743, w1=15.962832672244012\n",
      "SubGD iter. 215/499: loss=2.6552996717925312, w0=72.63366336633673, w1=15.967301372051416\n",
      "SubGD iter. 216/499: loss=2.655309114137895, w0=72.62673267326743, w1=15.965175272265679\n",
      "SubGD iter. 217/499: loss=2.655303229364963, w0=72.63366336633673, w1=15.969643972073083\n",
      "SubGD iter. 218/499: loss=2.6553016367262767, w0=72.62673267326743, w1=15.967517872287345\n",
      "SubGD iter. 219/499: loss=2.655306786937395, w0=72.63366336633673, w1=15.97198657209475\n",
      "SubGD iter. 220/499: loss=2.6552941593146593, w0=72.62673267326743, w1=15.969860472309012\n",
      "SubGD iter. 221/499: loss=2.6553103445098247, w0=72.63366336633673, w1=15.974329172116416\n",
      "SubGD iter. 222/499: loss=2.6552874830749427, w0=72.62673267326743, w1=15.972203072330679\n",
      "SubGD iter. 223/499: loss=2.6552918198248636, w0=72.62673267326743, w1=15.970593411609592\n",
      "SubGD iter. 224/499: loss=2.6553114575827483, w0=72.63366336633673, w1=15.975062111416996\n",
      "SubGD iter. 225/499: loss=2.6552883257775157, w0=72.62673267326743, w1=15.972936011631258\n",
      "SubGD iter. 226/499: loss=2.655289480335071, w0=72.62673267326743, w1=15.971326350910171\n",
      "SubGD iter. 227/499: loss=2.6553125706556675, w0=72.63366336633673, w1=15.975795050717576\n",
      "SubGD iter. 228/499: loss=2.6552891684800897, w0=72.62673267326743, w1=15.973668950931838\n",
      "SubGD iter. 229/499: loss=2.6552873177603495, w0=72.62673267326743, w1=15.972059290210751\n",
      "SubGD iter. 230/499: loss=2.6552922787671025, w0=72.62673267326743, w1=15.970449629489664\n",
      "SubGD iter. 231/499: loss=2.65531123922908, w0=72.63366336633673, w1=15.974918329297068\n",
      "SubGD iter. 232/499: loss=2.6552881604629244, w0=72.62673267326743, w1=15.972792229511331\n",
      "SubGD iter. 233/499: loss=2.6552899392773064, w0=72.62673267326743, w1=15.971182568790244\n",
      "SubGD iter. 234/499: loss=2.6553123523020004, w0=72.63366336633673, w1=15.975651268597648\n",
      "SubGD iter. 235/499: loss=2.655289003165498, w0=72.62673267326743, w1=15.97352516881191\n",
      "SubGD iter. 236/499: loss=2.6552875997875143, w0=72.62673267326743, w1=15.971915508090824\n",
      "SubGD iter. 237/499: loss=2.6553134653749226, w0=72.63366336633673, w1=15.976384207898228\n",
      "SubGD iter. 238/499: loss=2.6552898458680687, w0=72.62673267326743, w1=15.97425810811249\n",
      "SubGD iter. 239/499: loss=2.655287995148331, w0=72.62673267326743, w1=15.972648447391403\n",
      "SubGD iter. 240/499: loss=2.6552903982195453, w0=72.62673267326743, w1=15.971038786670317\n",
      "SubGD iter. 241/499: loss=2.655312133948333, w0=72.63366336633673, w1=15.97550748647772\n",
      "SubGD iter. 242/499: loss=2.655288837850902, w0=72.62673267326743, w1=15.973381386691983\n",
      "SubGD iter. 243/499: loss=2.65528805872975, w0=72.62673267326743, w1=15.971771725970896\n",
      "SubGD iter. 244/499: loss=2.6553132470212564, w0=72.63366336633673, w1=15.9762404257783\n",
      "SubGD iter. 245/499: loss=2.6552896805534765, w0=72.62673267326743, w1=15.974114325992563\n",
      "SubGD iter. 246/499: loss=2.655287829833737, w0=72.62673267326743, w1=15.972504665271476\n",
      "SubGD iter. 247/499: loss=2.6552908571617815, w0=72.62673267326743, w1=15.970895004550389\n",
      "SubGD iter. 248/499: loss=2.6553119155946665, w0=72.63366336633673, w1=15.975363704357793\n",
      "SubGD iter. 249/499: loss=2.655288672536309, w0=72.62673267326743, w1=15.973237604572056\n",
      "SubGD iter. 250/499: loss=2.655288517671988, w0=72.62673267326743, w1=15.971627943850969\n",
      "SubGD iter. 251/499: loss=2.655313028667588, w0=72.63366336633673, w1=15.976096643658373\n",
      "SubGD iter. 252/499: loss=2.655289515238884, w0=72.62673267326743, w1=15.973970543872635\n",
      "SubGD iter. 253/499: loss=2.655287664519143, w0=72.62673267326743, w1=15.972360883151548\n",
      "SubGD iter. 254/499: loss=2.655291316104018, w0=72.62673267326743, w1=15.970751222430462\n",
      "SubGD iter. 255/499: loss=2.6553116972410007, w0=72.63366336633673, w1=15.975219922237866\n",
      "SubGD iter. 256/499: loss=2.655288507221716, w0=72.62673267326743, w1=15.973093822452128\n",
      "SubGD iter. 257/499: loss=2.6552889766142243, w0=72.62673267326743, w1=15.971484161731041\n",
      "SubGD iter. 258/499: loss=2.6553128103139194, w0=72.63366336633673, w1=15.975952861538445\n",
      "SubGD iter. 259/499: loss=2.6552893499242893, w0=72.62673267326743, w1=15.973826761752708\n",
      "SubGD iter. 260/499: loss=2.6552874992045497, w0=72.62673267326743, w1=15.972217101031621\n",
      "SubGD iter. 261/499: loss=2.655291775046256, w0=72.62673267326743, w1=15.970607440310534\n",
      "SubGD iter. 262/499: loss=2.6553114788873318, w0=72.63366336633673, w1=15.975076140117938\n",
      "SubGD iter. 263/499: loss=2.655288341907124, w0=72.62673267326743, w1=15.9729500403322\n",
      "SubGD iter. 264/499: loss=2.6552894355564596, w0=72.62673267326743, w1=15.971340379611114\n",
      "SubGD iter. 265/499: loss=2.655312591960252, w0=72.63366336633673, w1=15.975809079418518\n",
      "SubGD iter. 266/499: loss=2.655289184609696, w0=72.62673267326743, w1=15.97368297963278\n",
      "SubGD iter. 267/499: loss=2.6552873338899556, w0=72.62673267326743, w1=15.972073318911693\n",
      "SubGD iter. 268/499: loss=2.6552922339884923, w0=72.62673267326743, w1=15.970463658190607\n",
      "SubGD iter. 269/499: loss=2.6553112605336664, w0=72.63366336633673, w1=15.97493235799801\n",
      "SubGD iter. 270/499: loss=2.65528817659253, w0=72.62673267326743, w1=15.972806258212273\n",
      "SubGD iter. 271/499: loss=2.6552898944986993, w0=72.62673267326743, w1=15.971196597491186\n",
      "SubGD iter. 272/499: loss=2.655312373606585, w0=72.63366336633673, w1=15.97566529729859\n",
      "SubGD iter. 273/499: loss=2.655289019295102, w0=72.62673267326743, w1=15.973539197512853\n",
      "SubGD iter. 274/499: loss=2.6552875550089037, w0=72.62673267326743, w1=15.971929536791766\n",
      "SubGD iter. 275/499: loss=2.6553134866795056, w0=72.63366336633673, w1=15.97639823659917\n",
      "SubGD iter. 276/499: loss=2.6552898619976766, w0=72.62673267326743, w1=15.974272136813433\n",
      "SubGD iter. 277/499: loss=2.655288011277936, w0=72.62673267326743, w1=15.972662476092346\n",
      "SubGD iter. 278/499: loss=2.6552903534409347, w0=72.62673267326743, w1=15.971052815371259\n",
      "SubGD iter. 279/499: loss=2.655312155252917, w0=72.63366336633673, w1=15.975521515178663\n",
      "SubGD iter. 280/499: loss=2.65528885398051, w0=72.62673267326743, w1=15.973395415392925\n",
      "SubGD iter. 281/499: loss=2.6552880139511412, w0=72.62673267326743, w1=15.971785754671838\n",
      "SubGD iter. 282/499: loss=2.6553132683258402, w0=72.63366336633673, w1=15.976254454479243\n",
      "SubGD iter. 283/499: loss=2.655289696683084, w0=72.62673267326743, w1=15.974128354693505\n",
      "SubGD iter. 284/499: loss=2.655287845963342, w0=72.62673267326743, w1=15.972518693972418\n",
      "SubGD iter. 285/499: loss=2.6552908123831704, w0=72.62673267326743, w1=15.970909033251331\n",
      "SubGD iter. 286/499: loss=2.6553119368992504, w0=72.63366336633673, w1=15.975377733058735\n",
      "SubGD iter. 287/499: loss=2.655288688665915, w0=72.62673267326743, w1=15.973251633272998\n",
      "SubGD iter. 288/499: loss=2.655288472893378, w0=72.62673267326743, w1=15.971641972551911\n",
      "SubGD iter. 289/499: loss=2.655313049972172, w0=72.63366336633673, w1=15.976110672359315\n",
      "SubGD iter. 290/499: loss=2.6552895313684894, w0=72.62673267326743, w1=15.973984572573578\n",
      "SubGD iter. 291/499: loss=2.6552876806487498, w0=72.62673267326743, w1=15.97237491185249\n",
      "SubGD iter. 292/499: loss=2.6552912713254084, w0=72.62673267326743, w1=15.970765251131404\n",
      "SubGD iter. 293/499: loss=2.655311718545582, w0=72.63366336633673, w1=15.975233950938808\n",
      "SubGD iter. 294/499: loss=2.655288523351323, w0=72.62673267326743, w1=15.97310785115307\n",
      "SubGD iter. 295/499: loss=2.6552889318356137, w0=72.62673267326743, w1=15.971498190431983\n",
      "SubGD iter. 296/499: loss=2.6553128316185037, w0=72.63366336633673, w1=15.975966890239388\n",
      "SubGD iter. 297/499: loss=2.655289366053896, w0=72.62673267326743, w1=15.97384079045365\n",
      "SubGD iter. 298/499: loss=2.6552875153341553, w0=72.62673267326743, w1=15.972231129732563\n",
      "SubGD iter. 299/499: loss=2.6552917302676464, w0=72.62673267326743, w1=15.970621469011476\n",
      "SubGD iter. 300/499: loss=2.655311500191915, w0=72.63366336633673, w1=15.97509016881888\n",
      "SubGD iter. 301/499: loss=2.655288358036728, w0=72.62673267326743, w1=15.972964069033143\n",
      "SubGD iter. 302/499: loss=2.6552893907778525, w0=72.62673267326743, w1=15.971354408312056\n",
      "SubGD iter. 303/499: loss=2.6553126132648375, w0=72.63366336633673, w1=15.97582310811946\n",
      "SubGD iter. 304/499: loss=2.6552892007393027, w0=72.62673267326743, w1=15.973697008333723\n",
      "SubGD iter. 305/499: loss=2.6552873500195613, w0=72.62673267326743, w1=15.972087347612636\n",
      "SubGD iter. 306/499: loss=2.655292189209882, w0=72.62673267326743, w1=15.970477686891549\n",
      "SubGD iter. 307/499: loss=2.6553112818382494, w0=72.63366336633673, w1=15.974946386698953\n",
      "SubGD iter. 308/499: loss=2.6552881927221366, w0=72.62673267326743, w1=15.972820286913215\n",
      "SubGD iter. 309/499: loss=2.6552898497200896, w0=72.62673267326743, w1=15.971210626192129\n",
      "SubGD iter. 310/499: loss=2.6553123949111703, w0=72.63366336633673, w1=15.975679325999533\n",
      "SubGD iter. 311/499: loss=2.6552890354247096, w0=72.62673267326743, w1=15.973553226213795\n",
      "SubGD iter. 312/499: loss=2.655287510230296, w0=72.62673267326743, w1=15.971943565492708\n",
      "SubGD iter. 313/499: loss=2.6553135079840913, w0=72.63366336633673, w1=15.976412265300112\n",
      "SubGD iter. 314/499: loss=2.655289878127283, w0=72.62673267326743, w1=15.974286165514375\n",
      "SubGD iter. 315/499: loss=2.655288027407542, w0=72.62673267326743, w1=15.972676504793288\n",
      "SubGD iter. 316/499: loss=2.6552903086623263, w0=72.62673267326743, w1=15.971066844072201\n",
      "SubGD iter. 317/499: loss=2.6553121765575027, w0=72.63366336633673, w1=15.975535543879605\n",
      "SubGD iter. 318/499: loss=2.655288870110115, w0=72.62673267326743, w1=15.973409444093868\n",
      "SubGD iter. 319/499: loss=2.655287969172531, w0=72.62673267326743, w1=15.97179978337278\n",
      "SubGD iter. 320/499: loss=2.655313289630424, w0=72.63366336633673, w1=15.976268483180185\n",
      "SubGD iter. 321/499: loss=2.65528971281269, w0=72.62673267326743, w1=15.974142383394447\n",
      "SubGD iter. 322/499: loss=2.6552878620929468, w0=72.62673267326743, w1=15.97253272267336\n",
      "SubGD iter. 323/499: loss=2.655290767604562, w0=72.62673267326743, w1=15.970923061952274\n",
      "SubGD iter. 324/499: loss=2.655311958203835, w0=72.63366336633673, w1=15.975391761759678\n",
      "SubGD iter. 325/499: loss=2.6552887047955216, w0=72.62673267326743, w1=15.97326566197394\n",
      "SubGD iter. 326/499: loss=2.655288428114768, w0=72.62673267326743, w1=15.971656001252853\n",
      "SubGD iter. 327/499: loss=2.655313071276755, w0=72.63366336633673, w1=15.976124701060257\n",
      "SubGD iter. 328/499: loss=2.6552895474980964, w0=72.62673267326743, w1=15.97399860127452\n",
      "SubGD iter. 329/499: loss=2.6552876967783545, w0=72.62673267326743, w1=15.972388940553433\n",
      "SubGD iter. 330/499: loss=2.6552912265468, w0=72.62673267326743, w1=15.970779279832346\n",
      "SubGD iter. 331/499: loss=2.655311739850167, w0=72.63366336633673, w1=15.97524797963975\n",
      "SubGD iter. 332/499: loss=2.6552885394809285, w0=72.62673267326743, w1=15.973121879854013\n",
      "SubGD iter. 333/499: loss=2.655288887057005, w0=72.62673267326743, w1=15.971512219132926\n",
      "SubGD iter. 334/499: loss=2.6553128529230885, w0=72.63366336633673, w1=15.97598091894033\n",
      "SubGD iter. 335/499: loss=2.6552893821835037, w0=72.62673267326743, w1=15.973854819154592\n",
      "SubGD iter. 336/499: loss=2.655287531463763, w0=72.62673267326743, w1=15.972245158433505\n",
      "SubGD iter. 337/499: loss=2.6552916854890363, w0=72.62673267326743, w1=15.970635497712419\n",
      "SubGD iter. 338/499: loss=2.6553115214965013, w0=72.63366336633673, w1=15.975104197519823\n",
      "SubGD iter. 339/499: loss=2.655288374166335, w0=72.62673267326743, w1=15.972978097734085\n",
      "SubGD iter. 340/499: loss=2.655289345999243, w0=72.62673267326743, w1=15.971368437012998\n",
      "SubGD iter. 341/499: loss=2.6553126345694213, w0=72.63366336633673, w1=15.975837136820402\n",
      "SubGD iter. 342/499: loss=2.655289216868908, w0=72.62673267326743, w1=15.973711037034665\n",
      "SubGD iter. 343/499: loss=2.655287366149168, w0=72.62673267326743, w1=15.972101376313578\n",
      "SubGD iter. 344/499: loss=2.6552921444312725, w0=72.62673267326743, w1=15.970491715592491\n",
      "SubGD iter. 345/499: loss=2.655311303142833, w0=72.63366336633673, w1=15.974960415399895\n",
      "SubGD iter. 346/499: loss=2.6552882088517418, w0=72.62673267326743, w1=15.972834315614158\n",
      "SubGD iter. 347/499: loss=2.6552898049414795, w0=72.62673267326743, w1=15.97122465489307\n",
      "SubGD iter. 348/499: loss=2.655312416215754, w0=72.63366336633673, w1=15.975693354700475\n",
      "SubGD iter. 349/499: loss=2.655289051554315, w0=72.62673267326743, w1=15.973567254914737\n",
      "SubGD iter. 350/499: loss=2.655287465451686, w0=72.62673267326743, w1=15.97195759419365\n",
      "SubGD iter. 351/499: loss=2.6553135292886765, w0=72.63366336633673, w1=15.976426294001055\n",
      "SubGD iter. 352/499: loss=2.65528989425689, w0=72.62673267326743, w1=15.974300194215317\n",
      "SubGD iter. 353/499: loss=2.655288043537149, w0=72.62673267326743, w1=15.97269053349423\n",
      "SubGD iter. 354/499: loss=2.6552902638837157, w0=72.62673267326743, w1=15.971080872773143\n",
      "SubGD iter. 355/499: loss=2.655312197862086, w0=72.63366336633673, w1=15.975549572580547\n",
      "SubGD iter. 356/499: loss=2.6552888862397235, w0=72.62673267326743, w1=15.97342347279481\n",
      "SubGD iter. 357/499: loss=2.6552879243939222, w0=72.62673267326743, w1=15.971813812073723\n",
      "SubGD iter. 358/499: loss=2.6553133109350084, w0=72.63366336633673, w1=15.976282511881127\n",
      "SubGD iter. 359/499: loss=2.655289728942297, w0=72.62673267326743, w1=15.97415641209539\n",
      "SubGD iter. 360/499: loss=2.655287878222556, w0=72.62673267326743, w1=15.972546751374303\n",
      "SubGD iter. 361/499: loss=2.655290722825954, w0=72.62673267326743, w1=15.970937090653216\n",
      "SubGD iter. 362/499: loss=2.6553119795084212, w0=72.63366336633673, w1=15.97540579046062\n",
      "SubGD iter. 363/499: loss=2.6552887209251286, w0=72.62673267326743, w1=15.973279690674882\n",
      "SubGD iter. 364/499: loss=2.6552883833361602, w0=72.62673267326743, w1=15.971670029953795\n",
      "SubGD iter. 365/499: loss=2.6553130925813413, w0=72.63366336633673, w1=15.9761387297612\n",
      "SubGD iter. 366/499: loss=2.655289563627703, w0=72.62673267326743, w1=15.974012629975462\n",
      "SubGD iter. 367/499: loss=2.655287712907961, w0=72.62673267326743, w1=15.972402969254375\n",
      "SubGD iter. 368/499: loss=2.6552911817681895, w0=72.62673267326743, w1=15.970793308533288\n",
      "SubGD iter. 369/499: loss=2.655311761154752, w0=72.63366336633673, w1=15.975262008340692\n",
      "SubGD iter. 370/499: loss=2.655288555610534, w0=72.62673267326743, w1=15.973135908554955\n",
      "SubGD iter. 371/499: loss=2.6552888422783973, w0=72.62673267326743, w1=15.971526247833868\n",
      "SubGD iter. 372/499: loss=2.655312874227674, w0=72.63366336633673, w1=15.975994947641272\n",
      "SubGD iter. 373/499: loss=2.6552893983131085, w0=72.62673267326743, w1=15.973868847855535\n",
      "SubGD iter. 374/499: loss=2.655287547593368, w0=72.62673267326743, w1=15.972259187134448\n",
      "SubGD iter. 375/499: loss=2.655291640710427, w0=72.62673267326743, w1=15.97064952641336\n",
      "SubGD iter. 376/499: loss=2.6553115428010843, w0=72.63366336633673, w1=15.975118226220765\n",
      "SubGD iter. 377/499: loss=2.6552883902959414, w0=72.62673267326743, w1=15.972992126435027\n",
      "SubGD iter. 378/499: loss=2.655289301220632, w0=72.62673267326743, w1=15.97138246571394\n",
      "SubGD iter. 379/499: loss=2.655312655874006, w0=72.63366336633673, w1=15.975851165521345\n",
      "SubGD iter. 380/499: loss=2.655289232998515, w0=72.62673267326743, w1=15.973725065735607\n",
      "SubGD iter. 381/499: loss=2.655287382278775, w0=72.62673267326743, w1=15.97211540501452\n",
      "SubGD iter. 382/499: loss=2.655292099652663, w0=72.62673267326743, w1=15.970505744293433\n",
      "SubGD iter. 383/499: loss=2.6553113244474185, w0=72.63366336633673, w1=15.974974444100837\n",
      "SubGD iter. 384/499: loss=2.6552882249813483, w0=72.62673267326743, w1=15.9728483443151\n",
      "SubGD iter. 385/499: loss=2.655289760162869, w0=72.62673267326743, w1=15.971238683594013\n",
      "SubGD iter. 386/499: loss=2.655312437520339, w0=72.63366336633673, w1=15.975707383401417\n",
      "SubGD iter. 387/499: loss=2.6552890676839223, w0=72.62673267326743, w1=15.97358128361568\n",
      "SubGD iter. 388/499: loss=2.6552874206730754, w0=72.62673267326743, w1=15.971971622894593\n",
      "SubGD iter. 389/499: loss=2.6553135505932595, w0=72.63366336633673, w1=15.976440322701997\n",
      "SubGD iter. 390/499: loss=2.6552899103864975, w0=72.62673267326743, w1=15.97431422291626\n",
      "SubGD iter. 391/499: loss=2.6552880596667556, w0=72.62673267326743, w1=15.972704562195172\n",
      "SubGD iter. 392/499: loss=2.6552902191051055, w0=72.62673267326743, w1=15.971094901474086\n",
      "SubGD iter. 393/499: loss=2.6553122191666723, w0=72.63366336633673, w1=15.97556360128149\n",
      "SubGD iter. 394/499: loss=2.6552889023693287, w0=72.62673267326743, w1=15.973437501495752\n",
      "SubGD iter. 395/499: loss=2.6552878796153143, w0=72.62673267326743, w1=15.971827840774665\n",
      "SubGD iter. 396/499: loss=2.6553133322395914, w0=72.63366336633673, w1=15.97629654058207\n",
      "SubGD iter. 397/499: loss=2.655289745071902, w0=72.62673267326743, w1=15.974170440796332\n",
      "SubGD iter. 398/499: loss=2.655287894352162, w0=72.62673267326743, w1=15.972560780075245\n",
      "SubGD iter. 399/499: loss=2.6552906780473435, w0=72.62673267326743, w1=15.970951119354158\n",
      "SubGD iter. 400/499: loss=2.655312000813004, w0=72.63366336633673, w1=15.975419819161562\n",
      "SubGD iter. 401/499: loss=2.6552887370547356, w0=72.62673267326743, w1=15.973293719375825\n",
      "SubGD iter. 402/499: loss=2.6552883385575505, w0=72.62673267326743, w1=15.971684058654738\n",
      "SubGD iter. 403/499: loss=2.655313113885926, w0=72.63366336633673, w1=15.976152758462142\n",
      "SubGD iter. 404/499: loss=2.655289579757308, w0=72.62673267326743, w1=15.974026658676404\n",
      "SubGD iter. 405/499: loss=2.655287729037569, w0=72.62673267326743, w1=15.972416997955317\n",
      "SubGD iter. 406/499: loss=2.65529113698958, w0=72.62673267326743, w1=15.97080733723423\n",
      "SubGD iter. 407/499: loss=2.655311782459336, w0=72.63366336633673, w1=15.975276037041635\n",
      "SubGD iter. 408/499: loss=2.6552885717401424, w0=72.62673267326743, w1=15.973149937255897\n",
      "SubGD iter. 409/499: loss=2.655288797499786, w0=72.62673267326743, w1=15.97154027653481\n",
      "SubGD iter. 410/499: loss=2.655312895532257, w0=72.63366336633673, w1=15.976008976342214\n",
      "SubGD iter. 411/499: loss=2.6552894144427155, w0=72.62673267326743, w1=15.973882876556477\n",
      "SubGD iter. 412/499: loss=2.6552875637229745, w0=72.62673267326743, w1=15.97227321583539\n",
      "SubGD iter. 413/499: loss=2.6552915959318173, w0=72.62673267326743, w1=15.970663555114303\n",
      "SubGD iter. 414/499: loss=2.655311564105669, w0=72.63366336633673, w1=15.975132254921707\n",
      "SubGD iter. 415/499: loss=2.655288406425549, w0=72.62673267326743, w1=15.97300615513597\n",
      "SubGD iter. 416/499: loss=2.655289256442024, w0=72.62673267326743, w1=15.971396494414883\n",
      "SubGD iter. 417/499: loss=2.6553126771785918, w0=72.63366336633673, w1=15.975865194222287\n",
      "SubGD iter. 418/499: loss=2.6552892491281224, w0=72.62673267326743, w1=15.97373909443655\n",
      "SubGD iter. 419/499: loss=2.655287398408381, w0=72.62673267326743, w1=15.972129433715462\n",
      "SubGD iter. 420/499: loss=2.655292054874053, w0=72.62673267326743, w1=15.970519772994376\n",
      "SubGD iter. 421/499: loss=2.655311345752003, w0=72.63366336633673, w1=15.97498847280178\n",
      "SubGD iter. 422/499: loss=2.6552882411109557, w0=72.62673267326743, w1=15.972862373016042\n",
      "SubGD iter. 423/499: loss=2.6552897153842605, w0=72.62673267326743, w1=15.971252712294955\n",
      "SubGD iter. 424/499: loss=2.655312458824922, w0=72.63366336633673, w1=15.97572141210236\n",
      "SubGD iter. 425/499: loss=2.655289083813528, w0=72.62673267326743, w1=15.973595312316622\n",
      "SubGD iter. 426/499: loss=2.655287375894467, w0=72.62673267326743, w1=15.971985651595535\n",
      "SubGD iter. 427/499: loss=2.655313571897845, w0=72.63366336633673, w1=15.97645435140294\n",
      "SubGD iter. 428/499: loss=2.655289926516102, w0=72.62673267326743, w1=15.974328251617202\n",
      "SubGD iter. 429/499: loss=2.6552880757963617, w0=72.62673267326743, w1=15.972718590896115\n",
      "SubGD iter. 430/499: loss=2.655290174326498, w0=72.62673267326743, w1=15.971108930175028\n",
      "SubGD iter. 431/499: loss=2.655312240471256, w0=72.63366336633673, w1=15.975577629982432\n",
      "SubGD iter. 432/499: loss=2.655288918498935, w0=72.62673267326743, w1=15.973451530196694\n",
      "SubGD iter. 433/499: loss=2.655287834836702, w0=72.62673267326743, w1=15.971841869475607\n",
      "SubGD iter. 434/499: loss=2.655313353544177, w0=72.63366336633673, w1=15.976310569283012\n",
      "SubGD iter. 435/499: loss=2.655289761201509, w0=72.62673267326743, w1=15.974184469497274\n",
      "SubGD iter. 436/499: loss=2.655287910481768, w0=72.62673267326743, w1=15.972574808776187\n",
      "SubGD iter. 437/499: loss=2.6552906332687343, w0=72.62673267326743, w1=15.9709651480551\n",
      "SubGD iter. 438/499: loss=2.655312022117588, w0=72.63366336633673, w1=15.975433847862504\n",
      "SubGD iter. 439/499: loss=2.65528875318434, w0=72.62673267326743, w1=15.973307748076767\n",
      "SubGD iter. 440/499: loss=2.6552882937789413, w0=72.62673267326743, w1=15.97169808735568\n",
      "SubGD iter. 441/499: loss=2.655313135190509, w0=72.63366336633673, w1=15.976166787163084\n",
      "SubGD iter. 442/499: loss=2.6552895958869143, w0=72.62673267326743, w1=15.974040687377347\n",
      "SubGD iter. 443/499: loss=2.655287745167174, w0=72.62673267326743, w1=15.97243102665626\n",
      "SubGD iter. 444/499: loss=2.6552910922109696, w0=72.62673267326743, w1=15.970821365935173\n",
      "SubGD iter. 445/499: loss=2.6553118037639196, w0=72.63366336633673, w1=15.975290065742577\n",
      "SubGD iter. 446/499: loss=2.655288587869748, w0=72.62673267326743, w1=15.97316396595684\n",
      "SubGD iter. 447/499: loss=2.6552887527211766, w0=72.62673267326743, w1=15.971554305235752\n",
      "SubGD iter. 448/499: loss=2.655312916836842, w0=72.63366336633673, w1=15.976023005043157\n",
      "SubGD iter. 449/499: loss=2.655289430572321, w0=72.62673267326743, w1=15.97389690525742\n",
      "SubGD iter. 450/499: loss=2.655287579852583, w0=72.62673267326743, w1=15.972287244536332\n",
      "SubGD iter. 451/499: loss=2.6552915511532063, w0=72.62673267326743, w1=15.970677583815245\n",
      "SubGD iter. 452/499: loss=2.655311585410253, w0=72.63366336633673, w1=15.97514628362265\n",
      "SubGD iter. 453/499: loss=2.6552884225551527, w0=72.62673267326743, w1=15.973020183836912\n",
      "SubGD iter. 454/499: loss=2.655289211663416, w0=72.62673267326743, w1=15.971410523115825\n",
      "SubGD iter. 455/499: loss=2.655312698483175, w0=72.63366336633673, w1=15.97587922292323\n",
      "SubGD iter. 456/499: loss=2.655289265257728, w0=72.62673267326743, w1=15.973753123137492\n",
      "SubGD iter. 457/499: loss=2.655287414537987, w0=72.62673267326743, w1=15.972143462416405\n",
      "SubGD iter. 458/499: loss=2.6552920100954442, w0=72.62673267326743, w1=15.970533801695318\n",
      "SubGD iter. 459/499: loss=2.655311367056587, w0=72.63366336633673, w1=15.975002501502722\n",
      "SubGD iter. 460/499: loss=2.65528825724056, w0=72.62673267326743, w1=15.972876401716984\n",
      "SubGD iter. 461/499: loss=2.6552896706056517, w0=72.62673267326743, w1=15.971266740995897\n",
      "SubGD iter. 462/499: loss=2.655312480129508, w0=72.63366336633673, w1=15.975735440803302\n",
      "SubGD iter. 463/499: loss=2.655289099943134, w0=72.62673267326743, w1=15.973609341017564\n",
      "SubGD iter. 464/499: loss=2.6552873311158574, w0=72.62673267326743, w1=15.971999680296477\n",
      "SubGD iter. 465/499: loss=2.655313593202429, w0=72.63366336633673, w1=15.976468380103881\n",
      "SubGD iter. 466/499: loss=2.655289942645707, w0=72.62673267326743, w1=15.974342280318144\n",
      "SubGD iter. 467/499: loss=2.655288091925969, w0=72.62673267326743, w1=15.972732619597057\n",
      "SubGD iter. 468/499: loss=2.6552901295478883, w0=72.62673267326743, w1=15.97112295887597\n",
      "SubGD iter. 469/499: loss=2.6553122617758405, w0=72.63366336633673, w1=15.975591658683374\n",
      "SubGD iter. 470/499: loss=2.6552889346285413, w0=72.62673267326743, w1=15.973465558897637\n",
      "SubGD iter. 471/499: loss=2.6552877900580936, w0=72.62673267326743, w1=15.97185589817655\n",
      "SubGD iter. 472/499: loss=2.655313374848762, w0=72.63366336633673, w1=15.976324597983954\n",
      "SubGD iter. 473/499: loss=2.6552897773311144, w0=72.62673267326743, w1=15.974198498198216\n",
      "SubGD iter. 474/499: loss=2.655287926611373, w0=72.62673267326743, w1=15.97258883747713\n",
      "SubGD iter. 475/499: loss=2.655290588490126, w0=72.62673267326743, w1=15.970979176756043\n",
      "SubGD iter. 476/499: loss=2.655312043422172, w0=72.63366336633673, w1=15.975447876563447\n",
      "SubGD iter. 477/499: loss=2.6552887693139486, w0=72.62673267326743, w1=15.97332177677771\n",
      "SubGD iter. 478/499: loss=2.6552882490003302, w0=72.62673267326743, w1=15.971712116056622\n",
      "SubGD iter. 479/499: loss=2.6553131564950934, w0=72.63366336633673, w1=15.976180815864026\n",
      "SubGD iter. 480/499: loss=2.6552896120165213, w0=72.62673267326743, w1=15.974054716078289\n",
      "SubGD iter. 481/499: loss=2.6552877612967802, w0=72.62673267326743, w1=15.972445055357202\n",
      "SubGD iter. 482/499: loss=2.655291047432361, w0=72.62673267326743, w1=15.970835394636115\n",
      "SubGD iter. 483/499: loss=2.655311825068504, w0=72.63366336633673, w1=15.97530409444352\n",
      "SubGD iter. 484/499: loss=2.655288603999354, w0=72.62673267326743, w1=15.973177994657782\n",
      "SubGD iter. 485/499: loss=2.655288707942567, w0=72.62673267326743, w1=15.971568333936695\n",
      "SubGD iter. 486/499: loss=2.655312938141426, w0=72.63366336633673, w1=15.976037033744099\n",
      "SubGD iter. 487/499: loss=2.6552894467019286, w0=72.62673267326743, w1=15.973910933958361\n",
      "SubGD iter. 488/499: loss=2.6552875959821867, w0=72.62673267326743, w1=15.972301273237274\n",
      "SubGD iter. 489/499: loss=2.6552915063745988, w0=72.62673267326743, w1=15.970691612516188\n",
      "SubGD iter. 490/499: loss=2.6553116067148377, w0=72.63366336633673, w1=15.975160312323592\n",
      "SubGD iter. 491/499: loss=2.6552884386847615, w0=72.62673267326743, w1=15.973034212537854\n",
      "SubGD iter. 492/499: loss=2.655289166884805, w0=72.62673267326743, w1=15.971424551816767\n",
      "SubGD iter. 493/499: loss=2.6553127197877595, w0=72.63366336633673, w1=15.975893251624171\n",
      "SubGD iter. 494/499: loss=2.6552892813873354, w0=72.62673267326743, w1=15.973767151838434\n",
      "SubGD iter. 495/499: loss=2.6552874306675935, w0=72.62673267326743, w1=15.972157491117347\n",
      "SubGD iter. 496/499: loss=2.6552919653168354, w0=72.62673267326743, w1=15.97054783039626\n",
      "SubGD iter. 497/499: loss=2.6553113883611705, w0=72.63366336633673, w1=15.975016530203664\n",
      "SubGD iter. 498/499: loss=2.6552882733701666, w0=72.62673267326743, w1=15.972890430417927\n",
      "SubGD iter. 499/499: loss=2.6552896258270424, w0=72.62673267326743, w1=15.97128076969684\n",
      "SubGD: execution time=0.035 seconds\n"
     ]
    }
   ],
   "source": [
    "# Define the parameters of the algorithm.\n",
    "max_iters = 500\n",
    "gamma = 0.7\n",
    "batch_size = 1\n",
    "\n",
    "# Initialization\n",
    "w_initial = np.array([0, 0])\n",
    "\n",
    "# Start SubSGD.\n",
    "start_time = datetime.datetime.now()\n",
    "subgd_losses, subgd_ws = subgradient_descent(y, tx, w_initial, max_iters, gamma)\n",
    "end_time = datetime.datetime.now()\n",
    "\n",
    "# Print result\n",
    "exection_time = (end_time - start_time).total_seconds()\n",
    "print(\"SubGD: execution time={t:.3f} seconds\".format(t=exection_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6939469fb0cf4707afa33b3b171aa9ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=1, description='n_iter', max=501, min=1), Output()), _dom_classes=('widg…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.plot_figure(n_iter)>"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ipywidgets import IntSlider, interact\n",
    "\n",
    "\n",
    "def plot_figure(n_iter):\n",
    "    fig = gradient_descent_visualization(\n",
    "        subgd_losses,\n",
    "        subgd_ws,\n",
    "        grid_losses,\n",
    "        grid_w0,\n",
    "        grid_w1,\n",
    "        mean_x,\n",
    "        std_x,\n",
    "        height,\n",
    "        weight,\n",
    "        n_iter,\n",
    "    )\n",
    "    fig.set_size_inches(10.0, 6.0)\n",
    "\n",
    "\n",
    "interact(plot_figure, n_iter=IntSlider(min=1, max=len(subgd_ws)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stochastic Subgradient Descent\n",
    "\n",
    "**NB** for the computation of the subgradient you can reuse the `compute_subgradient` method that you implemented above, just making sure that you pass in a minibatch as opposed to the full data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stochastic_subgradient_descent(y, tx, initial_w, batch_size, max_iters, gamma):\n",
    "    \"\"\"Compute a stochastic subgradient at w from a data sample batch of size B, where B < N, and their corresponding labels.\n",
    "\n",
    "    Args:\n",
    "        y: numpy array of shape=(B, )\n",
    "        tx: numpy array of shape=(B,2)\n",
    "        initial_w: numpy array of shape=(2, ). The initial guess (or the initialization) for the model parameters\n",
    "        batch_size: a scalar denoting the number of data points in a mini-batch used for computing the stochastic subgradient\n",
    "        max_iters: a scalar denoting the total number of iterations of SubSGD\n",
    "        gamma: a scalar denoting the stepsize\n",
    "\n",
    "    Returns:\n",
    "        losses: a list of length max_iters containing the loss value (scalar) for each iteration of SubSGD\n",
    "        ws: a list of length max_iters containing the model parameters as numpy arrays of shape (2, ), for each iteration of SubSGD\n",
    "    \"\"\"\n",
    "\n",
    "    # Define parameters to store w and loss\n",
    "    ws = [initial_w]\n",
    "    losses = []\n",
    "    w = initial_w\n",
    "\n",
    "    for n_iter in range(max_iters):\n",
    "        # ***************************************************\n",
    "        # INSERT YOUR CODE HERE\n",
    "        # TODO: implement stochastic subgradient descent.\n",
    "        for y_batched, tx_batched in batch_iter(y=y,tx=tx,batch_size=batch_size):\n",
    "            loss = compute_loss(y_batched,tx_batched,w, MSE=False)\n",
    "            w = w - gamma * compute_subgradient_mae(y_batched,tx_batched,w)\n",
    "        ws.append(w)\n",
    "        losses.append(loss)\n",
    "        # ***************************************************\n",
    "\n",
    "        print(\n",
    "            \"SubSGD iter. {bi}/{ti}: loss={l}, w0={w0}, w1={w1}\".format(\n",
    "                bi=n_iter, ti=max_iters - 1, l=loss, w0=w[0], w1=w[1]\n",
    "            )\n",
    "        )\n",
    "    return losses, ws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SubSGD iter. 0/499: loss=38.460803476269305, w0=0.7, w1=0.25028111646205636\n",
      "SubSGD iter. 1/499: loss=27.340024376890693, w0=1.4, w1=-0.25822000127777706\n",
      "SubSGD iter. 2/499: loss=43.93969191609284, w0=2.0999999999999996, w1=0.46680018880302704\n",
      "SubSGD iter. 3/499: loss=40.44447814754712, w0=2.8, w1=0.5806205156173397\n",
      "SubSGD iter. 4/499: loss=43.64345754553777, w0=3.5, w1=1.2041086379035173\n",
      "SubSGD iter. 5/499: loss=26.04525626004959, w0=4.2, w1=0.7723160596200969\n",
      "SubSGD iter. 6/499: loss=42.00600659412334, w0=4.9, w1=1.497336249700901\n",
      "SubSGD iter. 7/499: loss=41.97093001416113, w0=5.6000000000000005, w1=2.1493931471433565\n",
      "SubSGD iter. 8/499: loss=32.11675345474946, w0=6.300000000000001, w1=2.348154012961881\n",
      "SubSGD iter. 9/499: loss=29.17236893310691, w0=7.000000000000001, w1=1.9778859224330843\n",
      "SubSGD iter. 10/499: loss=32.96657052649296, w0=7.700000000000001, w1=1.9593064635342077\n",
      "SubSGD iter. 11/499: loss=42.20876817098759, w0=8.4, w1=3.154045300638633\n",
      "SubSGD iter. 12/499: loss=27.3806526324789, w0=9.1, w1=2.300199030213364\n",
      "SubSGD iter. 13/499: loss=26.114173355405597, w0=9.799999999999999, w1=2.0829420260336136\n",
      "SubSGD iter. 14/499: loss=31.93232639657188, w0=10.499999999999998, w1=2.1351023715633244\n",
      "SubSGD iter. 15/499: loss=39.456774242476534, w0=11.199999999999998, w1=2.7780320703271197\n",
      "SubSGD iter. 16/499: loss=39.57143919913789, w0=11.899999999999997, w1=3.217956513211302\n",
      "SubSGD iter. 17/499: loss=22.46637380744226, w0=12.599999999999996, w1=2.7861639349278815\n",
      "SubSGD iter. 18/499: loss=32.17134044820068, w0=13.299999999999995, w1=2.8014716016400176\n",
      "SubSGD iter. 19/499: loss=27.181209378402038, w0=13.999999999999995, w1=2.0621388021960736\n",
      "SubSGD iter. 20/499: loss=29.54527251708605, w0=14.699999999999994, w1=2.0274479428546024\n",
      "SubSGD iter. 21/499: loss=32.897825600260816, w0=15.399999999999993, w1=2.223968025633105\n",
      "SubSGD iter. 22/499: loss=19.15747416017873, w0=16.099999999999994, w1=1.3839404541732943\n",
      "SubSGD iter. 23/499: loss=37.948705262969085, w0=16.799999999999994, w1=2.1021037782044827\n",
      "SubSGD iter. 24/499: loss=26.523467223259672, w0=17.499999999999993, w1=2.300864644023007\n",
      "SubSGD iter. 25/499: loss=29.175985117634855, w0=18.199999999999992, w1=2.5656497532137754\n",
      "SubSGD iter. 26/499: loss=22.511461989534823, w0=18.89999999999999, w1=1.8873027572392325\n",
      "SubSGD iter. 27/499: loss=51.81530693349387, w0=19.59999999999999, w1=-1.4858409203504446\n",
      "SubSGD iter. 28/499: loss=46.30395608158341, w0=20.29999999999999, w1=-0.3607109602201375\n",
      "SubSGD iter. 29/499: loss=20.78705761396231, w0=20.99999999999999, w1=-0.7917216449687512\n",
      "SubSGD iter. 30/499: loss=31.09679626642059, w0=21.69999999999999, w1=-0.6779013181544385\n",
      "SubSGD iter. 31/499: loss=19.532212722403088, w0=22.399999999999988, w1=-1.1036874654451778\n",
      "SubSGD iter. 32/499: loss=27.762842255043005, w0=23.099999999999987, w1=-0.8745657731584198\n",
      "SubSGD iter. 33/499: loss=19.258826149297224, w0=23.799999999999986, w1=-1.2312912915142564\n",
      "SubSGD iter. 34/499: loss=45.92777726301253, w0=24.499999999999986, w1=0.008025009463744626\n",
      "SubSGD iter. 35/499: loss=13.954775235091516, w0=25.199999999999985, w1=-0.893607254949013\n",
      "SubSGD iter. 36/499: loss=18.06635199034288, w0=25.899999999999984, w1=-1.1376340796581639\n",
      "SubSGD iter. 37/499: loss=15.108768776989587, w0=26.599999999999984, w1=-1.7075942041941499\n",
      "SubSGD iter. 38/499: loss=12.409897860601935, w0=27.299999999999983, w1=-2.330380611014442\n",
      "SubSGD iter. 39/499: loss=11.7828529259447, w0=27.999999999999982, w1=-2.9531670178347342\n",
      "SubSGD iter. 40/499: loss=26.946961931948334, w0=28.69999999999998, w1=-2.7566469350562315\n",
      "SubSGD iter. 41/499: loss=34.72941064521697, w0=29.39999999999998, w1=-1.9004248825516934\n",
      "SubSGD iter. 42/499: loss=29.100217304991958, w0=30.09999999999998, w1=-0.9422897916498864\n",
      "SubSGD iter. 43/499: loss=19.000478949554235, w0=30.79999999999998, w1=-1.4669227163616259\n",
      "SubSGD iter. 44/499: loss=16.36695490777599, w0=31.49999999999998, w1=-2.0512352539075174\n",
      "SubSGD iter. 45/499: loss=12.498570439871838, w0=32.19999999999998, w1=-2.6722868274781106\n",
      "SubSGD iter. 46/499: loss=20.30485788829322, w0=32.899999999999984, w1=-2.690866286376987\n",
      "SubSGD iter. 47/499: loss=13.230692930292786, w0=33.59999999999999, w1=-2.704621482352478\n",
      "SubSGD iter. 48/499: loss=18.99771770974321, w0=34.29999999999999, w1=-2.5262693609726634\n",
      "SubSGD iter. 49/499: loss=29.75781479038044, w0=34.99999999999999, w1=-1.6210942577856\n",
      "SubSGD iter. 50/499: loss=19.920310289773294, w0=35.699999999999996, w1=-1.4887707314317613\n",
      "SubSGD iter. 51/499: loss=18.123506722365672, w0=36.4, w1=-1.8882285038183402\n",
      "SubSGD iter. 52/499: loss=3.937923344765192, w0=37.1, w1=-2.9780235268915605\n",
      "SubSGD iter. 53/499: loss=5.186176781163194, w0=37.800000000000004, w1=-3.818051098351371\n",
      "SubSGD iter. 54/499: loss=6.731657251821943, w0=38.50000000000001, w1=-4.442867198162317\n",
      "SubSGD iter. 55/499: loss=29.737704943034586, w0=39.20000000000001, w1=-3.724703874131129\n",
      "SubSGD iter. 56/499: loss=33.932693690792874, w0=39.90000000000001, w1=-6.495003571020119\n",
      "SubSGD iter. 57/499: loss=16.40412645356557, w0=40.600000000000016, w1=-6.513583029918996\n",
      "SubSGD iter. 58/499: loss=33.01763003715685, w0=41.30000000000002, w1=-5.420958515593202\n",
      "SubSGD iter. 59/499: loss=21.32315430464582, w0=42.00000000000002, w1=-5.307138188778889\n",
      "SubSGD iter. 60/499: loss=6.5585504845247975, w0=42.700000000000024, w1=-5.850154650143987\n",
      "SubSGD iter. 61/499: loss=17.472093249644928, w0=43.40000000000003, w1=-5.7616271366548615\n",
      "SubSGD iter. 62/499: loss=24.74275542836722, w0=44.10000000000003, w1=-4.803492045753054\n",
      "SubSGD iter. 63/499: loss=5.718761206134609, w0=44.80000000000003, w1=-5.074972227735634\n",
      "SubSGD iter. 64/499: loss=6.389021150350324, w0=45.500000000000036, w1=-5.422056213355624\n",
      "SubSGD iter. 65/499: loss=31.83986371467216, w0=46.20000000000004, w1=-4.409377872002858\n",
      "SubSGD iter. 66/499: loss=3.1505078957752524, w0=46.90000000000004, w1=-4.944897554829063\n",
      "SubSGD iter. 67/499: loss=7.006071937382689, w0=47.600000000000044, w1=-5.499004628825643\n",
      "SubSGD iter. 68/499: loss=5.647770572553377, w0=48.30000000000005, w1=-6.238337428269587\n",
      "SubSGD iter. 69/499: loss=8.918684770788449, w0=49.00000000000005, w1=-6.668669016730323\n",
      "SubSGD iter. 70/499: loss=25.60914871843451, w0=49.70000000000005, w1=-5.936704423222689\n",
      "SubSGD iter. 71/499: loss=13.716716706486658, w0=50.400000000000055, w1=-5.9213967565105525\n",
      "SubSGD iter. 72/499: loss=13.366549331729392, w0=51.10000000000006, w1=-5.906089089798416\n",
      "SubSGD iter. 73/499: loss=6.18667159131115, w0=51.80000000000006, w1=-6.433277728545644\n",
      "SubSGD iter. 74/499: loss=10.434763017146611, w0=52.500000000000064, w1=-6.467968587887115\n",
      "SubSGD iter. 75/499: loss=23.75421614142377, w0=53.20000000000007, w1=-5.73600399437948\n",
      "SubSGD iter. 76/499: loss=10.838949517261952, w0=53.90000000000007, w1=-5.76843300214684\n",
      "SubSGD iter. 77/499: loss=4.082256742983876, w0=53.20000000000007, w1=-4.7916355232049215\n",
      "SubSGD iter. 78/499: loss=3.8011821850431566, w0=53.90000000000007, w1=-5.364645606219545\n",
      "SubSGD iter. 79/499: loss=7.518206695465885, w0=53.20000000000007, w1=-4.274850583146325\n",
      "SubSGD iter. 80/499: loss=11.948545917409383, w0=53.90000000000007, w1=-4.259542916434189\n",
      "SubSGD iter. 81/499: loss=14.180339860328722, w0=54.60000000000007, w1=-4.063022833655686\n",
      "SubSGD iter. 82/499: loss=14.974043666284587, w0=55.300000000000075, w1=-3.6844830502989545\n",
      "SubSGD iter. 83/499: loss=17.28294465392965, w0=56.00000000000008, w1=-3.0705686369213714\n",
      "SubSGD iter. 84/499: loss=18.36851992732725, w0=56.70000000000008, w1=-2.4244214035341507\n",
      "SubSGD iter. 85/499: loss=17.07089043741768, w0=57.400000000000084, w1=-1.6784357499467537\n",
      "SubSGD iter. 86/499: loss=15.353272259927213, w0=58.10000000000009, w1=-1.0645213365691708\n",
      "SubSGD iter. 87/499: loss=0.042209788749964616, w0=57.400000000000084, w1=-0.21067506614390175\n",
      "SubSGD iter. 88/499: loss=1.8230658041747958, w0=58.10000000000009, w1=-0.6061118580869077\n",
      "SubSGD iter. 89/499: loss=1.8459843326237682, w0=57.400000000000084, w1=-0.047988154337868405\n",
      "SubSGD iter. 90/499: loss=4.271687648621345, w0=56.70000000000008, w1=1.136014046056023\n",
      "SubSGD iter. 91/499: loss=2.920358212523073, w0=56.00000000000008, w1=2.3200162464499146\n",
      "SubSGD iter. 92/499: loss=12.548162073041208, w0=56.70000000000008, w1=2.698556029806646\n",
      "SubSGD iter. 93/499: loss=5.020475668276028, w0=57.400000000000084, w1=2.514395251488326\n",
      "SubSGD iter. 94/499: loss=2.4434956028491612, w0=58.10000000000009, w1=2.5707048665336294\n",
      "SubSGD iter. 95/499: loss=0.7927524407354198, w0=58.80000000000009, w1=2.290775874097166\n",
      "SubSGD iter. 96/499: loss=0.05452375142010624, w0=59.50000000000009, w1=1.7208157495611802\n",
      "SubSGD iter. 97/499: loss=1.2188260011784529, w0=60.200000000000095, w1=1.2811273444759959\n",
      "SubSGD iter. 98/499: loss=2.1925936146870697, w0=59.50000000000009, w1=1.905943444286942\n",
      "SubSGD iter. 99/499: loss=6.448529046271659, w0=60.200000000000095, w1=1.778928999058917\n",
      "SubSGD iter. 100/499: loss=0.48328080873605117, w0=60.9000000000001, w1=1.5616719948791669\n",
      "SubSGD iter. 101/499: loss=10.712637461839662, w0=61.6000000000001, w1=2.153989956147345\n",
      "SubSGD iter. 102/499: loss=13.157209869769538, w0=62.300000000000104, w1=2.8001371895345657\n",
      "SubSGD iter. 103/499: loss=16.32166771817372, w0=63.00000000000011, w1=3.9184474101460474\n",
      "SubSGD iter. 104/499: loss=6.76831565945837, w0=63.70000000000011, w1=3.6774674954793993\n",
      "SubSGD iter. 105/499: loss=8.70389752804715, w0=64.4000000000001, w1=4.378401492914152\n",
      "SubSGD iter. 106/499: loss=13.201440714800547, w0=65.10000000000011, w1=5.257649458810325\n",
      "SubSGD iter. 107/499: loss=1.9441458466971397, w0=65.80000000000011, w1=4.703542384813744\n",
      "SubSGD iter. 108/499: loss=4.091927437860427, w0=65.10000000000011, w1=5.522200754619372\n",
      "SubSGD iter. 109/499: loss=0.4838958642445803, w0=65.80000000000011, w1=5.171863821250981\n",
      "SubSGD iter. 110/499: loss=3.392537770963827, w0=65.10000000000011, w1=5.729987525000021\n",
      "SubSGD iter. 111/499: loss=0.5270688226471165, w0=65.80000000000011, w1=5.609482973520978\n",
      "SubSGD iter. 112/499: loss=3.0877567448044054, w0=65.10000000000011, w1=6.511115237933736\n",
      "SubSGD iter. 113/499: loss=6.728405266315484, w0=65.80000000000011, w1=7.142280577928588\n",
      "SubSGD iter. 114/499: loss=3.267141895832495, w0=65.10000000000011, w1=8.031112402095081\n",
      "SubSGD iter. 115/499: loss=2.5822288563803397, w0=65.80000000000011, w1=7.665191671364684\n",
      "SubSGD iter. 116/499: loss=0.7085363019740107, w0=65.10000000000011, w1=7.947739490450909\n",
      "SubSGD iter. 117/499: loss=3.965894700730182, w0=65.80000000000011, w1=8.080063016804747\n",
      "SubSGD iter. 118/499: loss=1.8721053731884325, w0=65.10000000000011, w1=8.615582699630952\n",
      "SubSGD iter. 119/499: loss=9.259992291456982, w0=65.80000000000011, w1=8.826747094197156\n",
      "SubSGD iter. 120/499: loss=4.353267424101098, w0=66.50000000000011, w1=8.571315213095586\n",
      "SubSGD iter. 121/499: loss=10.08937807359765, w0=67.20000000000012, w1=8.919282259486\n",
      "SubSGD iter. 122/499: loss=0.2760928559066329, w0=67.90000000000012, w1=8.838467953997288\n",
      "SubSGD iter. 123/499: loss=4.5949843746353665, w0=67.20000000000012, w1=8.95835976748562\n",
      "SubSGD iter. 124/499: loss=1.668558884185117, w0=67.90000000000012, w1=8.753526247610397\n",
      "SubSGD iter. 125/499: loss=0.6126810504616884, w0=67.20000000000012, w1=8.87403079908944\n",
      "SubSGD iter. 126/499: loss=3.269637649027544, w0=67.90000000000012, w1=8.984330832550231\n",
      "SubSGD iter. 127/499: loss=1.8649563252682881, w0=68.60000000000012, w1=8.874156715669491\n",
      "SubSGD iter. 128/499: loss=0.42651199372431847, w0=67.90000000000012, w1=8.954971021158203\n",
      "SubSGD iter. 129/499: loss=7.3685301249687924, w0=68.60000000000012, w1=9.75014074627555\n",
      "SubSGD iter. 130/499: loss=3.7579182097584223, w0=67.90000000000012, w1=10.228188948701673\n",
      "SubSGD iter. 131/499: loss=3.2446824355849593, w0=67.20000000000012, w1=10.706237151127796\n",
      "SubSGD iter. 132/499: loss=1.764333479502131, w0=66.50000000000011, w1=11.54765566085374\n",
      "SubSGD iter. 133/499: loss=3.408994140660255, w0=67.20000000000012, w1=11.657955694314532\n",
      "SubSGD iter. 134/499: loss=2.9583293175540177, w0=67.90000000000012, w1=12.358889691749285\n",
      "SubSGD iter. 135/499: loss=3.5672876166482936, w0=68.60000000000012, w1=13.093165435241083\n",
      "SubSGD iter. 136/499: loss=5.171012447710815, w0=69.30000000000013, w1=13.71665355752726\n",
      "SubSGD iter. 137/499: loss=2.068786024407551, w0=68.60000000000012, w1=14.225154675267094\n",
      "SubSGD iter. 138/499: loss=3.547808130107896, w0=69.30000000000013, w1=15.058492257826671\n",
      "SubSGD iter. 139/499: loss=5.654078945959636, w0=70.00000000000013, w1=14.319159458382728\n",
      "SubSGD iter. 140/499: loss=0.73436770649473, w0=70.70000000000013, w1=14.923691564236888\n",
      "SubSGD iter. 141/499: loss=2.3303716132887615, w0=70.00000000000013, w1=15.432192681976721\n",
      "SubSGD iter. 142/499: loss=1.6655119333239057, w0=69.30000000000013, w1=16.054979088797012\n",
      "SubSGD iter. 143/499: loss=3.5019727095557016, w0=70.00000000000013, w1=16.678467211083188\n",
      "SubSGD iter. 144/499: loss=1.1681470135971068, w0=70.70000000000013, w1=18.0438366637468\n",
      "SubSGD iter. 145/499: loss=64.84267136099326, w0=71.40000000000013, w1=14.670692986157121\n",
      "SubSGD iter. 146/499: loss=1.8567545336524205, w0=70.70000000000013, w1=15.16037651955371\n",
      "SubSGD iter. 147/499: loss=3.223493410677083, w0=71.40000000000013, w1=14.824013561877633\n",
      "SubSGD iter. 148/499: loss=1.400662285069913, w0=70.70000000000013, w1=15.436811732879045\n",
      "SubSGD iter. 149/499: loss=3.439950441756345, w0=71.40000000000013, w1=16.154975056910235\n",
      "SubSGD iter. 150/499: loss=1.5831717571594481, w0=72.10000000000014, w1=17.167413394776656\n",
      "SubSGD iter. 151/499: loss=0.22573010714595654, w0=72.80000000000014, w1=16.624396933411557\n",
      "SubSGD iter. 152/499: loss=0.9111769701612147, w0=72.10000000000014, w1=16.3741158169495\n",
      "SubSGD iter. 153/499: loss=5.020270200230289, w0=72.80000000000014, w1=15.974658044562922\n",
      "SubSGD iter. 154/499: loss=4.23845358482037, w0=72.10000000000014, w1=15.713945823181058\n",
      "SubSGD iter. 155/499: loss=1.3496250733087223, w0=72.80000000000014, w1=15.689979983377967\n",
      "SubSGD iter. 156/499: loss=0.24854430365207492, w0=73.50000000000014, w1=15.67140052447909\n",
      "SubSGD iter. 157/499: loss=0.8750757207017656, w0=74.20000000000014, w1=15.94153897476876\n",
      "SubSGD iter. 158/499: loss=0.9150617534095566, w0=74.90000000000015, w1=14.964741495826841\n",
      "SubSGD iter. 159/499: loss=0.31661325273500296, w0=75.60000000000015, w1=15.414921242033135\n",
      "SubSGD iter. 160/499: loss=0.2257194424139044, w0=76.30000000000015, w1=16.047195670514824\n",
      "SubSGD iter. 161/499: loss=4.741158268071352, w0=75.60000000000015, w1=15.86884354913501\n",
      "SubSGD iter. 162/499: loss=2.5928331733863885, w0=74.90000000000015, w1=16.069593086184263\n",
      "SubSGD iter. 163/499: loss=0.18382959878108807, w0=75.60000000000015, w1=16.72164998362672\n",
      "SubSGD iter. 164/499: loss=2.451377593474689, w0=74.90000000000015, w1=15.880459815402077\n",
      "SubSGD iter. 165/499: loss=1.2792520040518696, w0=74.20000000000014, w1=15.352403999891427\n",
      "SubSGD iter. 166/499: loss=1.9668867451182237, w0=73.50000000000014, w1=15.553153536940679\n",
      "SubSGD iter. 167/499: loss=4.894701227523939, w0=72.80000000000014, w1=14.595018446038871\n",
      "SubSGD iter. 168/499: loss=1.4880896687556344, w0=72.10000000000014, w1=15.720950859540043\n",
      "SubSGD iter. 169/499: loss=0.10010740452273836, w0=71.40000000000013, w1=14.8797606913154\n",
      "SubSGD iter. 170/499: loss=2.9817989807463405, w0=72.10000000000014, w1=15.494421672445787\n",
      "SubSGD iter. 171/499: loss=2.524042788468126, w0=71.40000000000013, w1=15.879705812773915\n",
      "SubSGD iter. 172/499: loss=3.7196634594743685, w0=70.70000000000013, w1=16.16488030732321\n",
      "SubSGD iter. 173/499: loss=0.9405947751546151, w0=70.00000000000013, w1=15.809852829793384\n",
      "SubSGD iter. 174/499: loss=1.9793052579676207, w0=70.70000000000013, w1=15.015483485302603\n",
      "SubSGD iter. 175/499: loss=0.8047745780709334, w0=71.40000000000013, w1=14.81064996542738\n",
      "SubSGD iter. 176/499: loss=0.9340880663839997, w0=70.70000000000013, w1=15.206086757370386\n",
      "SubSGD iter. 177/499: loss=3.354114204109891, w0=71.40000000000013, w1=15.849016456134182\n",
      "SubSGD iter. 178/499: loss=1.961835113115427, w0=72.10000000000014, w1=15.992347046728698\n",
      "SubSGD iter. 179/499: loss=0.9308136885258165, w0=71.40000000000013, w1=16.17650782504702\n",
      "SubSGD iter. 180/499: loss=1.8001359101585592, w0=72.10000000000014, w1=17.032729877551557\n",
      "SubSGD iter. 181/499: loss=1.312399005149743, w0=72.80000000000014, w1=17.302868327841228\n",
      "SubSGD iter. 182/499: loss=1.4757435182259897, w0=72.10000000000014, w1=16.568592584349428\n",
      "SubSGD iter. 183/499: loss=0.21341591875588506, w0=72.80000000000014, w1=16.67889261781022\n",
      "SubSGD iter. 184/499: loss=5.826216821442149, w0=72.10000000000014, w1=16.622583002764916\n",
      "SubSGD iter. 185/499: loss=0.014407341778547078, w0=72.80000000000014, w1=16.079566541399817\n",
      "SubSGD iter. 186/499: loss=0.3230268180828375, w0=73.50000000000014, w1=17.619628879787005\n",
      "SubSGD iter. 187/499: loss=1.1721802583681296, w0=74.20000000000014, w1=17.436163100736586\n",
      "SubSGD iter. 188/499: loss=1.2195590058694386, w0=73.50000000000014, w1=18.27758161046253\n",
      "SubSGD iter. 189/499: loss=3.470799792917603, w0=74.20000000000014, w1=19.402711570592835\n",
      "SubSGD iter. 190/499: loss=0.19490326754529974, w0=73.50000000000014, w1=19.132573120303164\n",
      "SubSGD iter. 191/499: loss=0.8755430963735762, w0=72.80000000000014, w1=19.75738922011411\n",
      "SubSGD iter. 192/499: loss=0.19611891633208245, w0=73.50000000000014, w1=19.407052286745717\n",
      "SubSGD iter. 193/499: loss=0.4182473338179449, w0=74.20000000000014, w1=18.598938545703785\n",
      "SubSGD iter. 194/499: loss=2.915240341098851, w0=73.50000000000014, w1=18.719443097182825\n",
      "SubSGD iter. 195/499: loss=3.1156915093913753, w0=74.20000000000014, w1=19.844573057313134\n",
      "SubSGD iter. 196/499: loss=3.22453898093654, w0=73.50000000000014, w1=20.52517223496922\n",
      "SubSGD iter. 197/499: loss=1.7032445556550826, w0=72.80000000000014, w1=20.936247419511446\n",
      "SubSGD iter. 198/499: loss=3.624911489296089, w0=72.10000000000014, w1=20.305082079516595\n",
      "SubSGD iter. 199/499: loss=4.6948782060190695, w0=71.40000000000013, w1=20.04436985813473\n",
      "SubSGD iter. 200/499: loss=3.560060262075254, w0=72.10000000000014, w1=19.440603788168215\n",
      "SubSGD iter. 201/499: loss=0.4839583877088991, w0=72.80000000000014, w1=19.00091538308303\n",
      "SubSGD iter. 202/499: loss=0.28827235363495873, w0=73.50000000000014, w1=19.732879976590663\n",
      "SubSGD iter. 203/499: loss=3.27531458495136, w0=72.80000000000014, w1=19.140562015322484\n",
      "SubSGD iter. 204/499: loss=0.02384909439959415, w0=73.50000000000014, w1=19.59074176152878\n",
      "SubSGD iter. 205/499: loss=0.3642034833505754, w0=72.80000000000014, w1=20.20353993253019\n",
      "SubSGD iter. 206/499: loss=2.959217817946417, w0=73.50000000000014, w1=19.26003344899307\n",
      "SubSGD iter. 207/499: loss=0.19720282478242268, w0=72.80000000000014, w1=18.528068855485436\n",
      "SubSGD iter. 208/499: loss=1.6304799531595435, w0=73.50000000000014, w1=17.438273832412214\n",
      "SubSGD iter. 209/499: loss=3.3439320422415406, w0=74.20000000000014, w1=16.226850944486035\n",
      "SubSGD iter. 210/499: loss=0.11591277155496371, w0=74.90000000000015, w1=15.432481599995254\n",
      "SubSGD iter. 211/499: loss=3.351596552582052, w0=75.60000000000015, w1=15.033023827608675\n",
      "SubSGD iter. 212/499: loss=0.41882060753795614, w0=74.90000000000015, w1=16.009821306550595\n",
      "SubSGD iter. 213/499: loss=0.0453099949512108, w0=74.20000000000014, w1=16.033787146353685\n",
      "SubSGD iter. 214/499: loss=1.3837176936807438, w0=74.90000000000015, w1=16.751950470384873\n",
      "SubSGD iter. 215/499: loss=0.18251575560021394, w0=74.20000000000014, w1=17.12753630867144\n",
      "SubSGD iter. 216/499: loss=3.441976456308936, w0=74.90000000000015, w1=16.886556394004792\n",
      "SubSGD iter. 217/499: loss=3.027015546060632, w0=74.20000000000014, w1=16.006826264172314\n",
      "SubSGD iter. 218/499: loss=0.33999026912793795, w0=74.90000000000015, w1=16.09535377766144\n",
      "SubSGD iter. 219/499: loss=4.903003743015386, w0=74.20000000000014, w1=16.375282770097904\n",
      "SubSGD iter. 220/499: loss=1.9689089442530836, w0=73.50000000000014, w1=17.078787688488767\n",
      "SubSGD iter. 221/499: loss=1.088496520186041, w0=74.20000000000014, w1=17.54536981445534\n",
      "SubSGD iter. 222/499: loss=4.997472304641949, w0=73.50000000000014, w1=17.81684999643792\n",
      "SubSGD iter. 223/499: loss=1.263503607339942, w0=72.80000000000014, w1=18.01759953348717\n",
      "SubSGD iter. 224/499: loss=0.20549087039184144, w0=73.50000000000014, w1=17.474583072122073\n",
      "SubSGD iter. 225/499: loss=1.0346221503104935, w0=72.80000000000014, w1=18.00154010789092\n",
      "SubSGD iter. 226/499: loss=1.0414619086333161, w0=73.50000000000014, w1=18.144870698485438\n",
      "SubSGD iter. 227/499: loss=60.057890697657676, w0=74.20000000000014, w1=15.374571001596449\n",
      "SubSGD iter. 228/499: loss=2.351905067585168, w0=73.50000000000014, w1=16.21459857305626\n",
      "SubSGD iter. 229/499: loss=2.1891696564392547, w0=74.20000000000014, w1=17.22727691440903\n",
      "SubSGD iter. 230/499: loss=0.5298914452335453, w0=74.90000000000015, w1=17.850765036695204\n",
      "SubSGD iter. 231/499: loss=1.4070370462782762, w0=74.20000000000014, w1=17.507052415511815\n",
      "SubSGD iter. 232/499: loss=0.5806848262244344, w0=73.50000000000014, w1=17.711885935387038\n",
      "SubSGD iter. 233/499: loss=3.709336869211228, w0=74.20000000000014, w1=16.85803966496177\n",
      "SubSGD iter. 234/499: loss=3.0680423723729753, w0=74.90000000000015, w1=16.427708076501034\n",
      "SubSGD iter. 235/499: loss=0.3584123941657751, w0=75.60000000000015, w1=17.044095025338283\n",
      "SubSGD iter. 236/499: loss=3.6135557634003277, w0=74.90000000000015, w1=16.689067547808456\n",
      "SubSGD iter. 237/499: loss=1.4907755789889663, w0=75.60000000000015, w1=16.35270459013238\n",
      "SubSGD iter. 238/499: loss=1.3141484639272818, w0=74.90000000000015, w1=14.987335137468769\n",
      "SubSGD iter. 239/499: loss=1.3476600567921508, w0=75.60000000000015, w1=14.1334888670435\n",
      "SubSGD iter. 240/499: loss=0.9894188911047799, w0=74.90000000000015, w1=14.904311933111687\n",
      "SubSGD iter. 241/499: loss=3.462604284918566, w0=74.20000000000014, w1=15.529128032922634\n",
      "SubSGD iter. 242/499: loss=4.207942120671589, w0=74.90000000000015, w1=15.773440756631768\n",
      "SubSGD iter. 243/499: loss=0.6464708491787334, w0=75.60000000000015, w1=16.389827705469017\n",
      "SubSGD iter. 244/499: loss=2.628033537040068, w0=76.30000000000015, w1=16.586172298986245\n",
      "SubSGD iter. 245/499: loss=2.610032580423937, w0=75.60000000000015, w1=17.394286040028177\n",
      "SubSGD iter. 246/499: loss=1.4593227608827917, w0=76.30000000000015, w1=18.007278537211736\n",
      "SubSGD iter. 247/499: loss=6.366974301866641, w0=75.60000000000015, w1=17.74656631582987\n",
      "SubSGD iter. 248/499: loss=1.9860138588544487, w0=76.30000000000015, w1=17.16225377828398\n",
      "SubSGD iter. 249/499: loss=2.406684401198909, w0=75.60000000000015, w1=16.283081466053172\n",
      "SubSGD iter. 250/499: loss=3.537986442259843, w0=74.90000000000015, w1=14.920330070661425\n",
      "SubSGD iter. 251/499: loss=0.8685456186944798, w0=75.60000000000015, w1=14.366222996664844\n",
      "SubSGD iter. 252/499: loss=1.6762374556394093, w0=74.90000000000015, w1=13.160206706894396\n",
      "SubSGD iter. 253/499: loss=0.8968739765221727, w0=75.60000000000015, w1=13.61038645310069\n",
      "SubSGD iter. 254/499: loss=4.62215527990039, w0=74.90000000000015, w1=14.05058170780766\n",
      "SubSGD iter. 255/499: loss=0.29406382977500556, w0=74.20000000000014, w1=13.436667294430078\n",
      "SubSGD iter. 256/499: loss=0.5898330353335481, w0=73.50000000000014, w1=13.326367260969286\n",
      "SubSGD iter. 257/499: loss=0.8546204596330256, w0=74.20000000000014, w1=14.05138745105009\n",
      "SubSGD iter. 258/499: loss=3.6675003884440507, w0=73.50000000000014, w1=14.603358882987768\n",
      "SubSGD iter. 259/499: loss=55.15322430809677, w0=74.20000000000014, w1=11.23021520539809\n",
      "SubSGD iter. 260/499: loss=1.31386259009777, w0=73.50000000000014, w1=11.60580104368466\n",
      "SubSGD iter. 261/499: loss=0.3639914113378353, w0=72.80000000000014, w1=11.355519927222604\n",
      "SubSGD iter. 262/499: loss=4.063414862998883, w0=72.10000000000014, w1=12.195547498682414\n",
      "SubSGD iter. 263/499: loss=2.3184577999430402, w0=72.80000000000014, w1=12.21085516539455\n",
      "SubSGD iter. 264/499: loss=3.290994415418691, w0=72.10000000000014, w1=12.361311841845678\n",
      "SubSGD iter. 265/499: loss=3.676393944417047, w0=71.40000000000013, w1=12.919435545594718\n",
      "SubSGD iter. 266/499: loss=1.9183961128532339, w0=70.70000000000013, w1=13.489395670130703\n",
      "SubSGD iter. 267/499: loss=1.6914460454736968, w0=70.00000000000013, w1=13.065854417076688\n",
      "SubSGD iter. 268/499: loss=1.2953989772873271, w0=70.70000000000013, w1=13.658172378344865\n",
      "SubSGD iter. 269/499: loss=1.5009057598367264, w0=71.40000000000013, w1=14.106831417129575\n",
      "SubSGD iter. 270/499: loss=2.560649472715589, w0=72.10000000000014, w1=13.252985146704306\n",
      "SubSGD iter. 271/499: loss=2.932282719295536, w0=71.40000000000013, w1=13.804956578641985\n",
      "SubSGD iter. 272/499: loss=3.704885120902894, w0=72.10000000000014, w1=14.53692117214962\n",
      "SubSGD iter. 273/499: loss=5.426422958383434, w0=72.80000000000014, w1=14.976845615033803\n",
      "SubSGD iter. 274/499: loss=1.9716285275731629, w0=72.10000000000014, w1=15.680350533424665\n",
      "SubSGD iter. 275/499: loss=1.153128297409836, w0=71.40000000000013, w1=14.596475136733364\n",
      "SubSGD iter. 276/499: loss=1.7408007452524608, w0=72.10000000000014, w1=13.91812814075882\n",
      "SubSGD iter. 277/499: loss=2.8313319734555478, w0=72.80000000000014, w1=14.77435019326336\n",
      "SubSGD iter. 278/499: loss=2.083829091032051, w0=73.50000000000014, w1=13.420393299230131\n",
      "SubSGD iter. 279/499: loss=3.433413508728819, w0=72.80000000000014, w1=13.221632433411607\n",
      "SubSGD iter. 280/499: loss=2.7172586651158603, w0=72.10000000000014, w1=13.955746756412596\n",
      "SubSGD iter. 281/499: loss=0.050275139300211436, w0=71.40000000000013, w1=14.160580276287819\n",
      "SubSGD iter. 282/499: loss=2.244499166275375, w0=70.70000000000013, w1=13.737039023233804\n",
      "SubSGD iter. 283/499: loss=4.201378384523977, w0=71.40000000000013, w1=13.212406098522065\n",
      "SubSGD iter. 284/499: loss=3.2136229442547233, w0=72.10000000000014, w1=13.639923183739484\n",
      "SubSGD iter. 285/499: loss=1.1106695749436568, w0=72.80000000000014, w1=14.401280134358553\n",
      "SubSGD iter. 286/499: loss=6.55137433852229, w0=72.10000000000014, w1=14.415035330334042\n",
      "SubSGD iter. 287/499: loss=4.190868742010217, w0=72.80000000000014, w1=15.42771367168681\n",
      "SubSGD iter. 288/499: loss=0.66549295744489, w0=73.50000000000014, w1=15.061792940956412\n",
      "SubSGD iter. 289/499: loss=1.9977710372978237, w0=74.20000000000014, w1=15.793757534464048\n",
      "SubSGD iter. 290/499: loss=0.7546276564961403, w0=74.90000000000015, w1=16.42603196294574\n",
      "SubSGD iter. 291/499: loss=1.7658537271822823, w0=75.60000000000015, w1=16.578925720060322\n",
      "SubSGD iter. 292/499: loss=1.3532532072969161, w0=74.90000000000015, w1=15.745588137500746\n",
      "SubSGD iter. 293/499: loss=1.2283807370065247, w0=74.20000000000014, w1=15.217532321990097\n",
      "SubSGD iter. 294/499: loss=0.08944255188863082, w0=73.50000000000014, w1=15.583453052720495\n",
      "SubSGD iter. 295/499: loss=5.456638056669512, w0=72.80000000000014, w1=14.97804990127651\n",
      "SubSGD iter. 296/499: loss=2.6766598312403715, w0=73.50000000000014, w1=15.00442255190133\n",
      "SubSGD iter. 297/499: loss=1.379938022946554, w0=74.20000000000014, w1=15.656479449343784\n",
      "SubSGD iter. 298/499: loss=3.1712967955290416, w0=73.50000000000014, w1=16.003563434963777\n",
      "SubSGD iter. 299/499: loss=3.945650520711723, w0=74.20000000000014, w1=16.21472782952998\n",
      "SubSGD iter. 300/499: loss=1.9768352553287976, w0=73.50000000000014, w1=16.784687954065966\n",
      "SubSGD iter. 301/499: loss=1.122668300223765, w0=72.80000000000014, w1=16.77826007318762\n",
      "SubSGD iter. 302/499: loss=2.4787992788337654, w0=72.10000000000014, w1=17.325422375421493\n",
      "SubSGD iter. 303/499: loss=0.47465553983039044, w0=71.40000000000013, w1=17.895382499957478\n",
      "SubSGD iter. 304/499: loss=0.2069961118001018, w0=70.70000000000013, w1=17.446723461172766\n",
      "SubSGD iter. 305/499: loss=0.2885847971416098, w0=70.00000000000013, w1=17.181938351981998\n",
      "SubSGD iter. 306/499: loss=5.316943077818465, w0=70.70000000000013, w1=17.378282945499226\n",
      "SubSGD iter. 307/499: loss=3.6674959594770797, w0=71.40000000000013, w1=16.401485466557308\n",
      "SubSGD iter. 308/499: loss=0.27865048340140675, w0=72.10000000000014, w1=15.858469005192209\n",
      "SubSGD iter. 309/499: loss=1.4581460080518482, w0=71.40000000000013, w1=15.362842744723377\n",
      "SubSGD iter. 310/499: loss=3.2830105036959125, w0=72.10000000000014, w1=15.887023296175094\n",
      "SubSGD iter. 311/499: loss=4.480380810787544, w0=72.80000000000014, w1=16.16515026497678\n",
      "SubSGD iter. 312/499: loss=0.7028053547174125, w0=72.10000000000014, w1=16.515487198345173\n",
      "SubSGD iter. 313/499: loss=0.8043917929678841, w0=71.40000000000013, w1=17.08544732288116\n",
      "SubSGD iter. 314/499: loss=1.671784811753298, w0=72.10000000000014, w1=17.173974836370284\n",
      "SubSGD iter. 315/499: loss=0.6423345617739251, w0=71.40000000000013, w1=17.53070035472612\n",
      "SubSGD iter. 316/499: loss=2.9494103084948016, w0=70.70000000000013, w1=18.211299532382206\n",
      "SubSGD iter. 317/499: loss=2.4125806904459424, w0=70.00000000000013, w1=17.127424135690905\n",
      "SubSGD iter. 318/499: loss=0.398895737126459, w0=70.70000000000013, w1=17.37770525215296\n",
      "SubSGD iter. 319/499: loss=2.546598488584074, w0=70.00000000000013, w1=17.657634244589424\n",
      "SubSGD iter. 320/499: loss=4.144015279780795, w0=70.70000000000013, w1=18.270626741772983\n",
      "SubSGD iter. 321/499: loss=1.3535828377298955, w0=71.40000000000013, w1=18.720806487979278\n",
      "SubSGD iter. 322/499: loss=6.572845762174872, w0=72.10000000000014, w1=19.065274734849744\n",
      "SubSGD iter. 323/499: loss=1.8397797914775893, w0=71.40000000000013, w1=18.303917784230674\n",
      "SubSGD iter. 324/499: loss=2.6055539375459915, w0=72.10000000000014, w1=17.504087050167964\n",
      "SubSGD iter. 325/499: loss=4.41932397732824, w0=72.80000000000014, w1=17.715251444734168\n",
      "SubSGD iter. 326/499: loss=4.578467553927766, w0=73.50000000000014, w1=17.365313513253852\n",
      "SubSGD iter. 327/499: loss=0.6040877703651688, w0=74.20000000000014, w1=17.453841026742978\n",
      "SubSGD iter. 328/499: loss=1.472374460901868, w0=73.50000000000014, w1=18.023801151278963\n",
      "SubSGD iter. 329/499: loss=0.15453599329275391, w0=72.80000000000014, w1=17.857994891711467\n",
      "SubSGD iter. 330/499: loss=0.4362674816851211, w0=73.50000000000014, w1=18.308174637917762\n",
      "SubSGD iter. 331/499: loss=0.9349812147745453, w0=74.20000000000014, w1=17.932588799631194\n",
      "SubSGD iter. 332/499: loss=0.3722238370605382, w0=74.90000000000015, w1=18.36010588484861\n",
      "SubSGD iter. 333/499: loss=0.6951703738819575, w0=74.20000000000014, w1=19.248937709015106\n",
      "SubSGD iter. 334/499: loss=5.183877225592546, w0=73.50000000000014, w1=18.82539645596109\n",
      "SubSGD iter. 335/499: loss=1.2622266765153327, w0=72.80000000000014, w1=18.69307292960725\n",
      "SubSGD iter. 336/499: loss=61.49266532245098, w0=73.50000000000014, w1=15.922773232718262\n",
      "SubSGD iter. 337/499: loss=0.9498124417784339, w0=74.20000000000014, w1=15.739307453667843\n",
      "SubSGD iter. 338/499: loss=1.3556829300986024, w0=73.50000000000014, w1=15.005031710176045\n",
      "SubSGD iter. 339/499: loss=2.8484653319348894, w0=74.20000000000014, w1=14.574700121715308\n",
      "SubSGD iter. 340/499: loss=4.367285845675362, w0=74.90000000000015, w1=13.955558966300925\n",
      "SubSGD iter. 341/499: loss=3.647341381268273, w0=74.20000000000014, w1=14.460576698125248\n",
      "SubSGD iter. 342/499: loss=3.5986035404897905, w0=74.90000000000015, w1=14.656921291642476\n",
      "SubSGD iter. 343/499: loss=0.5599499797161158, w0=74.20000000000014, w1=14.043006878264894\n",
      "SubSGD iter. 344/499: loss=4.404192058046341, w0=73.50000000000014, w1=14.068304643653736\n",
      "SubSGD iter. 345/499: loss=1.459596641786682, w0=74.20000000000014, w1=13.812872762552166\n",
      "SubSGD iter. 346/499: loss=0.4852133157024703, w0=73.50000000000014, w1=14.50945751379293\n",
      "SubSGD iter. 347/499: loss=4.520102559624998, w0=72.80000000000014, w1=14.789386506229393\n",
      "SubSGD iter. 348/499: loss=0.9837980443954919, w0=73.50000000000014, w1=14.765420666426301\n",
      "SubSGD iter. 349/499: loss=4.996638961898277, w0=72.80000000000014, w1=15.050595160975595\n",
      "SubSGD iter. 350/499: loss=1.7507703987185579, w0=72.10000000000014, w1=15.62055528551158\n",
      "SubSGD iter. 351/499: loss=1.0324742836428804, w0=71.40000000000013, w1=16.147512321280427\n",
      "SubSGD iter. 352/499: loss=4.778111802962734, w0=72.10000000000014, w1=15.109998127466886\n",
      "SubSGD iter. 353/499: loss=0.723923729031128, w0=71.40000000000013, w1=16.235930540968056\n",
      "SubSGD iter. 354/499: loss=1.7186354980646072, w0=70.70000000000013, w1=16.356435092447096\n",
      "SubSGD iter. 355/499: loss=0.132739365089936, w0=71.40000000000013, w1=15.467603268280604\n",
      "SubSGD iter. 356/499: loss=2.8351512974155675, w0=72.10000000000014, w1=14.913496194284022\n",
      "SubSGD iter. 357/499: loss=2.1043073948726345, w0=71.40000000000013, w1=13.745165393766554\n",
      "SubSGD iter. 358/499: loss=3.4799357370158432, w0=72.10000000000014, w1=14.35982637489694\n",
      "SubSGD iter. 359/499: loss=1.6422577496534387, w0=71.40000000000013, w1=13.191495574379472\n",
      "SubSGD iter. 360/499: loss=0.52130272256057, w0=72.10000000000014, w1=13.796027680233632\n",
      "SubSGD iter. 361/499: loss=1.4170739383521678, w0=72.80000000000014, w1=14.888652194559427\n",
      "SubSGD iter. 362/499: loss=3.782305486206667, w0=72.10000000000014, w1=15.105909198739177\n",
      "SubSGD iter. 363/499: loss=1.446958803172734, w0=72.80000000000014, w1=15.194436712228303\n",
      "SubSGD iter. 364/499: loss=1.2043661366766045, w0=73.50000000000014, w1=15.010970933177884\n",
      "SubSGD iter. 365/499: loss=0.63759122788057, w0=74.20000000000014, w1=14.987005093374792\n",
      "SubSGD iter. 366/499: loss=5.586008096411515, w0=73.50000000000014, w1=15.667604271030875\n",
      "SubSGD iter. 367/499: loss=3.156381236400552, w0=72.80000000000014, w1=16.012781358755873\n",
      "SubSGD iter. 368/499: loss=1.694649031881923, w0=72.10000000000014, w1=14.806765068985426\n",
      "SubSGD iter. 369/499: loss=0.35094913501427527, w0=71.40000000000013, w1=13.444013673593679\n",
      "SubSGD iter. 370/499: loss=3.068850973556522, w0=72.10000000000014, w1=14.239183398711026\n",
      "SubSGD iter. 371/499: loss=3.493976774856044, w0=72.80000000000014, w1=13.843207155489193\n",
      "SubSGD iter. 372/499: loss=2.886172391093453, w0=72.10000000000014, w1=14.468023255300139\n",
      "SubSGD iter. 373/499: loss=1.6532427619904482, w0=72.80000000000014, w1=15.301360837859715\n",
      "SubSGD iter. 374/499: loss=2.854314633803476, w0=72.10000000000014, w1=15.859484541608754\n",
      "SubSGD iter. 375/499: loss=1.3756597994953523, w0=71.40000000000013, w1=14.496733146217007\n",
      "SubSGD iter. 376/499: loss=0.44128826837228985, w0=70.70000000000013, w1=13.440331914838117\n",
      "SubSGD iter. 377/499: loss=2.271727158804154, w0=70.00000000000013, w1=13.975851597664322\n",
      "SubSGD iter. 378/499: loss=4.502320349641678, w0=70.70000000000013, w1=14.50003214911604\n",
      "SubSGD iter. 379/499: loss=1.2827524558817345, w0=71.40000000000013, w1=14.481452690217163\n",
      "SubSGD iter. 380/499: loss=3.2603843813126687, w0=70.70000000000013, w1=14.220740468835299\n",
      "SubSGD iter. 381/499: loss=0.379158837943244, w0=70.00000000000013, w1=14.42149000588455\n",
      "SubSGD iter. 382/499: loss=6.885329471087331, w0=70.70000000000013, w1=14.769457052274964\n",
      "SubSGD iter. 383/499: loss=1.0258420089437728, w0=70.00000000000013, w1=15.472961970665827\n",
      "SubSGD iter. 384/499: loss=0.6499732216055705, w0=69.30000000000013, w1=15.977979702490149\n",
      "SubSGD iter. 385/499: loss=2.791814350826826, w0=70.00000000000013, w1=16.066507215979275\n",
      "SubSGD iter. 386/499: loss=60.42851684295833, w0=70.70000000000013, w1=12.693363538389598\n",
      "SubSGD iter. 387/499: loss=3.8563251444871938, w0=71.40000000000013, w1=13.345420435832052\n",
      "SubSGD iter. 388/499: loss=5.22364467064309, w0=72.10000000000014, w1=12.72627928041767\n",
      "SubSGD iter. 389/499: loss=7.697791675036349, w0=72.80000000000014, w1=13.070747527288137\n",
      "SubSGD iter. 390/499: loss=6.730979547609728, w0=73.50000000000014, w1=14.251552227988034\n",
      "SubSGD iter. 391/499: loss=1.0820952209864885, w0=74.20000000000014, w1=15.084889810547612\n",
      "SubSGD iter. 392/499: loss=5.474594846945788, w0=73.50000000000014, w1=15.35636999253019\n",
      "SubSGD iter. 393/499: loss=2.895699071524124, w0=72.80000000000014, w1=15.703453978150181\n",
      "SubSGD iter. 394/499: loss=1.7272843754981793, w0=73.50000000000014, w1=16.319840926987432\n",
      "SubSGD iter. 395/499: loss=2.9968849685421546, w0=72.80000000000014, w1=16.70512506731556\n",
      "SubSGD iter. 396/499: loss=1.9263133782317112, w0=72.10000000000014, w1=15.799949964128496\n",
      "SubSGD iter. 397/499: loss=0.3251388467419538, w0=72.80000000000014, w1=14.898317699715738\n",
      "SubSGD iter. 398/499: loss=0.3701998029374849, w0=73.50000000000014, w1=14.522731861429168\n",
      "SubSGD iter. 399/499: loss=1.5930122552268742, w0=74.20000000000014, w1=14.538039528141304\n",
      "SubSGD iter. 400/499: loss=4.351072929772801, w0=74.90000000000015, w1=13.918898372726922\n",
      "SubSGD iter. 401/499: loss=1.3765270857090819, w0=75.60000000000015, w1=12.88138417891338\n",
      "SubSGD iter. 402/499: loss=0.0350645444436779, w0=76.30000000000015, w1=13.606404368994184\n",
      "SubSGD iter. 403/499: loss=4.383625632493839, w0=75.60000000000015, w1=14.219202539995596\n",
      "SubSGD iter. 404/499: loss=1.4198389904616562, w0=74.90000000000015, w1=14.167042194465886\n",
      "SubSGD iter. 405/499: loss=3.30641277958901, w0=74.20000000000014, w1=14.975155935507818\n",
      "SubSGD iter. 406/499: loss=0.23149072697164286, w0=73.50000000000014, w1=15.075433034748027\n",
      "SubSGD iter. 407/499: loss=0.6574922997146473, w0=72.80000000000014, w1=14.341157291256227\n",
      "SubSGD iter. 408/499: loss=0.8253247482415702, w0=72.10000000000014, w1=15.125390019295551\n",
      "SubSGD iter. 409/499: loss=0.11311601598954368, w0=71.40000000000013, w1=16.068896502832672\n",
      "SubSGD iter. 410/499: loss=1.1928534358092193, w0=70.70000000000013, w1=16.69371260264362\n",
      "SubSGD iter. 411/499: loss=2.023520886895014, w0=70.00000000000013, w1=16.515360481263805\n",
      "SubSGD iter. 412/499: loss=1.9034115744428703, w0=70.70000000000013, w1=16.480669621922335\n",
      "SubSGD iter. 413/499: loss=0.12906873168174826, w0=71.40000000000013, w1=15.672555880880402\n",
      "SubSGD iter. 414/499: loss=1.8390106097174552, w0=72.10000000000014, w1=16.122735627086698\n",
      "SubSGD iter. 415/499: loss=0.3987961619394724, w0=71.40000000000013, w1=15.030111112760903\n",
      "SubSGD iter. 416/499: loss=2.6619959415645127, w0=72.10000000000014, w1=14.476004038764321\n",
      "SubSGD iter. 417/499: loss=0.7677416467018148, w0=71.40000000000013, w1=15.132885006517284\n",
      "SubSGD iter. 418/499: loss=0.8512756623952242, w0=70.70000000000013, w1=14.637258746048452\n",
      "SubSGD iter. 419/499: loss=0.9796271390708711, w0=71.40000000000013, w1=15.38324439963585\n",
      "SubSGD iter. 420/499: loss=2.6730525822182543, w0=72.10000000000014, w1=15.579764482414351\n",
      "SubSGD iter. 421/499: loss=1.614724810659986, w0=71.40000000000013, w1=14.385025645309925\n",
      "SubSGD iter. 422/499: loss=0.894568526002292, w0=70.70000000000013, w1=15.474820668383146\n",
      "SubSGD iter. 423/499: loss=4.124281843206255, w0=71.40000000000013, w1=16.487499009735913\n",
      "SubSGD iter. 424/499: loss=0.30474478605166055, w0=70.70000000000013, w1=17.2216133327369\n",
      "SubSGD iter. 425/499: loss=1.0197653872550418, w0=71.40000000000013, w1=17.730799176683153\n",
      "SubSGD iter. 426/499: loss=0.10876883942149362, w0=70.70000000000013, w1=17.598475650329313\n",
      "SubSGD iter. 427/499: loss=5.144119578913202, w0=71.40000000000013, w1=17.20249940710748\n",
      "SubSGD iter. 428/499: loss=2.097266751128828, w0=72.10000000000014, w1=17.669081533074056\n",
      "SubSGD iter. 429/499: loss=0.2733481572608625, w0=71.40000000000013, w1=17.13938055901194\n",
      "SubSGD iter. 430/499: loss=0.3800032813221996, w0=72.10000000000014, w1=16.32072218920631\n",
      "SubSGD iter. 431/499: loss=0.4077448674570121, w0=72.80000000000014, w1=17.8607845275935\n",
      "SubSGD iter. 432/499: loss=2.6223560075661396, w0=73.50000000000014, w1=17.88715717821832\n",
      "SubSGD iter. 433/499: loss=0.2577639090444279, w0=72.80000000000014, w1=17.68472028817732\n",
      "SubSGD iter. 434/499: loss=2.7321556072823867, w0=73.50000000000014, w1=18.29771278536088\n",
      "SubSGD iter. 435/499: loss=2.7853746254019214, w0=72.80000000000014, w1=17.666547445366028\n",
      "SubSGD iter. 436/499: loss=0.011732730250553658, w0=72.10000000000014, w1=18.485205815171657\n",
      "SubSGD iter. 437/499: loss=5.787056511079484, w0=71.40000000000013, w1=17.538293553429227\n",
      "SubSGD iter. 438/499: loss=2.468489786150542, w0=72.10000000000014, w1=18.062474104880945\n",
      "SubSGD iter. 439/499: loss=0.9803460357950762, w0=71.40000000000013, w1=18.48571352965346\n",
      "SubSGD iter. 440/499: loss=1.5259436924590801, w0=72.10000000000014, w1=19.203876853684648\n",
      "SubSGD iter. 441/499: loss=4.707487524936582, w0=71.40000000000013, w1=18.009138016580224\n",
      "SubSGD iter. 442/499: loss=0.006491970603040187, w0=70.70000000000013, w1=18.621936187581635\n",
      "SubSGD iter. 443/499: loss=1.2431062967064932, w0=71.40000000000013, w1=17.78051767785569\n",
      "SubSGD iter. 444/499: loss=0.7155853757844177, w0=70.70000000000013, w1=18.203757102628206\n",
      "SubSGD iter. 445/499: loss=5.315317490036897, w0=71.40000000000013, w1=17.807780859406375\n",
      "SubSGD iter. 446/499: loss=2.849160710386748, w0=72.10000000000014, w1=18.360986775482488\n",
      "SubSGD iter. 447/499: loss=2.288157889806815, w0=72.80000000000014, w1=17.56115604141978\n",
      "SubSGD iter. 448/499: loss=6.520328115408109, w0=72.10000000000014, w1=17.57491123739527\n",
      "SubSGD iter. 449/499: loss=0.8707232553040605, w0=71.40000000000013, w1=18.199727337206216\n",
      "SubSGD iter. 450/499: loss=4.496739581941007, w0=70.70000000000013, w1=17.031396536688746\n",
      "SubSGD iter. 451/499: loss=2.0126562813171702, w0=71.40000000000013, w1=17.301534986978417\n",
      "SubSGD iter. 452/499: loss=2.043903867681312, w0=70.70000000000013, w1=17.451991663429546\n",
      "SubSGD iter. 453/499: loss=1.0040961543557572, w0=70.00000000000013, w1=16.820826323434694\n",
      "SubSGD iter. 454/499: loss=3.7117979206719056, w0=70.70000000000013, w1=16.565394442333123\n",
      "SubSGD iter. 455/499: loss=3.4375036563292163, w0=70.00000000000013, w1=16.8368746243157\n",
      "SubSGD iter. 456/499: loss=0.15797316821074858, w0=69.30000000000013, w1=17.341892356140022\n",
      "SubSGD iter. 457/499: loss=3.105941434448326, w0=70.00000000000013, w1=16.542061622077313\n",
      "SubSGD iter. 458/499: loss=0.191497642937847, w0=70.70000000000013, w1=16.357900843758994\n",
      "SubSGD iter. 459/499: loss=3.5375228577974127, w0=71.40000000000013, w1=15.803793769762413\n",
      "SubSGD iter. 460/499: loss=0.8964016179189471, w0=72.10000000000014, w1=16.682966081993218\n",
      "SubSGD iter. 461/499: loss=2.994543289255631, w0=72.80000000000014, w1=16.70933873261804\n",
      "SubSGD iter. 462/499: loss=0.693209216161403, w0=72.10000000000014, w1=17.598170556784535\n",
      "SubSGD iter. 463/499: loss=4.963480334992894, w0=71.40000000000013, w1=17.049776053026722\n",
      "SubSGD iter. 464/499: loss=1.659109842702442, w0=72.10000000000014, w1=17.319914503316394\n",
      "SubSGD iter. 465/499: loss=4.998893202724005, w0=71.40000000000013, w1=16.373002241573964\n",
      "SubSGD iter. 466/499: loss=1.3521682167775033, w0=70.70000000000013, w1=16.924973673511644\n",
      "SubSGD iter. 467/499: loss=2.6138588178390663, w0=71.40000000000013, w1=16.892544665744285\n",
      "SubSGD iter. 468/499: loss=1.3474902027652789, w0=70.70000000000013, w1=15.987369562557221\n",
      "SubSGD iter. 469/499: loss=2.8245951091104935, w0=70.00000000000013, w1=16.267298554993683\n",
      "SubSGD iter. 470/499: loss=3.0726094202863052, w0=70.70000000000013, w1=16.88195953612407\n",
      "SubSGD iter. 471/499: loss=3.9220311165941553, w0=71.40000000000013, w1=16.30894945310945\n",
      "SubSGD iter. 472/499: loss=0.8248408190193288, w0=70.70000000000013, w1=15.704417347255289\n",
      "SubSGD iter. 473/499: loss=5.529187158176896, w0=71.40000000000013, w1=15.30495957486871\n",
      "SubSGD iter. 474/499: loss=5.182821237900903, w0=72.10000000000014, w1=14.922833590318374\n",
      "SubSGD iter. 475/499: loss=2.681345519071172, w0=71.40000000000013, w1=15.308117730646503\n",
      "SubSGD iter. 476/499: loss=3.3704421429929, w0=72.10000000000014, w1=15.334490381271323\n",
      "SubSGD iter. 477/499: loss=0.8113460393019096, w0=72.80000000000014, w1=15.536927271312322\n",
      "SubSGD iter. 478/499: loss=1.2492484918478652, w0=73.50000000000014, w1=15.353461492261903\n",
      "SubSGD iter. 479/499: loss=1.9389391254387647, w0=72.80000000000014, w1=15.01823343695865\n",
      "SubSGD iter. 480/499: loss=4.4045601609400435, w0=73.50000000000014, w1=14.636107452408314\n",
      "SubSGD iter. 481/499: loss=0.06143697187552988, w0=74.20000000000014, w1=15.72873196673411\n",
      "SubSGD iter. 482/499: loss=7.238331938449189, w0=73.50000000000014, w1=15.7424871627096\n",
      "SubSGD iter. 483/499: loss=2.453589886250313, w0=72.80000000000014, w1=14.547748325605173\n",
      "SubSGD iter. 484/499: loss=2.0080950633691117, w0=73.50000000000014, w1=16.08781066399236\n",
      "SubSGD iter. 485/499: loss=1.7331431392946257, w0=72.80000000000014, w1=15.495492702724183\n",
      "SubSGD iter. 486/499: loss=0.5974948143387735, w0=72.10000000000014, w1=15.363169176370345\n",
      "SubSGD iter. 487/499: loss=0.48315713171592733, w0=71.40000000000013, w1=16.452964199443564\n",
      "SubSGD iter. 488/499: loss=1.5880648820117074, w0=72.10000000000014, w1=16.90314394564986\n",
      "SubSGD iter. 489/499: loss=1.8747652992202717, w0=72.80000000000014, w1=17.546073644413653\n",
      "SubSGD iter. 490/499: loss=0.8975223187890258, w0=72.10000000000014, w1=17.90279916276949\n",
      "SubSGD iter. 491/499: loss=2.0263917936534774, w0=72.80000000000014, w1=17.10296842870678\n",
      "SubSGD iter. 492/499: loss=3.556183208289582, w0=72.10000000000014, w1=16.445785725511797\n",
      "SubSGD iter. 493/499: loss=1.6734722140270897, w0=71.40000000000013, w1=16.997757157449477\n",
      "SubSGD iter. 494/499: loss=6.838867511917801, w0=72.10000000000014, w1=16.378616002035095\n",
      "SubSGD iter. 495/499: loss=0.304214029112849, w0=72.80000000000014, w1=16.173782482159872\n",
      "SubSGD iter. 496/499: loss=4.7199639585069875, w0=73.50000000000014, w1=15.791656497609537\n",
      "SubSGD iter. 497/499: loss=0.7035963008506769, w0=74.20000000000014, w1=15.880184011098663\n",
      "SubSGD iter. 498/499: loss=2.5158335274614743, w0=73.50000000000014, w1=15.384557750629831\n",
      "SubSGD iter. 499/499: loss=1.1657841521464753, w0=72.80000000000014, w1=15.92757421199493\n",
      "SubSGD: execution time=0.043 seconds\n"
     ]
    }
   ],
   "source": [
    "# Define the parameters of the algorithm.\n",
    "max_iters = 500\n",
    "gamma = 0.7\n",
    "batch_size = 1\n",
    "\n",
    "# Initialization\n",
    "w_initial = np.array([0, 0])\n",
    "\n",
    "# Start SubSGD.\n",
    "start_time = datetime.datetime.now()\n",
    "subsgd_losses, subsgd_ws = stochastic_subgradient_descent(\n",
    "    y, tx, w_initial, batch_size, max_iters, gamma\n",
    ")\n",
    "end_time = datetime.datetime.now()\n",
    "\n",
    "# Print result\n",
    "exection_time = (end_time - start_time).total_seconds()\n",
    "print(\"SubSGD: execution time={t:.3f} seconds\".format(t=exection_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d00008acd6fe44d3b59fa3d2cc64a195",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=1, description='n_iter', max=501, min=1), Output()), _dom_classes=('widg…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.plot_figure(n_iter)>"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ipywidgets import IntSlider, interact\n",
    "\n",
    "\n",
    "def plot_figure(n_iter):\n",
    "    fig = gradient_descent_visualization(\n",
    "        subsgd_losses,\n",
    "        subsgd_ws,\n",
    "        grid_losses,\n",
    "        grid_w0,\n",
    "        grid_w1,\n",
    "        mean_x,\n",
    "        std_x,\n",
    "        height,\n",
    "        weight,\n",
    "        n_iter,\n",
    "    )\n",
    "    fig.set_size_inches(10.0, 6.0)\n",
    "\n",
    "\n",
    "interact(plot_figure, n_iter=IntSlider(min=1, max=len(subsgd_ws)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
