{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Useful starting lines\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "from helpers import *\n",
    "\n",
    "height, weight, gender = load_data(sub_sample=False, add_outlier=False)\n",
    "x, mean_x, std_x = standardize(height)\n",
    "y, tx = build_model_data(x, weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10000,), (10000, 2))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape, tx.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NB: throughout this laboratory the data has the following format: \n",
    "  * there are **N = 10000** data entries\n",
    "  * **y** represents the column vector containing weight information -- that which we wish to predict/the output (see also the first page of $\\texttt{exercise02.pdf}$). Its **shape** is **(N,)**.\n",
    "  * **tx** represents the matrix $\\tilde{X}$ formed by laterally concatenating a column vector of 1s to the column vector of height information -- the input data (see also the first page of $\\texttt{exercise02.pdf}$). Its **shape** is **(N,2)**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Computing the Cost Function\n",
    "Fill in the `compute_loss` function below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_loss(y, tx, w, MSE = True):\n",
    "    \"\"\"Calculate the loss using either MSE or MAE.\n",
    "\n",
    "    Args:\n",
    "        y: numpy array of shape=(N, )\n",
    "        tx: numpy array of shape=(N,2)\n",
    "        w: numpy array of shape=(2,). The vector of model parameters.\n",
    "\n",
    "    Returns:\n",
    "        the value of the loss (a scalar), corresponding to the input parameters w.\n",
    "    \"\"\"\n",
    "    e = y - tx @ w\n",
    "    if MSE:\n",
    "        loss = 1/(2*len(y)) *np.linalg.norm(e)**2\n",
    "    else:\n",
    "        loss = 1/(2*len(y)) * sum(abs(e))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35.6469610010525"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = [2,1]\n",
    "loss = compute_loss(y, tx, w, MSE=False)\n",
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Grid Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fill in the function `grid_search()` below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from costs import *\n",
    "\n",
    "\n",
    "def grid_search(y, tx, grid_w0, grid_w1):\n",
    "    \"\"\"Algorithm for grid search.\n",
    "\n",
    "    Args:\n",
    "        y: numpy array of shape=(N, )\n",
    "        tx: numpy array of shape=(N,2)\n",
    "        grid_w0: numpy array of shape=(num_grid_pts_w0, ). A 1D array containing num_grid_pts_w0 values of parameter w0 to be tested in the grid search.\n",
    "        grid_w1: numpy array of shape=(num_grid_pts_w1, ). A 1D array containing num_grid_pts_w1 values of parameter w1 to be tested in the grid search.\n",
    "\n",
    "    Returns:\n",
    "        losses: numpy array of shape=(num_grid_pts_w0, num_grid_pts_w1). A 2D array containing the loss value for each combination of w0 and w1\n",
    "    \"\"\"\n",
    "\n",
    "    losses = np.zeros((len(grid_w0), len(grid_w1)))\n",
    "    for i in range(len(grid_w0)):\n",
    "        for j in range(len(grid_w1)):\n",
    "            w = [grid_w0[i], grid_w1[j]]\n",
    "            losses[i][j] = compute_loss(y, tx,w,)\n",
    "    return losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us play with the grid search demo now!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid Search: loss*=15.765788547059048, w0*=72.88135593220338, w1*=12.711864406779654, execution time=0.381 seconds\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from grid_search import generate_w, get_best_parameters\n",
    "from plots import grid_visualization\n",
    "\n",
    "# Generate the grid of parameters to be swept\n",
    "grid_w0, grid_w1 = generate_w(num_intervals=60)\n",
    "\n",
    "# Start the grid search\n",
    "start_time = datetime.datetime.now()\n",
    "grid_losses = grid_search(y, tx, grid_w0, grid_w1)\n",
    "\n",
    "# Select the best combinaison\n",
    "loss_star, w0_star, w1_star = get_best_parameters(grid_w0, grid_w1, grid_losses)\n",
    "end_time = datetime.datetime.now()\n",
    "execution_time = (end_time - start_time).total_seconds()\n",
    "\n",
    "# Print the results\n",
    "print(\n",
    "    \"Grid Search: loss*={l}, w0*={w0}, w1*={w1}, execution time={t:.3f} seconds\".format(\n",
    "        l=loss_star, w0=w0_star, w1=w1_star, t=execution_time\n",
    "    )\n",
    ")\n",
    "\n",
    "# Plot the results\n",
    "fig = grid_visualization(grid_losses, grid_w0, grid_w1, mean_x, std_x, height, weight)\n",
    "fig.set_size_inches(10.0, 6.0)\n",
    "fig.savefig(\"grid_plot\")  # Optional saving"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, please fill in the functions `compute_gradient` below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_gradient(y, tx, w):\n",
    "    \"\"\"Computes the gradient at w.\n",
    "\n",
    "    Args:\n",
    "        y: numpy array of shape=(N, )\n",
    "        tx: numpy array of shape=(N,2)\n",
    "        w: numpy array of shape=(2, ). The vector of model parameters.\n",
    "\n",
    "    Returns:\n",
    "        An numpy array of shape (2, ) (same shape as w), containing the gradient of the loss at w.\n",
    "    \"\"\"\n",
    "    return -1/len(y) * (tx.T @ (y - tx @ w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The gradient using w0 is: [26.706  6.52 ] and using w1 is: [-23.294  -3.48 ]\n"
     ]
    }
   ],
   "source": [
    "w0 = [100,20]\n",
    "w1 = [50,10]\n",
    "result_w0 = compute_gradient(y,tx,w0)\n",
    "result_w1 = compute_gradient(y,tx,w1)\n",
    "np.set_printoptions(precision=3)\n",
    "print(f'The gradient using w0 is: {result_w0} and using w1 is: {result_w1}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please fill in the functions `gradient_descent` below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(y, tx, initial_w, max_iters, gamma):\n",
    "    \"\"\"The Gradient Descent (GD) algorithm.\n",
    "\n",
    "    Args:\n",
    "        y: numpy array of shape=(N, )\n",
    "        tx: numpy array of shape=(N,2)\n",
    "        initial_w: numpy array of shape=(2, ). The initial guess (or the initialization) for the model parameters\n",
    "        max_iters: a scalar denoting the total number of iterations of GD\n",
    "        gamma: a scalar denoting the stepsize\n",
    "\n",
    "    Returns:\n",
    "        losses: a list of length max_iters containing the loss value (scalar) for each iteration of GD\n",
    "        ws: a list of length max_iters containing the model parameters as numpy arrays of shape (2, ), for each iteration of GD\n",
    "    \"\"\"\n",
    "    # Define parameters to store w and loss\n",
    "    ws = [initial_w]\n",
    "    losses = []\n",
    "    w = initial_w\n",
    "    for n_iter in range(max_iters):\n",
    "        loss = compute_loss(y,tx,w)\n",
    "        w = w - gamma * compute_gradient(y,tx,w)\n",
    "        # store w and loss\n",
    "        ws.append(w)\n",
    "        losses.append(loss)\n",
    "        print(\n",
    "            \"GD iter. {bi}/{ti}: loss={l}, w0={w0}, w1={w1}\".format(\n",
    "                bi=n_iter, ti=max_iters - 1, l=loss, w0=w[0], w1=w[1]\n",
    "            )\n",
    "        )\n",
    "\n",
    "    return losses, ws"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test your gradient descent function through gradient descent demo shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GD iter. 0/49: loss=1062606.4462798766, w0=-34.03547019810537, w1=112.13174119148891\n",
      "GD iter. 1/49: loss=10641.29649178879, w0=62.56098278208415, w1=23.344915310638783\n",
      "GD iter. 2/49: loss=121.64499390802628, w0=72.2206280801031, w1=14.466232722553986\n",
      "GD iter. 3/49: loss=16.448478929221324, w0=73.18659260990498, w1=13.578364463745542\n",
      "GD iter. 4/49: loss=15.39651377943332, w0=73.28318906288517, w1=13.489577637864699\n",
      "GD iter. 5/49: loss=15.385994127935446, w0=73.29284870818319, w1=13.480698955276614\n",
      "GD iter. 6/49: loss=15.385888931420459, w0=73.29381467271298, w1=13.479811087017804\n",
      "GD iter. 7/49: loss=15.38588787945531, w0=73.29391126916597, w1=13.479722300191924\n",
      "GD iter. 8/49: loss=15.385887868935662, w0=73.29392092881127, w1=13.479713421509336\n",
      "GD iter. 9/49: loss=15.385887868830464, w0=73.29392189477579, w1=13.479712533641077\n",
      "GD iter. 10/49: loss=15.385887868829416, w0=73.29392199137226, w1=13.479712444854252\n",
      "GD iter. 11/49: loss=15.385887868829403, w0=73.29392200103189, w1=13.47971243597557\n",
      "GD iter. 12/49: loss=15.385887868829398, w0=73.29392200199786, w1=13.4797124350877\n",
      "GD iter. 13/49: loss=15.385887868829398, w0=73.29392200209445, w1=13.479712434998914\n",
      "GD iter. 14/49: loss=15.385887868829398, w0=73.29392200210411, w1=13.479712434990036\n",
      "GD iter. 15/49: loss=15.385887868829403, w0=73.29392200210508, w1=13.479712434989148\n",
      "GD iter. 16/49: loss=15.385887868829403, w0=73.29392200210518, w1=13.47971243498906\n",
      "GD iter. 17/49: loss=15.385887868829398, w0=73.29392200210519, w1=13.47971243498905\n",
      "GD iter. 18/49: loss=15.385887868829398, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 19/49: loss=15.385887868829398, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 20/49: loss=15.385887868829398, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 21/49: loss=15.385887868829398, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 22/49: loss=15.385887868829398, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 23/49: loss=15.385887868829398, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 24/49: loss=15.385887868829398, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 25/49: loss=15.385887868829398, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 26/49: loss=15.385887868829398, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 27/49: loss=15.385887868829398, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 28/49: loss=15.385887868829398, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 29/49: loss=15.385887868829398, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 30/49: loss=15.385887868829398, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 31/49: loss=15.385887868829398, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 32/49: loss=15.385887868829398, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 33/49: loss=15.385887868829398, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 34/49: loss=15.385887868829398, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 35/49: loss=15.385887868829398, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 36/49: loss=15.385887868829398, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 37/49: loss=15.385887868829398, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 38/49: loss=15.385887868829398, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 39/49: loss=15.385887868829398, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 40/49: loss=15.385887868829398, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 41/49: loss=15.385887868829398, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 42/49: loss=15.385887868829398, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 43/49: loss=15.385887868829398, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 44/49: loss=15.385887868829398, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 45/49: loss=15.385887868829398, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 46/49: loss=15.385887868829398, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 47/49: loss=15.385887868829398, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 48/49: loss=15.385887868829398, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 49/49: loss=15.385887868829398, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD: execution time=0.007 seconds\n"
     ]
    }
   ],
   "source": [
    "# from gradient_descent import *\n",
    "from plots import gradient_descent_visualization\n",
    "\n",
    "# Define the parameters of the algorithm.\n",
    "max_iters = 50\n",
    "gamma = 0.9\n",
    "\n",
    "# Initialization\n",
    "w_initial = np.array([-1000,1000])\n",
    "\n",
    "# Start gradient descent.\n",
    "start_time = datetime.datetime.now()\n",
    "gd_losses, gd_ws = gradient_descent(y, tx, w_initial, max_iters, gamma)\n",
    "end_time = datetime.datetime.now()\n",
    "\n",
    "# Print result\n",
    "exection_time = (end_time - start_time).total_seconds()\n",
    "print(\"GD: execution time={t:.3f} seconds\".format(t=exection_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66e03d79c8214968b09c10cf92d540f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=1, description='n_iter', max=51, min=1), Output()), _dom_classes=('widge"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.plot_figure(n_iter)>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Time Visualization\n",
    "from ipywidgets import IntSlider, interact\n",
    "\n",
    "\n",
    "def plot_figure(n_iter):\n",
    "    fig = gradient_descent_visualization(\n",
    "        gd_losses,\n",
    "        gd_ws,\n",
    "        grid_losses,\n",
    "        grid_w0,\n",
    "        grid_w1,\n",
    "        mean_x,\n",
    "        std_x,\n",
    "        height,\n",
    "        weight,\n",
    "        n_iter,\n",
    "    )\n",
    "    fig.set_size_inches(10.0, 6.0)\n",
    "\n",
    "\n",
    "interact(plot_figure, n_iter=IntSlider(min=1, max=len(gd_ws)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 4. Stochastic gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_stoch_gradient(y, tx, w):\n",
    "    \"\"\"Compute a stochastic gradient at w from a data sample batch of size B, where B < N, and their corresponding labels.\n",
    "\n",
    "    Args:\n",
    "        y: numpy array of shape=(B, )\n",
    "        tx: numpy array of shape=(B,2)\n",
    "        w: numpy array of shape=(2, ). The vector of model parameters.\n",
    "\n",
    "    Returns:\n",
    "        A numpy array of shape (2, ) (same shape as w), containing the stochastic gradient of the loss at w.\n",
    "    \"\"\"\n",
    "\n",
    "    # ***************************************************\n",
    "    # INSERT YOUR CODE HERE\n",
    "    # TODO: implement stochastic gradient computation. It's the same as the usual gradient.\n",
    "    return -1/len(y) * (tx.T @ (y - tx @ w))\n",
    "    # ***************************************************\n",
    "\n",
    "\n",
    "def stochastic_gradient_descent(y, tx, initial_w, batch_size, max_iters, gamma):\n",
    "    \"\"\"The Stochastic Gradient Descent algorithm (SGD).\n",
    "\n",
    "    Args:\n",
    "        y: numpy array of shape=(N, )\n",
    "        tx: numpy array of shape=(N,2)\n",
    "        initial_w: numpy array of shape=(2, ). The initial guess (or the initialization) for the model parameters\n",
    "        batch_size: a scalar denoting the number of data points in a mini-batch used for computing the stochastic gradient\n",
    "        max_iters: a scalar denoting the total number of iterations of SGD\n",
    "        gamma: a scalar denoting the stepsize\n",
    "\n",
    "    Returns:\n",
    "        losses: a list of length max_iters containing the loss value (scalar) for each iteration of SGD\n",
    "        ws: a list of length max_iters containing the model parameters as numpy arrays of shape (2, ), for each iteration of SGD\n",
    "    \"\"\"\n",
    "\n",
    "    # Define parameters to store w and loss\n",
    "    ws = [initial_w]\n",
    "    losses = []\n",
    "    w = initial_w\n",
    "\n",
    "    for n_iter in range(max_iters):\n",
    "        # ***************************************************\n",
    "        # INSERT YOUR CODE HERE\n",
    "        # TODO: implement stochastic gradient descent.\n",
    "        for y_batched, tx_batched in batch_iter(y=y,tx=tx,batch_size=batch_size):\n",
    "            loss = compute_loss(y_batched,tx_batched,w)\n",
    "            w = w - gamma * compute_stoch_gradient(y_batched,tx_batched,w)\n",
    "        # ***************************************************\n",
    "        # store w and loss\n",
    "        ws.append(w)\n",
    "        losses.append(loss)\n",
    "        print(\n",
    "            \"SGD iter. {bi}/{ti}: loss={l}, w0={w0}, w1={w1}\".format(\n",
    "                bi=n_iter, ti=max_iters - 1, l=loss, w0=w[0], w1=w[1]\n",
    "            )\n",
    "        )\n",
    "    return losses, ws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD iter. 0/49: loss=4474.061199117087, w0=9.459451568793074, w1=18.39043569151485\n",
      "SGD iter. 1/49: loss=3048.19308045315, w0=17.267387378535815, w1=13.953924651189439\n",
      "SGD iter. 2/49: loss=1658.9196280477036, w0=23.027456176818877, w1=9.23843714778819\n",
      "SGD iter. 3/49: loss=1047.9698562938822, w0=27.605599591553464, w1=5.489050124728406\n",
      "SGD iter. 4/49: loss=992.0956857180238, w0=32.06002589741603, w1=6.033186267656118\n",
      "SGD iter. 5/49: loss=232.33138775234477, w0=34.215629700309066, w1=1.726335682422861\n",
      "SGD iter. 6/49: loss=1006.9630895479743, w0=38.703308587101155, w1=3.001387541639837\n",
      "SGD iter. 7/49: loss=881.6461638113914, w0=42.90246603547432, w1=7.3946502124567\n",
      "SGD iter. 8/49: loss=89.986211796291, w0=44.244004046835094, w1=6.1216679495218935\n",
      "SGD iter. 9/49: loss=957.6501661956216, w0=48.62041848378144, w1=12.364248368942963\n",
      "SGD iter. 10/49: loss=125.21943820694389, w0=50.202944554384665, w1=12.59211892643459\n",
      "SGD iter. 11/49: loss=68.28941363919074, w0=51.37161399985837, w1=10.114673948037312\n",
      "SGD iter. 12/49: loss=281.20001047277054, w0=53.743111461264434, w1=10.815731164631476\n",
      "SGD iter. 13/49: loss=178.15939014419953, w0=55.630752264723604, w1=7.942562347896384\n",
      "SGD iter. 14/49: loss=88.52924484847848, w0=56.96138553387389, w1=6.643625379923558\n",
      "SGD iter. 15/49: loss=18.498347497915507, w0=57.569634619330095, w1=6.293286839338163\n",
      "SGD iter. 16/49: loss=103.39846750126948, w0=59.00767820351849, w1=5.706981590298466\n",
      "SGD iter. 17/49: loss=16.49684162722192, w0=59.58207948532802, w1=5.112903033467446\n",
      "SGD iter. 18/49: loss=252.79283044964254, w0=61.830602691566476, w1=6.218925070806417\n",
      "SGD iter. 19/49: loss=20.082051077810917, w0=62.46435423717107, w1=5.868645932600047\n",
      "SGD iter. 20/49: loss=0.12863754694603882, w0=62.515076529498224, w1=5.8586001249537585\n",
      "SGD iter. 21/49: loss=11.85187063065777, w0=62.028211648229146, w1=5.88116975747044\n",
      "SGD iter. 22/49: loss=44.776008534517615, w0=62.97453092346893, w1=5.292296222979154\n",
      "SGD iter. 23/49: loss=114.02158636782605, w0=64.48464076296953, w1=6.880504757451259\n",
      "SGD iter. 24/49: loss=2.6135484462916674, w0=64.71326921466755, w1=6.976534204723898\n",
      "SGD iter. 25/49: loss=56.23328045158825, w0=65.77377174131789, w1=7.446297624734345\n",
      "SGD iter. 26/49: loss=10.557399691515062, w0=66.23328016760657, w1=7.189220529736289\n",
      "SGD iter. 27/49: loss=79.0383952698403, w0=67.49056609586505, w1=7.670850308369369\n",
      "SGD iter. 28/49: loss=32.269494546196135, w0=66.68720447683914, w1=8.748852836937425\n",
      "SGD iter. 29/49: loss=153.3888468462261, w0=68.43871152419138, w1=11.003200476363522\n",
      "SGD iter. 30/49: loss=77.02860987367457, w0=69.67990941231136, w1=13.183642725295645\n",
      "SGD iter. 31/49: loss=2.066247742065468, w0=69.88319481474181, w1=13.181405347480535\n",
      "SGD iter. 32/49: loss=44.992584942059146, w0=70.83179994799863, w1=13.559069637458665\n",
      "SGD iter. 33/49: loss=20.627501742947498, w0=71.47410052783563, w1=14.870205937659376\n",
      "SGD iter. 34/49: loss=0.09966515245242716, w0=71.42945410525724, w1=14.845660697348631\n",
      "SGD iter. 35/49: loss=0.0385077426248673, w0=71.45720576921632, w1=14.811931587018135\n",
      "SGD iter. 36/49: loss=19.635842094878864, w0=72.08387700830231, w1=14.261649039432502\n",
      "SGD iter. 37/49: loss=7.757624059463352, w0=72.47777100570423, w1=13.674686550216856\n",
      "SGD iter. 38/49: loss=18.871122336812178, w0=73.09211817688372, w1=13.124567499263488\n",
      "SGD iter. 39/49: loss=27.87275433417717, w0=73.83874732625009, w1=14.094564338928869\n",
      "SGD iter. 40/49: loss=24.78700551572688, w0=74.54283546726266, w1=13.265195016298671\n",
      "SGD iter. 41/49: loss=62.85530410914956, w0=73.42162804569296, w1=12.505782991626322\n",
      "SGD iter. 42/49: loss=15.074166018418406, w0=72.87255307779843, w1=12.75400330534588\n",
      "SGD iter. 43/49: loss=11.628554580667956, w0=72.39029682681421, w1=12.605028145048397\n",
      "SGD iter. 44/49: loss=3.824976298187982, w0=72.11371135003758, w1=12.553252182072825\n",
      "SGD iter. 45/49: loss=0.06272822604189342, w0=72.14913118234715, w1=12.58485566510709\n",
      "SGD iter. 46/49: loss=14.136768122828393, w0=72.68085983726107, w1=12.466154539549924\n",
      "SGD iter. 47/49: loss=0.246057748540087, w0=72.6107088930707, w1=12.398992187476798\n",
      "SGD iter. 48/49: loss=37.64446830883914, w0=71.74301691651635, w1=11.327377219763266\n",
      "SGD iter. 49/49: loss=7.698587456100792, w0=72.13540925732083, w1=11.414280259201774\n",
      "SGD: execution time=0.009 seconds\n"
     ]
    }
   ],
   "source": [
    "# from stochastic_gradient_descent import *\n",
    "\n",
    "# Define the parameters of the algorithm.\n",
    "max_iters = 50\n",
    "gamma = 0.1\n",
    "batch_size = 1\n",
    "\n",
    "# Initialization\n",
    "w_initial = np.array([0, 0])\n",
    "\n",
    "# Start SGD.\n",
    "start_time = datetime.datetime.now()\n",
    "sgd_losses, sgd_ws = stochastic_gradient_descent(\n",
    "    y, tx, w_initial, batch_size, max_iters, gamma\n",
    ")\n",
    "end_time = datetime.datetime.now()\n",
    "\n",
    "# Print result\n",
    "exection_time = (end_time - start_time).total_seconds()\n",
    "print(\"SGD: execution time={t:.3f} seconds\".format(t=exection_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ec009a1b54b4b3dbf931743ad88fe8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=1, description='n_iter', max=51, min=1), Output()), _dom_classes=('widge"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.plot_figure(n_iter)>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Time Visualization\n",
    "from ipywidgets import IntSlider, interact\n",
    "\n",
    "\n",
    "def plot_figure(n_iter):\n",
    "    fig = gradient_descent_visualization(\n",
    "        sgd_losses,\n",
    "        sgd_ws,\n",
    "        grid_losses,\n",
    "        grid_w0,\n",
    "        grid_w1,\n",
    "        mean_x,\n",
    "        std_x,\n",
    "        height,\n",
    "        weight,\n",
    "        n_iter,\n",
    "    )\n",
    "    fig.set_size_inches(10.0, 6.0)\n",
    "\n",
    "\n",
    "interact(plot_figure, n_iter=IntSlider(min=1, max=len(sgd_ws)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Effect of Outliers and MAE Cost Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "from helpers import *\n",
    "\n",
    "# ***************************************************\n",
    "# INSERT YOUR CODE HERE\n",
    "# TODO: reload the data by subsampling first, then by subsampling and adding outliers\n",
    "height, weight, gender = load_data(sub_sample=True, add_outlier=True)\n",
    "\n",
    "# ***************************************************\n",
    "\n",
    "x, mean_x, std_x = standardize(height)\n",
    "y, tx = build_model_data(x, weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((202,), (202, 2))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape, tx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GD iter. 0/49: loss=2869.8351145358533, w0=51.847464098448484, w1=7.724426406192441\n",
      "GD iter. 1/49: loss=318.282124701595, w0=67.401703327983, w1=10.041754328050121\n",
      "GD iter. 2/49: loss=88.64235561651259, w0=72.06797509684336, w1=10.736952704607413\n",
      "GD iter. 3/49: loss=67.9747763988552, w0=73.46785662750146, w1=10.945512217574594\n",
      "GD iter. 4/49: loss=66.11469426926604, w0=73.88782108669889, w1=11.00808007146475\n",
      "GD iter. 5/49: loss=65.947286877603, w0=74.01381042445813, w1=11.026850427631796\n",
      "GD iter. 6/49: loss=65.93222021235334, w0=74.05160722578589, w1=11.03248153448191\n",
      "GD iter. 7/49: loss=65.93086421248087, w0=74.06294626618423, w1=11.034170866536943\n",
      "GD iter. 8/49: loss=65.93074217249236, w0=74.06634797830372, w1=11.034677666153454\n",
      "GD iter. 9/49: loss=65.93073118889338, w0=74.06736849193958, w1=11.034829706038407\n",
      "GD iter. 10/49: loss=65.93073020036948, w0=74.06767464603033, w1=11.034875318003893\n",
      "GD iter. 11/49: loss=65.93073011140233, w0=74.06776649225756, w1=11.034889001593537\n",
      "GD iter. 12/49: loss=65.93073010339529, w0=74.06779404612573, w1=11.034893106670431\n",
      "GD iter. 13/49: loss=65.93073010267466, w0=74.06780231228618, w1=11.034894338193501\n",
      "GD iter. 14/49: loss=65.93073010260979, w0=74.06780479213431, w1=11.034894707650421\n",
      "GD iter. 15/49: loss=65.93073010260396, w0=74.06780553608876, w1=11.034894818487498\n",
      "GD iter. 16/49: loss=65.93073010260342, w0=74.06780575927509, w1=11.03489485173862\n",
      "GD iter. 17/49: loss=65.93073010260338, w0=74.06780582623098, w1=11.034894861713957\n",
      "GD iter. 18/49: loss=65.93073010260338, w0=74.06780584631775, w1=11.034894864706558\n",
      "GD iter. 19/49: loss=65.93073010260338, w0=74.06780585234378, w1=11.034894865604338\n",
      "GD iter. 20/49: loss=65.93073010260338, w0=74.06780585415159, w1=11.034894865873671\n",
      "GD iter. 21/49: loss=65.9307301026034, w0=74.06780585469393, w1=11.03489486595447\n",
      "GD iter. 22/49: loss=65.93073010260338, w0=74.06780585485663, w1=11.034894865978712\n",
      "GD iter. 23/49: loss=65.93073010260338, w0=74.06780585490544, w1=11.034894865985985\n",
      "GD iter. 24/49: loss=65.93073010260338, w0=74.0678058549201, w1=11.034894865988164\n",
      "GD iter. 25/49: loss=65.93073010260338, w0=74.06780585492449, w1=11.034894865988818\n",
      "GD iter. 26/49: loss=65.93073010260338, w0=74.06780585492581, w1=11.034894865989017\n",
      "GD iter. 27/49: loss=65.93073010260338, w0=74.06780585492619, w1=11.034894865989077\n",
      "GD iter. 28/49: loss=65.93073010260338, w0=74.06780585492632, w1=11.034894865989095\n",
      "GD iter. 29/49: loss=65.93073010260336, w0=74.06780585492635, w1=11.034894865989099\n",
      "GD iter. 30/49: loss=65.93073010260338, w0=74.06780585492636, w1=11.034894865989102\n",
      "GD iter. 31/49: loss=65.93073010260338, w0=74.06780585492636, w1=11.0348948659891\n",
      "GD iter. 32/49: loss=65.93073010260338, w0=74.06780585492636, w1=11.0348948659891\n",
      "GD iter. 33/49: loss=65.93073010260338, w0=74.06780585492636, w1=11.0348948659891\n",
      "GD iter. 34/49: loss=65.93073010260338, w0=74.06780585492636, w1=11.0348948659891\n",
      "GD iter. 35/49: loss=65.93073010260338, w0=74.06780585492636, w1=11.0348948659891\n",
      "GD iter. 36/49: loss=65.93073010260338, w0=74.06780585492636, w1=11.0348948659891\n",
      "GD iter. 37/49: loss=65.93073010260338, w0=74.06780585492636, w1=11.0348948659891\n",
      "GD iter. 38/49: loss=65.93073010260338, w0=74.06780585492636, w1=11.0348948659891\n",
      "GD iter. 39/49: loss=65.93073010260338, w0=74.06780585492636, w1=11.0348948659891\n",
      "GD iter. 40/49: loss=65.93073010260338, w0=74.06780585492636, w1=11.0348948659891\n",
      "GD iter. 41/49: loss=65.93073010260338, w0=74.06780585492636, w1=11.0348948659891\n",
      "GD iter. 42/49: loss=65.93073010260338, w0=74.06780585492636, w1=11.0348948659891\n",
      "GD iter. 43/49: loss=65.93073010260338, w0=74.06780585492636, w1=11.0348948659891\n",
      "GD iter. 44/49: loss=65.93073010260338, w0=74.06780585492636, w1=11.0348948659891\n",
      "GD iter. 45/49: loss=65.93073010260338, w0=74.06780585492636, w1=11.0348948659891\n",
      "GD iter. 46/49: loss=65.93073010260338, w0=74.06780585492636, w1=11.0348948659891\n",
      "GD iter. 47/49: loss=65.93073010260338, w0=74.06780585492636, w1=11.0348948659891\n",
      "GD iter. 48/49: loss=65.93073010260338, w0=74.06780585492636, w1=11.0348948659891\n",
      "GD iter. 49/49: loss=65.93073010260338, w0=74.06780585492636, w1=11.0348948659891\n",
      "GD: execution time=0.003 seconds\n"
     ]
    }
   ],
   "source": [
    "from plots import gradient_descent_visualization\n",
    "\n",
    "# Define the parameters of the algorithm.\n",
    "max_iters = 50\n",
    "gamma = 0.7\n",
    "\n",
    "# Initialization\n",
    "w_initial = np.array([0, 0])\n",
    "\n",
    "# Start gradient descent.\n",
    "start_time = datetime.datetime.now()\n",
    "\n",
    "# ***************************************************\n",
    "# INSERT YOUR CODE HERE\n",
    "# TODO: fit the model to the subsampled data / subsampled data with outliers and visualize the cloud of points\n",
    "#       and the model fit\n",
    "gd_losses, gd_ws = gradient_descent(y, tx, w_initial, max_iters, gamma)\n",
    "# ***************************************************\n",
    "\n",
    "\n",
    "end_time = datetime.datetime.now()\n",
    "\n",
    "# Print result\n",
    "exection_time = (end_time - start_time).total_seconds()\n",
    "print(\"GD: execution time={t:.3f} seconds\".format(t=exection_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c46362d414a49548efd16beb996a3b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=1, description='n_iter', max=51, min=1), Output()), _dom_classes=('widge"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.plot_figure(n_iter)>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Time Visualization\n",
    "from ipywidgets import IntSlider, interact\n",
    "\n",
    "\n",
    "def plot_figure(n_iter):\n",
    "    fig = gradient_descent_visualization(\n",
    "        gd_losses,\n",
    "        gd_ws,\n",
    "        grid_losses,\n",
    "        grid_w0,\n",
    "        grid_w1,\n",
    "        mean_x,\n",
    "        std_x,\n",
    "        height,\n",
    "        weight,\n",
    "        n_iter,\n",
    "    )\n",
    "    fig.set_size_inches(10.0, 6.0)\n",
    "\n",
    "\n",
    "interact(plot_figure, n_iter=IntSlider(min=1, max=len(gd_ws)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 6. Subgradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_subgradient_mae(y, tx, w):\n",
    "    \"\"\"Compute a subgradient of the MAE at w.\n",
    "\n",
    "    Args:\n",
    "        y: numpy array of shape=(N, )\n",
    "        tx: numpy array of shape=(N,2)\n",
    "        w: numpy array of shape=(2, ). The vector of model parameters.\n",
    "\n",
    "    Returns:\n",
    "        A numpy array of shape (2, ) (same shape as w), containing the subgradient of the MAE at w.\n",
    "    \"\"\"\n",
    "    e = y - (tx @ w)\n",
    "    subgradient = (-tx.T @ np.sign(e))/len(y)\n",
    "    return subgradient\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subgradient_descent(y, tx, initial_w, max_iters, gamma):\n",
    "    \"\"\"The SubGradient Descent (SubGD) algorithm.\n",
    "\n",
    "    Args:\n",
    "        y: numpy array of shape=(N, )\n",
    "        tx: numpy array of shape=(N,2)\n",
    "        initial_w: numpy array of shape=(2, ). The initial guess (or the initialization) for the model parameters\n",
    "        max_iters: a scalar denoting the total number of iterations of GD\n",
    "        gamma: a scalar denoting the stepsize\n",
    "\n",
    "    Returns:\n",
    "        losses: a list of length max_iters containing the loss value (scalar) for each iteration of SubGD\n",
    "        ws: a list of length max_iters containing the model parameters as numpy arrays of shape (2, ), for each iteration of SubGD\n",
    "    \"\"\"\n",
    "    # Define parameters to store w and loss\n",
    "    ws = [initial_w]\n",
    "    losses = []\n",
    "    w = initial_w\n",
    "    for n_iter in range(max_iters):\n",
    "        w = w - gamma * compute_subgradient_mae(y,tx,w)\n",
    "        loss = compute_loss(y,tx,w,MSE=False)\n",
    "        ws.append(w)\n",
    "        losses.append(loss)\n",
    "        print(\n",
    "            \"SubGD iter. {bi}/{ti}: loss={l}, w0={w0}, w1={w1}\".format(\n",
    "                bi=n_iter, ti=max_iters - 1, l=loss, w0=w[0], w1=w[1]\n",
    "            )\n",
    "        )\n",
    "\n",
    "    return losses, ws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SubGD iter. 0/499: loss=36.6839029274632, w0=0.7, w1=8.756471895211877e-16\n",
      "SubGD iter. 1/499: loss=36.33390292746317, w0=1.4, w1=1.7512943790423754e-15\n",
      "SubGD iter. 2/499: loss=35.983902927463205, w0=2.0999999999999996, w1=2.626941568563563e-15\n",
      "SubGD iter. 3/499: loss=35.63390292746321, w0=2.8, w1=3.502588758084751e-15\n",
      "SubGD iter. 4/499: loss=35.28390292746316, w0=3.5, w1=4.378235947605939e-15\n",
      "SubGD iter. 5/499: loss=34.933902927463194, w0=4.2, w1=5.253883137127127e-15\n",
      "SubGD iter. 6/499: loss=34.58390292746317, w0=4.9, w1=6.1295303266483146e-15\n",
      "SubGD iter. 7/499: loss=34.233902927463205, w0=5.6000000000000005, w1=7.0051775161695025e-15\n",
      "SubGD iter. 8/499: loss=33.88390292746321, w0=6.300000000000001, w1=7.88082470569069e-15\n",
      "SubGD iter. 9/499: loss=33.53390292746315, w0=7.000000000000001, w1=8.756471895211878e-15\n",
      "SubGD iter. 10/499: loss=33.183902927463194, w0=7.700000000000001, w1=9.632119084733065e-15\n",
      "SubGD iter. 11/499: loss=32.83390292746318, w0=8.4, w1=1.0507766274254253e-14\n",
      "SubGD iter. 12/499: loss=32.483902927463205, w0=9.1, w1=1.1383413463775441e-14\n",
      "SubGD iter. 13/499: loss=32.133902927463204, w0=9.799999999999999, w1=1.2259060653296629e-14\n",
      "SubGD iter. 14/499: loss=31.78390292746316, w0=10.499999999999998, w1=1.3134707842817817e-14\n",
      "SubGD iter. 15/499: loss=31.433902927463198, w0=11.199999999999998, w1=1.4010355032339005e-14\n",
      "SubGD iter. 16/499: loss=31.083902927463182, w0=11.899999999999997, w1=1.488600222186019e-14\n",
      "SubGD iter. 17/499: loss=30.73390292746321, w0=12.599999999999996, w1=1.576164941138138e-14\n",
      "SubGD iter. 18/499: loss=30.3839029274632, w0=13.299999999999995, w1=1.6637296600902567e-14\n",
      "SubGD iter. 19/499: loss=30.033902927463156, w0=13.999999999999995, w1=1.7512943790423755e-14\n",
      "SubGD iter. 20/499: loss=29.683902927463212, w0=14.699999999999994, w1=1.8388590979944943e-14\n",
      "SubGD iter. 21/499: loss=29.33390292746319, w0=15.399999999999993, w1=1.926423816946613e-14\n",
      "SubGD iter. 22/499: loss=28.983902927463205, w0=16.099999999999994, w1=2.013988535898732e-14\n",
      "SubGD iter. 23/499: loss=28.6339029274632, w0=16.799999999999994, w1=2.1015532548508507e-14\n",
      "SubGD iter. 24/499: loss=28.28390292746316, w0=17.499999999999993, w1=2.1891179738029695e-14\n",
      "SubGD iter. 25/499: loss=27.933902927463212, w0=18.199999999999992, w1=2.2766826927550882e-14\n",
      "SubGD iter. 26/499: loss=27.58390292746319, w0=18.89999999999999, w1=2.364247411707207e-14\n",
      "SubGD iter. 27/499: loss=27.233902927463213, w0=19.59999999999999, w1=2.4518121306593258e-14\n",
      "SubGD iter. 28/499: loss=26.8839029274632, w0=20.29999999999999, w1=2.5393768496114446e-14\n",
      "SubGD iter. 29/499: loss=26.533902927463174, w0=20.99999999999999, w1=2.6269415685635634e-14\n",
      "SubGD iter. 30/499: loss=26.18390292746322, w0=21.69999999999999, w1=2.7145062875156822e-14\n",
      "SubGD iter. 31/499: loss=25.833902927463193, w0=22.399999999999988, w1=2.802071006467801e-14\n",
      "SubGD iter. 32/499: loss=25.483902927463205, w0=23.099999999999987, w1=2.8896357254199195e-14\n",
      "SubGD iter. 33/499: loss=25.1339029274632, w0=23.799999999999986, w1=2.977200444372038e-14\n",
      "SubGD iter. 34/499: loss=24.78390292746319, w0=24.499999999999986, w1=3.064765163324157e-14\n",
      "SubGD iter. 35/499: loss=24.433902927463215, w0=25.199999999999985, w1=3.152329882276276e-14\n",
      "SubGD iter. 36/499: loss=24.083902927463193, w0=25.899999999999984, w1=3.2398946012283946e-14\n",
      "SubGD iter. 37/499: loss=23.733902927463195, w0=26.599999999999984, w1=3.3274593201805134e-14\n",
      "SubGD iter. 38/499: loss=23.383902927463204, w0=27.299999999999983, w1=3.415024039132632e-14\n",
      "SubGD iter. 39/499: loss=23.033902927463192, w0=27.999999999999982, w1=3.502588758084751e-14\n",
      "SubGD iter. 40/499: loss=22.68390292746321, w0=28.69999999999998, w1=3.59015347703687e-14\n",
      "SubGD iter. 41/499: loss=22.333902927463203, w0=29.39999999999998, w1=3.6777181959889886e-14\n",
      "SubGD iter. 42/499: loss=21.983902927463195, w0=30.09999999999998, w1=3.7652829149411074e-14\n",
      "SubGD iter. 43/499: loss=21.633902927463204, w0=30.79999999999998, w1=3.852847633893226e-14\n",
      "SubGD iter. 44/499: loss=21.28390292746319, w0=31.49999999999998, w1=3.940412352845345e-14\n",
      "SubGD iter. 45/499: loss=20.933902927463198, w0=32.19999999999998, w1=4.027977071797464e-14\n",
      "SubGD iter. 46/499: loss=20.583902927463193, w0=32.899999999999984, w1=4.1155417907495825e-14\n",
      "SubGD iter. 47/499: loss=20.2339029274632, w0=33.59999999999999, w1=4.2031065097017013e-14\n",
      "SubGD iter. 48/499: loss=19.88390292746319, w0=34.29999999999999, w1=4.29067122865382e-14\n",
      "SubGD iter. 49/499: loss=19.533902927463195, w0=34.99999999999999, w1=4.378235947605939e-14\n",
      "SubGD iter. 50/499: loss=19.183902927463187, w0=35.699999999999996, w1=4.465800666558058e-14\n",
      "SubGD iter. 51/499: loss=18.83390292746319, w0=36.4, w1=4.5533653855101765e-14\n",
      "SubGD iter. 52/499: loss=18.483902927463184, w0=37.1, w1=4.640930104462295e-14\n",
      "SubGD iter. 53/499: loss=18.133902927463183, w0=37.800000000000004, w1=4.728494823414414e-14\n",
      "SubGD iter. 54/499: loss=17.78390292746319, w0=38.50000000000001, w1=4.816059542366533e-14\n",
      "SubGD iter. 55/499: loss=17.433902927463183, w0=39.20000000000001, w1=4.9036242613186517e-14\n",
      "SubGD iter. 56/499: loss=17.083902927463182, w0=39.90000000000001, w1=4.9911889802707705e-14\n",
      "SubGD iter. 57/499: loss=16.73390292746318, w0=40.600000000000016, w1=5.078753699222889e-14\n",
      "SubGD iter. 58/499: loss=16.38390292746318, w0=41.30000000000002, w1=5.166318418175008e-14\n",
      "SubGD iter. 59/499: loss=16.03390292746318, w0=42.00000000000002, w1=5.253883137127127e-14\n",
      "SubGD iter. 60/499: loss=15.683902927463174, w0=42.700000000000024, w1=5.3414478560792456e-14\n",
      "SubGD iter. 61/499: loss=15.33390292746318, w0=43.40000000000003, w1=5.4290125750313644e-14\n",
      "SubGD iter. 62/499: loss=14.983902927463175, w0=44.10000000000003, w1=5.516577293983483e-14\n",
      "SubGD iter. 63/499: loss=14.633902927463177, w0=44.80000000000003, w1=5.604142012935602e-14\n",
      "SubGD iter. 64/499: loss=14.283902927463178, w0=45.500000000000036, w1=5.691706731887721e-14\n",
      "SubGD iter. 65/499: loss=13.933902927463167, w0=46.20000000000004, w1=5.779271450839839e-14\n",
      "SubGD iter. 66/499: loss=13.586635104834459, w0=46.90000000000004, w1=5.866836169791957e-14\n",
      "SubGD iter. 67/499: loss=13.245225781875607, w0=47.59306930693074, w1=0.01114784567828894\n",
      "SubGD iter. 68/499: loss=12.908606161385098, w0=48.279207920792125, w1=0.03308574108991741\n",
      "SubGD iter. 69/499: loss=12.577519717328222, w0=48.96534653465351, w1=0.055023636501545875\n",
      "SubGD iter. 70/499: loss=12.262051706947382, w0=49.63069306930698, w1=0.1053832638830964\n",
      "SubGD iter. 71/499: loss=11.949647673017784, w0=50.28910891089114, w1=0.16746568532795278\n",
      "SubGD iter. 72/499: loss=11.642196462828569, w0=50.947524752475296, w1=0.22954810677280915\n",
      "SubGD iter. 73/499: loss=11.343438222090922, w0=51.59207920792084, w1=0.312425129327494\n",
      "SubGD iter. 74/499: loss=11.053133784820279, w0=52.22277227722777, w1=0.41195013288401805\n",
      "SubGD iter. 75/499: loss=10.76890941400422, w0=52.84653465346539, w1=0.5208167847923948\n",
      "SubGD iter. 76/499: loss=10.493169937314228, w0=53.4564356435644, w1=0.6457900912636185\n",
      "SubGD iter. 77/499: loss=10.222780468310223, w0=54.0594059405941, w1=0.7796904498577408\n",
      "SubGD iter. 78/499: loss=9.955955079478917, w0=54.655445544554496, w1=0.9197570104995888\n",
      "SubGD iter. 79/499: loss=9.694822045281622, w0=55.24455445544559, w1=1.067092029785011\n",
      "SubGD iter. 80/499: loss=9.443994532197943, w0=55.819801980198065, w1=1.2261255948210965\n",
      "SubGD iter. 81/499: loss=9.207980250927127, w0=56.36732673267331, w1=1.410709342622233\n",
      "SubGD iter. 82/499: loss=8.977449271520188, w0=56.900990099009945, w1=1.605853732220289\n",
      "SubGD iter. 83/499: loss=8.75287882828991, w0=57.42772277227727, w1=1.808762802293982\n",
      "SubGD iter. 84/499: loss=8.537478713465806, w0=57.933663366336674, w1=2.0285064197514897\n",
      "SubGD iter. 85/499: loss=8.32648364875495, w0=58.43267326732677, w1=2.2494370848672975\n",
      "SubGD iter. 86/499: loss=8.124270365748359, w0=58.91089108910895, w1=2.4837982986028537\n",
      "SubGD iter. 87/499: loss=7.924552606327075, w0=59.382178217821824, w1=2.7260245553531703\n",
      "SubGD iter. 88/499: loss=7.733459895615649, w0=59.83960396039608, w1=2.978742333469156\n",
      "SubGD iter. 89/499: loss=7.554147310756099, w0=60.262376237623805, w1=3.251528669355458\n",
      "SubGD iter. 90/499: loss=7.377448172961413, w0=60.67821782178222, w1=3.5270865794243\n",
      "SubGD iter. 91/499: loss=7.202264480810142, w0=61.087128712871326, w1=3.806459183951836\n",
      "SubGD iter. 92/499: loss=7.027893514063638, w0=61.49603960396043, w1=4.085831788479371\n",
      "SubGD iter. 93/499: loss=6.857310455802809, w0=61.891089108910926, w1=4.373839384328629\n",
      "SubGD iter. 94/499: loss=6.690618153642077, w0=62.27920792079211, w1=4.666037469532069\n",
      "SubGD iter. 95/499: loss=6.529410807583118, w0=62.65346534653469, w1=4.959829093241791\n",
      "SubGD iter. 96/499: loss=6.370125862169614, w0=63.02079207920796, w1=5.257057192056662\n",
      "SubGD iter. 97/499: loss=6.211609444378057, w0=63.38118811881192, w1=5.5604343163524295\n",
      "SubGD iter. 98/499: loss=6.053780865950577, w0=63.74158415841588, w1=5.863811440648197\n",
      "SubGD iter. 99/499: loss=5.900311048699066, w0=64.08811881188123, w1=6.172402175278572\n",
      "SubGD iter. 100/499: loss=5.747520897323205, w0=64.42772277227726, w1=6.4863693105165225\n",
      "SubGD iter. 101/499: loss=5.594730745947353, w0=64.7673267326733, w1=6.800336445754473\n",
      "SubGD iter. 102/499: loss=5.441940594571494, w0=65.10693069306933, w1=7.1143035809924235\n",
      "SubGD iter. 103/499: loss=5.292296704156596, w0=65.44653465346536, w1=7.428270716230374\n",
      "SubGD iter. 104/499: loss=5.147908267159466, w0=65.76534653465349, w1=7.747893210218651\n",
      "SubGD iter. 105/499: loss=5.005676040610676, w0=66.070297029703, w1=8.073669686866932\n",
      "SubGD iter. 106/499: loss=4.864042163334058, w0=66.37524752475251, w1=8.399446163515213\n",
      "SubGD iter. 107/499: loss=4.724062730561248, w0=66.6663366336634, w1=8.73297028041742\n",
      "SubGD iter. 108/499: loss=4.585520552048326, w0=66.9574257425743, w1=9.066494397319628\n",
      "SubGD iter. 109/499: loss=4.451828065579475, w0=67.23465346534658, w1=9.398630319470323\n",
      "SubGD iter. 110/499: loss=4.318135579110621, w0=67.51188118811886, w1=9.730766241621017\n",
      "SubGD iter. 111/499: loss=4.18807596015118, w0=67.78910891089114, w1=10.062902163771712\n",
      "SubGD iter. 112/499: loss=4.070270419375745, w0=68.06633663366343, w1=10.363999289979459\n",
      "SubGD iter. 113/499: loss=3.9592722507986293, w0=68.32970297029709, w1=10.66046690927365\n",
      "SubGD iter. 114/499: loss=3.852639864188492, w0=68.59306930693076, w1=10.943174379960851\n",
      "SubGD iter. 115/499: loss=3.7468479155893117, w0=68.85643564356442, w1=11.225881850648053\n",
      "SubGD iter. 116/499: loss=3.6449962028716993, w0=69.11287128712878, w1=11.504395843582245\n",
      "SubGD iter. 117/499: loss=3.548617017890767, w0=69.35544554455453, w1=11.78820189306779\n",
      "SubGD iter. 118/499: loss=3.4599526473344535, w0=69.58415841584166, w1=12.06091146519101\n",
      "SubGD iter. 119/499: loss=3.375286763657721, w0=69.80594059405948, w1=12.324245668386087\n",
      "SubGD iter. 120/499: loss=3.2923724054028254, w0=70.0277227722773, w1=12.587579871581164\n",
      "SubGD iter. 121/499: loss=3.2151716381738966, w0=70.25643564356443, w1=12.824765405096523\n",
      "SubGD iter. 122/499: loss=3.1390357409451686, w0=70.47821782178225, w1=13.065616959310187\n",
      "SubGD iter. 123/499: loss=3.0668316646316547, w0=70.69306930693077, w1=13.302953389983951\n",
      "SubGD iter. 124/499: loss=3.002920399171509, w0=70.89405940594067, w1=13.525403099312957\n",
      "SubGD iter. 125/499: loss=2.942510912611603, w0=71.08811881188126, w1=13.742945617944251\n",
      "SubGD iter. 126/499: loss=2.8858176261348234, w0=71.27524752475254, w1=13.953548196006883\n",
      "SubGD iter. 127/499: loss=2.8335810308951257, w0=71.46237623762383, w1=14.164150774069515\n",
      "SubGD iter. 128/499: loss=2.793363382996567, w0=71.62178217821788, w1=14.349779559473214\n",
      "SubGD iter. 129/499: loss=2.76192390608019, w0=71.75346534653471, w1=14.516890107612351\n",
      "SubGD iter. 130/499: loss=2.740046854295932, w0=71.87128712871292, w1=14.670791185324227\n",
      "SubGD iter. 131/499: loss=2.726544001751007, w0=71.95445544554461, w1=14.780276456654562\n",
      "SubGD iter. 132/499: loss=2.7136963154314486, w0=72.0376237623763, w1=14.889761727984897\n",
      "SubGD iter. 133/499: loss=2.7036612228413737, w0=72.10693069306937, w1=14.985916181776767\n",
      "SubGD iter. 134/499: loss=2.6936261302512974, w0=72.17623762376245, w1=15.082070635568638\n",
      "SubGD iter. 135/499: loss=2.685230390169346, w0=72.24554455445552, w1=15.178225089360508\n",
      "SubGD iter. 136/499: loss=2.6787032616673674, w0=72.30099009900998, w1=15.25972348971595\n",
      "SubGD iter. 137/499: loss=2.672964632011289, w0=72.34950495049513, w1=15.335091856448178\n",
      "SubGD iter. 138/499: loss=2.667857329758735, w0=72.39801980198028, w1=15.410460223180406\n",
      "SubGD iter. 139/499: loss=2.665021955232679, w0=72.43267326732682, w1=15.469961786755766\n",
      "SubGD iter. 140/499: loss=2.6628382141366127, w0=72.46039603960405, w1=15.51864528583285\n",
      "SubGD iter. 141/499: loss=2.6610883632632945, w0=72.48811881188128, w1=15.561592159086528\n",
      "SubGD iter. 142/499: loss=2.660055654821555, w0=72.5019801980199, w1=15.597828332032567\n",
      "SubGD iter. 143/499: loss=2.659239142449219, w0=72.52277227722782, w1=15.624722856626754\n",
      "SubGD iter. 144/499: loss=2.6586200242825733, w0=72.55049504950505, w1=15.642690329098041\n",
      "SubGD iter. 145/499: loss=2.6582032739757726, w0=72.56435643564366, w1=15.664356578291132\n",
      "SubGD iter. 146/499: loss=2.6577785613330693, w0=72.58514851485158, w1=15.677095775361325\n",
      "SubGD iter. 147/499: loss=2.657353848690369, w0=72.6059405940595, w1=15.689834972431518\n",
      "SubGD iter. 148/499: loss=2.6569384404610816, w0=72.62673267326743, w1=15.70257416950171\n",
      "SubGD iter. 149/499: loss=2.656526123435691, w0=72.64059405940604, w1=15.724240418694801\n",
      "SubGD iter. 150/499: loss=2.6561889195121915, w0=72.66138613861396, w1=15.736979615764994\n",
      "SubGD iter. 151/499: loss=2.656066114862521, w0=72.66831683168327, w1=15.74811029423132\n",
      "SubGD iter. 152/499: loss=2.6559433102128485, w0=72.67524752475258, w1=15.759240972697647\n",
      "SubGD iter. 153/499: loss=2.655841783049218, w0=72.68217821782189, w1=15.770371651163973\n",
      "SubGD iter. 154/499: loss=2.65583062564566, w0=72.68217821782189, w1=15.774323911906727\n",
      "SubGD iter. 155/499: loss=2.655819468242105, w0=72.68217821782189, w1=15.77827617264948\n",
      "SubGD iter. 156/499: loss=2.6558083108385477, w0=72.68217821782189, w1=15.782228433392234\n",
      "SubGD iter. 157/499: loss=2.655797153434994, w0=72.68217821782189, w1=15.786180694134988\n",
      "SubGD iter. 158/499: loss=2.655785996031434, w0=72.68217821782189, w1=15.790132954877741\n",
      "SubGD iter. 159/499: loss=2.65577483862788, w0=72.68217821782189, w1=15.794085215620495\n",
      "SubGD iter. 160/499: loss=2.655763681224322, w0=72.68217821782189, w1=15.798037476363248\n",
      "SubGD iter. 161/499: loss=2.655752523820768, w0=72.68217821782189, w1=15.801989737106002\n",
      "SubGD iter. 162/499: loss=2.65574136641721, w0=72.68217821782189, w1=15.805941997848755\n",
      "SubGD iter. 163/499: loss=2.6557302090136568, w0=72.68217821782189, w1=15.809894258591509\n",
      "SubGD iter. 164/499: loss=2.655719051610098, w0=72.68217821782189, w1=15.813846519334263\n",
      "SubGD iter. 165/499: loss=2.655707894206543, w0=72.68217821782189, w1=15.817798780077016\n",
      "SubGD iter. 166/499: loss=2.6556967368029856, w0=72.68217821782189, w1=15.82175104081977\n",
      "SubGD iter. 167/499: loss=2.6556855793994303, w0=72.68217821782189, w1=15.825703301562523\n",
      "SubGD iter. 168/499: loss=2.6556744219958737, w0=72.68217821782189, w1=15.829655562305277\n",
      "SubGD iter. 169/499: loss=2.6556632645923184, w0=72.68217821782189, w1=15.83360782304803\n",
      "SubGD iter. 170/499: loss=2.6556521071887618, w0=72.68217821782189, w1=15.837560083790784\n",
      "SubGD iter. 171/499: loss=2.655640949785204, w0=72.68217821782189, w1=15.841512344533538\n",
      "SubGD iter. 172/499: loss=2.655629792381649, w0=72.68217821782189, w1=15.845464605276291\n",
      "SubGD iter. 173/499: loss=2.655618634978094, w0=72.68217821782189, w1=15.849416866019045\n",
      "SubGD iter. 174/499: loss=2.6556074775745357, w0=72.68217821782189, w1=15.853369126761798\n",
      "SubGD iter. 175/499: loss=2.6555963201709805, w0=72.68217821782189, w1=15.857321387504552\n",
      "SubGD iter. 176/499: loss=2.655585162767426, w0=72.68217821782189, w1=15.861273648247305\n",
      "SubGD iter. 177/499: loss=2.655574005363867, w0=72.68217821782189, w1=15.865225908990059\n",
      "SubGD iter. 178/499: loss=2.655562847960312, w0=72.68217821782189, w1=15.869178169732812\n",
      "SubGD iter. 179/499: loss=2.6555516905567558, w0=72.68217821782189, w1=15.873130430475566\n",
      "SubGD iter. 180/499: loss=2.655540533153201, w0=72.68217821782189, w1=15.87708269121832\n",
      "SubGD iter. 181/499: loss=2.6555293757496425, w0=72.68217821782189, w1=15.881034951961073\n",
      "SubGD iter. 182/499: loss=2.6555182183460846, w0=72.68217821782189, w1=15.884987212703827\n",
      "SubGD iter. 183/499: loss=2.65550706094253, w0=72.68217821782189, w1=15.88893947344658\n",
      "SubGD iter. 184/499: loss=2.655495903538975, w0=72.68217821782189, w1=15.892891734189334\n",
      "SubGD iter. 185/499: loss=2.655484746135418, w0=72.68217821782189, w1=15.896843994932087\n",
      "SubGD iter. 186/499: loss=2.655473588731861, w0=72.68217821782189, w1=15.900796255674841\n",
      "SubGD iter. 187/499: loss=2.6554624313283046, w0=72.68217821782189, w1=15.904748516417595\n",
      "SubGD iter. 188/499: loss=2.6554512739247493, w0=72.68217821782189, w1=15.908700777160348\n",
      "SubGD iter. 189/499: loss=2.65545685303069, w0=72.68217821782189, w1=15.912653037903102\n",
      "SubGD iter. 190/499: loss=2.6554461185931344, w0=72.67524752475258, w1=15.910526938117364\n",
      "SubGD iter. 191/499: loss=2.6554349611895796, w0=72.67524752475258, w1=15.914479198860118\n",
      "SubGD iter. 192/499: loss=2.6554313180269173, w0=72.67524752475258, w1=15.918431459602871\n",
      "SubGD iter. 193/499: loss=2.6554298058579633, w0=72.66831683168327, w1=15.916305359817134\n",
      "SubGD iter. 194/499: loss=2.6554186484544084, w0=72.66831683168327, w1=15.920257620559887\n",
      "SubGD iter. 195/499: loss=2.65540749105085, w0=72.66831683168327, w1=15.924209881302641\n",
      "SubGD iter. 196/499: loss=2.6554117850950854, w0=72.66831683168327, w1=15.928162142045394\n",
      "SubGD iter. 197/499: loss=2.6554023357192387, w0=72.66138613861396, w1=15.926036042259657\n",
      "SubGD iter. 198/499: loss=2.6553911783156807, w0=72.66138613861396, w1=15.92998830300241\n",
      "SubGD iter. 199/499: loss=2.655386250091312, w0=72.66138613861396, w1=15.933940563745164\n",
      "SubGD iter. 200/499: loss=2.6553860229840676, w0=72.65445544554466, w1=15.931814463959427\n",
      "SubGD iter. 201/499: loss=2.6553748655805087, w0=72.65445544554466, w1=15.93576672470218\n",
      "SubGD iter. 202/499: loss=2.6553637081769543, w0=72.65445544554466, w1=15.939718985444934\n",
      "SubGD iter. 203/499: loss=2.6553667171594806, w0=72.65445544554466, w1=15.943671246187687\n",
      "SubGD iter. 204/499: loss=2.6553585528453385, w0=72.64752475247535, w1=15.94154514640195\n",
      "SubGD iter. 205/499: loss=2.6553473954417823, w0=72.64752475247535, w1=15.945497407144703\n",
      "SubGD iter. 206/499: loss=2.6553411821557047, w0=72.64752475247535, w1=15.949449667887457\n",
      "SubGD iter. 207/499: loss=2.6553422401101687, w0=72.64059405940604, w1=15.94732356810172\n",
      "SubGD iter. 208/499: loss=2.655331082706613, w0=72.64059405940604, w1=15.951275828844473\n",
      "SubGD iter. 209/499: loss=2.655319925303056, w0=72.64059405940604, w1=15.955228089587226\n",
      "SubGD iter. 210/499: loss=2.6553216492238745, w0=72.64059405940604, w1=15.95918035032998\n",
      "SubGD iter. 211/499: loss=2.655314769971441, w0=72.63366336633673, w1=15.957054250544243\n",
      "SubGD iter. 212/499: loss=2.655303612567885, w0=72.63366336633673, w1=15.961006511286996\n",
      "SubGD iter. 213/499: loss=2.6552961142201, w0=72.63366336633673, w1=15.96495877202975\n",
      "SubGD iter. 214/499: loss=2.6553165915495143, w0=72.62673267326743, w1=15.962832672244012\n",
      "SubGD iter. 215/499: loss=2.6552996717925312, w0=72.63366336633673, w1=15.967301372051416\n",
      "SubGD iter. 216/499: loss=2.655309114137895, w0=72.62673267326743, w1=15.965175272265679\n",
      "SubGD iter. 217/499: loss=2.655303229364963, w0=72.63366336633673, w1=15.969643972073083\n",
      "SubGD iter. 218/499: loss=2.6553016367262767, w0=72.62673267326743, w1=15.967517872287345\n",
      "SubGD iter. 219/499: loss=2.655306786937395, w0=72.63366336633673, w1=15.97198657209475\n",
      "SubGD iter. 220/499: loss=2.6552941593146593, w0=72.62673267326743, w1=15.969860472309012\n",
      "SubGD iter. 221/499: loss=2.6553103445098247, w0=72.63366336633673, w1=15.974329172116416\n",
      "SubGD iter. 222/499: loss=2.6552874830749427, w0=72.62673267326743, w1=15.972203072330679\n",
      "SubGD iter. 223/499: loss=2.6552918198248636, w0=72.62673267326743, w1=15.970593411609592\n",
      "SubGD iter. 224/499: loss=2.6553114575827483, w0=72.63366336633673, w1=15.975062111416996\n",
      "SubGD iter. 225/499: loss=2.6552883257775157, w0=72.62673267326743, w1=15.972936011631258\n",
      "SubGD iter. 226/499: loss=2.655289480335071, w0=72.62673267326743, w1=15.971326350910171\n",
      "SubGD iter. 227/499: loss=2.6553125706556675, w0=72.63366336633673, w1=15.975795050717576\n",
      "SubGD iter. 228/499: loss=2.6552891684800897, w0=72.62673267326743, w1=15.973668950931838\n",
      "SubGD iter. 229/499: loss=2.6552873177603495, w0=72.62673267326743, w1=15.972059290210751\n",
      "SubGD iter. 230/499: loss=2.6552922787671025, w0=72.62673267326743, w1=15.970449629489664\n",
      "SubGD iter. 231/499: loss=2.65531123922908, w0=72.63366336633673, w1=15.974918329297068\n",
      "SubGD iter. 232/499: loss=2.6552881604629244, w0=72.62673267326743, w1=15.972792229511331\n",
      "SubGD iter. 233/499: loss=2.6552899392773064, w0=72.62673267326743, w1=15.971182568790244\n",
      "SubGD iter. 234/499: loss=2.6553123523020004, w0=72.63366336633673, w1=15.975651268597648\n",
      "SubGD iter. 235/499: loss=2.655289003165498, w0=72.62673267326743, w1=15.97352516881191\n",
      "SubGD iter. 236/499: loss=2.6552875997875143, w0=72.62673267326743, w1=15.971915508090824\n",
      "SubGD iter. 237/499: loss=2.6553134653749226, w0=72.63366336633673, w1=15.976384207898228\n",
      "SubGD iter. 238/499: loss=2.6552898458680687, w0=72.62673267326743, w1=15.97425810811249\n",
      "SubGD iter. 239/499: loss=2.655287995148331, w0=72.62673267326743, w1=15.972648447391403\n",
      "SubGD iter. 240/499: loss=2.6552903982195453, w0=72.62673267326743, w1=15.971038786670317\n",
      "SubGD iter. 241/499: loss=2.655312133948333, w0=72.63366336633673, w1=15.97550748647772\n",
      "SubGD iter. 242/499: loss=2.655288837850902, w0=72.62673267326743, w1=15.973381386691983\n",
      "SubGD iter. 243/499: loss=2.65528805872975, w0=72.62673267326743, w1=15.971771725970896\n",
      "SubGD iter. 244/499: loss=2.6553132470212564, w0=72.63366336633673, w1=15.9762404257783\n",
      "SubGD iter. 245/499: loss=2.6552896805534765, w0=72.62673267326743, w1=15.974114325992563\n",
      "SubGD iter. 246/499: loss=2.655287829833737, w0=72.62673267326743, w1=15.972504665271476\n",
      "SubGD iter. 247/499: loss=2.6552908571617815, w0=72.62673267326743, w1=15.970895004550389\n",
      "SubGD iter. 248/499: loss=2.6553119155946665, w0=72.63366336633673, w1=15.975363704357793\n",
      "SubGD iter. 249/499: loss=2.655288672536309, w0=72.62673267326743, w1=15.973237604572056\n",
      "SubGD iter. 250/499: loss=2.655288517671988, w0=72.62673267326743, w1=15.971627943850969\n",
      "SubGD iter. 251/499: loss=2.655313028667588, w0=72.63366336633673, w1=15.976096643658373\n",
      "SubGD iter. 252/499: loss=2.655289515238884, w0=72.62673267326743, w1=15.973970543872635\n",
      "SubGD iter. 253/499: loss=2.655287664519143, w0=72.62673267326743, w1=15.972360883151548\n",
      "SubGD iter. 254/499: loss=2.655291316104018, w0=72.62673267326743, w1=15.970751222430462\n",
      "SubGD iter. 255/499: loss=2.6553116972410007, w0=72.63366336633673, w1=15.975219922237866\n",
      "SubGD iter. 256/499: loss=2.655288507221716, w0=72.62673267326743, w1=15.973093822452128\n",
      "SubGD iter. 257/499: loss=2.6552889766142243, w0=72.62673267326743, w1=15.971484161731041\n",
      "SubGD iter. 258/499: loss=2.6553128103139194, w0=72.63366336633673, w1=15.975952861538445\n",
      "SubGD iter. 259/499: loss=2.6552893499242893, w0=72.62673267326743, w1=15.973826761752708\n",
      "SubGD iter. 260/499: loss=2.6552874992045497, w0=72.62673267326743, w1=15.972217101031621\n",
      "SubGD iter. 261/499: loss=2.655291775046256, w0=72.62673267326743, w1=15.970607440310534\n",
      "SubGD iter. 262/499: loss=2.6553114788873318, w0=72.63366336633673, w1=15.975076140117938\n",
      "SubGD iter. 263/499: loss=2.655288341907124, w0=72.62673267326743, w1=15.9729500403322\n",
      "SubGD iter. 264/499: loss=2.6552894355564596, w0=72.62673267326743, w1=15.971340379611114\n",
      "SubGD iter. 265/499: loss=2.655312591960252, w0=72.63366336633673, w1=15.975809079418518\n",
      "SubGD iter. 266/499: loss=2.655289184609696, w0=72.62673267326743, w1=15.97368297963278\n",
      "SubGD iter. 267/499: loss=2.6552873338899556, w0=72.62673267326743, w1=15.972073318911693\n",
      "SubGD iter. 268/499: loss=2.6552922339884923, w0=72.62673267326743, w1=15.970463658190607\n",
      "SubGD iter. 269/499: loss=2.6553112605336664, w0=72.63366336633673, w1=15.97493235799801\n",
      "SubGD iter. 270/499: loss=2.65528817659253, w0=72.62673267326743, w1=15.972806258212273\n",
      "SubGD iter. 271/499: loss=2.6552898944986993, w0=72.62673267326743, w1=15.971196597491186\n",
      "SubGD iter. 272/499: loss=2.655312373606585, w0=72.63366336633673, w1=15.97566529729859\n",
      "SubGD iter. 273/499: loss=2.655289019295102, w0=72.62673267326743, w1=15.973539197512853\n",
      "SubGD iter. 274/499: loss=2.6552875550089037, w0=72.62673267326743, w1=15.971929536791766\n",
      "SubGD iter. 275/499: loss=2.6553134866795056, w0=72.63366336633673, w1=15.97639823659917\n",
      "SubGD iter. 276/499: loss=2.6552898619976766, w0=72.62673267326743, w1=15.974272136813433\n",
      "SubGD iter. 277/499: loss=2.655288011277936, w0=72.62673267326743, w1=15.972662476092346\n",
      "SubGD iter. 278/499: loss=2.6552903534409347, w0=72.62673267326743, w1=15.971052815371259\n",
      "SubGD iter. 279/499: loss=2.655312155252917, w0=72.63366336633673, w1=15.975521515178663\n",
      "SubGD iter. 280/499: loss=2.65528885398051, w0=72.62673267326743, w1=15.973395415392925\n",
      "SubGD iter. 281/499: loss=2.6552880139511412, w0=72.62673267326743, w1=15.971785754671838\n",
      "SubGD iter. 282/499: loss=2.6553132683258402, w0=72.63366336633673, w1=15.976254454479243\n",
      "SubGD iter. 283/499: loss=2.655289696683084, w0=72.62673267326743, w1=15.974128354693505\n",
      "SubGD iter. 284/499: loss=2.655287845963342, w0=72.62673267326743, w1=15.972518693972418\n",
      "SubGD iter. 285/499: loss=2.6552908123831704, w0=72.62673267326743, w1=15.970909033251331\n",
      "SubGD iter. 286/499: loss=2.6553119368992504, w0=72.63366336633673, w1=15.975377733058735\n",
      "SubGD iter. 287/499: loss=2.655288688665915, w0=72.62673267326743, w1=15.973251633272998\n",
      "SubGD iter. 288/499: loss=2.655288472893378, w0=72.62673267326743, w1=15.971641972551911\n",
      "SubGD iter. 289/499: loss=2.655313049972172, w0=72.63366336633673, w1=15.976110672359315\n",
      "SubGD iter. 290/499: loss=2.6552895313684894, w0=72.62673267326743, w1=15.973984572573578\n",
      "SubGD iter. 291/499: loss=2.6552876806487498, w0=72.62673267326743, w1=15.97237491185249\n",
      "SubGD iter. 292/499: loss=2.6552912713254084, w0=72.62673267326743, w1=15.970765251131404\n",
      "SubGD iter. 293/499: loss=2.655311718545582, w0=72.63366336633673, w1=15.975233950938808\n",
      "SubGD iter. 294/499: loss=2.655288523351323, w0=72.62673267326743, w1=15.97310785115307\n",
      "SubGD iter. 295/499: loss=2.6552889318356137, w0=72.62673267326743, w1=15.971498190431983\n",
      "SubGD iter. 296/499: loss=2.6553128316185037, w0=72.63366336633673, w1=15.975966890239388\n",
      "SubGD iter. 297/499: loss=2.655289366053896, w0=72.62673267326743, w1=15.97384079045365\n",
      "SubGD iter. 298/499: loss=2.6552875153341553, w0=72.62673267326743, w1=15.972231129732563\n",
      "SubGD iter. 299/499: loss=2.6552917302676464, w0=72.62673267326743, w1=15.970621469011476\n",
      "SubGD iter. 300/499: loss=2.655311500191915, w0=72.63366336633673, w1=15.97509016881888\n",
      "SubGD iter. 301/499: loss=2.655288358036728, w0=72.62673267326743, w1=15.972964069033143\n",
      "SubGD iter. 302/499: loss=2.6552893907778525, w0=72.62673267326743, w1=15.971354408312056\n",
      "SubGD iter. 303/499: loss=2.6553126132648375, w0=72.63366336633673, w1=15.97582310811946\n",
      "SubGD iter. 304/499: loss=2.6552892007393027, w0=72.62673267326743, w1=15.973697008333723\n",
      "SubGD iter. 305/499: loss=2.6552873500195613, w0=72.62673267326743, w1=15.972087347612636\n",
      "SubGD iter. 306/499: loss=2.655292189209882, w0=72.62673267326743, w1=15.970477686891549\n",
      "SubGD iter. 307/499: loss=2.6553112818382494, w0=72.63366336633673, w1=15.974946386698953\n",
      "SubGD iter. 308/499: loss=2.6552881927221366, w0=72.62673267326743, w1=15.972820286913215\n",
      "SubGD iter. 309/499: loss=2.6552898497200896, w0=72.62673267326743, w1=15.971210626192129\n",
      "SubGD iter. 310/499: loss=2.6553123949111703, w0=72.63366336633673, w1=15.975679325999533\n",
      "SubGD iter. 311/499: loss=2.6552890354247096, w0=72.62673267326743, w1=15.973553226213795\n",
      "SubGD iter. 312/499: loss=2.655287510230296, w0=72.62673267326743, w1=15.971943565492708\n",
      "SubGD iter. 313/499: loss=2.6553135079840913, w0=72.63366336633673, w1=15.976412265300112\n",
      "SubGD iter. 314/499: loss=2.655289878127283, w0=72.62673267326743, w1=15.974286165514375\n",
      "SubGD iter. 315/499: loss=2.655288027407542, w0=72.62673267326743, w1=15.972676504793288\n",
      "SubGD iter. 316/499: loss=2.6552903086623263, w0=72.62673267326743, w1=15.971066844072201\n",
      "SubGD iter. 317/499: loss=2.6553121765575027, w0=72.63366336633673, w1=15.975535543879605\n",
      "SubGD iter. 318/499: loss=2.655288870110115, w0=72.62673267326743, w1=15.973409444093868\n",
      "SubGD iter. 319/499: loss=2.655287969172531, w0=72.62673267326743, w1=15.97179978337278\n",
      "SubGD iter. 320/499: loss=2.655313289630424, w0=72.63366336633673, w1=15.976268483180185\n",
      "SubGD iter. 321/499: loss=2.65528971281269, w0=72.62673267326743, w1=15.974142383394447\n",
      "SubGD iter. 322/499: loss=2.6552878620929468, w0=72.62673267326743, w1=15.97253272267336\n",
      "SubGD iter. 323/499: loss=2.655290767604562, w0=72.62673267326743, w1=15.970923061952274\n",
      "SubGD iter. 324/499: loss=2.655311958203835, w0=72.63366336633673, w1=15.975391761759678\n",
      "SubGD iter. 325/499: loss=2.6552887047955216, w0=72.62673267326743, w1=15.97326566197394\n",
      "SubGD iter. 326/499: loss=2.655288428114768, w0=72.62673267326743, w1=15.971656001252853\n",
      "SubGD iter. 327/499: loss=2.655313071276755, w0=72.63366336633673, w1=15.976124701060257\n",
      "SubGD iter. 328/499: loss=2.6552895474980964, w0=72.62673267326743, w1=15.97399860127452\n",
      "SubGD iter. 329/499: loss=2.6552876967783545, w0=72.62673267326743, w1=15.972388940553433\n",
      "SubGD iter. 330/499: loss=2.6552912265468, w0=72.62673267326743, w1=15.970779279832346\n",
      "SubGD iter. 331/499: loss=2.655311739850167, w0=72.63366336633673, w1=15.97524797963975\n",
      "SubGD iter. 332/499: loss=2.6552885394809285, w0=72.62673267326743, w1=15.973121879854013\n",
      "SubGD iter. 333/499: loss=2.655288887057005, w0=72.62673267326743, w1=15.971512219132926\n",
      "SubGD iter. 334/499: loss=2.6553128529230885, w0=72.63366336633673, w1=15.97598091894033\n",
      "SubGD iter. 335/499: loss=2.6552893821835037, w0=72.62673267326743, w1=15.973854819154592\n",
      "SubGD iter. 336/499: loss=2.655287531463763, w0=72.62673267326743, w1=15.972245158433505\n",
      "SubGD iter. 337/499: loss=2.6552916854890363, w0=72.62673267326743, w1=15.970635497712419\n",
      "SubGD iter. 338/499: loss=2.6553115214965013, w0=72.63366336633673, w1=15.975104197519823\n",
      "SubGD iter. 339/499: loss=2.655288374166335, w0=72.62673267326743, w1=15.972978097734085\n",
      "SubGD iter. 340/499: loss=2.655289345999243, w0=72.62673267326743, w1=15.971368437012998\n",
      "SubGD iter. 341/499: loss=2.6553126345694213, w0=72.63366336633673, w1=15.975837136820402\n",
      "SubGD iter. 342/499: loss=2.655289216868908, w0=72.62673267326743, w1=15.973711037034665\n",
      "SubGD iter. 343/499: loss=2.655287366149168, w0=72.62673267326743, w1=15.972101376313578\n",
      "SubGD iter. 344/499: loss=2.6552921444312725, w0=72.62673267326743, w1=15.970491715592491\n",
      "SubGD iter. 345/499: loss=2.655311303142833, w0=72.63366336633673, w1=15.974960415399895\n",
      "SubGD iter. 346/499: loss=2.6552882088517418, w0=72.62673267326743, w1=15.972834315614158\n",
      "SubGD iter. 347/499: loss=2.6552898049414795, w0=72.62673267326743, w1=15.97122465489307\n",
      "SubGD iter. 348/499: loss=2.655312416215754, w0=72.63366336633673, w1=15.975693354700475\n",
      "SubGD iter. 349/499: loss=2.655289051554315, w0=72.62673267326743, w1=15.973567254914737\n",
      "SubGD iter. 350/499: loss=2.655287465451686, w0=72.62673267326743, w1=15.97195759419365\n",
      "SubGD iter. 351/499: loss=2.6553135292886765, w0=72.63366336633673, w1=15.976426294001055\n",
      "SubGD iter. 352/499: loss=2.65528989425689, w0=72.62673267326743, w1=15.974300194215317\n",
      "SubGD iter. 353/499: loss=2.655288043537149, w0=72.62673267326743, w1=15.97269053349423\n",
      "SubGD iter. 354/499: loss=2.6552902638837157, w0=72.62673267326743, w1=15.971080872773143\n",
      "SubGD iter. 355/499: loss=2.655312197862086, w0=72.63366336633673, w1=15.975549572580547\n",
      "SubGD iter. 356/499: loss=2.6552888862397235, w0=72.62673267326743, w1=15.97342347279481\n",
      "SubGD iter. 357/499: loss=2.6552879243939222, w0=72.62673267326743, w1=15.971813812073723\n",
      "SubGD iter. 358/499: loss=2.6553133109350084, w0=72.63366336633673, w1=15.976282511881127\n",
      "SubGD iter. 359/499: loss=2.655289728942297, w0=72.62673267326743, w1=15.97415641209539\n",
      "SubGD iter. 360/499: loss=2.655287878222556, w0=72.62673267326743, w1=15.972546751374303\n",
      "SubGD iter. 361/499: loss=2.655290722825954, w0=72.62673267326743, w1=15.970937090653216\n",
      "SubGD iter. 362/499: loss=2.6553119795084212, w0=72.63366336633673, w1=15.97540579046062\n",
      "SubGD iter. 363/499: loss=2.6552887209251286, w0=72.62673267326743, w1=15.973279690674882\n",
      "SubGD iter. 364/499: loss=2.6552883833361602, w0=72.62673267326743, w1=15.971670029953795\n",
      "SubGD iter. 365/499: loss=2.6553130925813413, w0=72.63366336633673, w1=15.9761387297612\n",
      "SubGD iter. 366/499: loss=2.655289563627703, w0=72.62673267326743, w1=15.974012629975462\n",
      "SubGD iter. 367/499: loss=2.655287712907961, w0=72.62673267326743, w1=15.972402969254375\n",
      "SubGD iter. 368/499: loss=2.6552911817681895, w0=72.62673267326743, w1=15.970793308533288\n",
      "SubGD iter. 369/499: loss=2.655311761154752, w0=72.63366336633673, w1=15.975262008340692\n",
      "SubGD iter. 370/499: loss=2.655288555610534, w0=72.62673267326743, w1=15.973135908554955\n",
      "SubGD iter. 371/499: loss=2.6552888422783973, w0=72.62673267326743, w1=15.971526247833868\n",
      "SubGD iter. 372/499: loss=2.655312874227674, w0=72.63366336633673, w1=15.975994947641272\n",
      "SubGD iter. 373/499: loss=2.6552893983131085, w0=72.62673267326743, w1=15.973868847855535\n",
      "SubGD iter. 374/499: loss=2.655287547593368, w0=72.62673267326743, w1=15.972259187134448\n",
      "SubGD iter. 375/499: loss=2.655291640710427, w0=72.62673267326743, w1=15.97064952641336\n",
      "SubGD iter. 376/499: loss=2.6553115428010843, w0=72.63366336633673, w1=15.975118226220765\n",
      "SubGD iter. 377/499: loss=2.6552883902959414, w0=72.62673267326743, w1=15.972992126435027\n",
      "SubGD iter. 378/499: loss=2.655289301220632, w0=72.62673267326743, w1=15.97138246571394\n",
      "SubGD iter. 379/499: loss=2.655312655874006, w0=72.63366336633673, w1=15.975851165521345\n",
      "SubGD iter. 380/499: loss=2.655289232998515, w0=72.62673267326743, w1=15.973725065735607\n",
      "SubGD iter. 381/499: loss=2.655287382278775, w0=72.62673267326743, w1=15.97211540501452\n",
      "SubGD iter. 382/499: loss=2.655292099652663, w0=72.62673267326743, w1=15.970505744293433\n",
      "SubGD iter. 383/499: loss=2.6553113244474185, w0=72.63366336633673, w1=15.974974444100837\n",
      "SubGD iter. 384/499: loss=2.6552882249813483, w0=72.62673267326743, w1=15.9728483443151\n",
      "SubGD iter. 385/499: loss=2.655289760162869, w0=72.62673267326743, w1=15.971238683594013\n",
      "SubGD iter. 386/499: loss=2.655312437520339, w0=72.63366336633673, w1=15.975707383401417\n",
      "SubGD iter. 387/499: loss=2.6552890676839223, w0=72.62673267326743, w1=15.97358128361568\n",
      "SubGD iter. 388/499: loss=2.6552874206730754, w0=72.62673267326743, w1=15.971971622894593\n",
      "SubGD iter. 389/499: loss=2.6553135505932595, w0=72.63366336633673, w1=15.976440322701997\n",
      "SubGD iter. 390/499: loss=2.6552899103864975, w0=72.62673267326743, w1=15.97431422291626\n",
      "SubGD iter. 391/499: loss=2.6552880596667556, w0=72.62673267326743, w1=15.972704562195172\n",
      "SubGD iter. 392/499: loss=2.6552902191051055, w0=72.62673267326743, w1=15.971094901474086\n",
      "SubGD iter. 393/499: loss=2.6553122191666723, w0=72.63366336633673, w1=15.97556360128149\n",
      "SubGD iter. 394/499: loss=2.6552889023693287, w0=72.62673267326743, w1=15.973437501495752\n",
      "SubGD iter. 395/499: loss=2.6552878796153143, w0=72.62673267326743, w1=15.971827840774665\n",
      "SubGD iter. 396/499: loss=2.6553133322395914, w0=72.63366336633673, w1=15.97629654058207\n",
      "SubGD iter. 397/499: loss=2.655289745071902, w0=72.62673267326743, w1=15.974170440796332\n",
      "SubGD iter. 398/499: loss=2.655287894352162, w0=72.62673267326743, w1=15.972560780075245\n",
      "SubGD iter. 399/499: loss=2.6552906780473435, w0=72.62673267326743, w1=15.970951119354158\n",
      "SubGD iter. 400/499: loss=2.655312000813004, w0=72.63366336633673, w1=15.975419819161562\n",
      "SubGD iter. 401/499: loss=2.6552887370547356, w0=72.62673267326743, w1=15.973293719375825\n",
      "SubGD iter. 402/499: loss=2.6552883385575505, w0=72.62673267326743, w1=15.971684058654738\n",
      "SubGD iter. 403/499: loss=2.655313113885926, w0=72.63366336633673, w1=15.976152758462142\n",
      "SubGD iter. 404/499: loss=2.655289579757308, w0=72.62673267326743, w1=15.974026658676404\n",
      "SubGD iter. 405/499: loss=2.655287729037569, w0=72.62673267326743, w1=15.972416997955317\n",
      "SubGD iter. 406/499: loss=2.65529113698958, w0=72.62673267326743, w1=15.97080733723423\n",
      "SubGD iter. 407/499: loss=2.655311782459336, w0=72.63366336633673, w1=15.975276037041635\n",
      "SubGD iter. 408/499: loss=2.6552885717401424, w0=72.62673267326743, w1=15.973149937255897\n",
      "SubGD iter. 409/499: loss=2.655288797499786, w0=72.62673267326743, w1=15.97154027653481\n",
      "SubGD iter. 410/499: loss=2.655312895532257, w0=72.63366336633673, w1=15.976008976342214\n",
      "SubGD iter. 411/499: loss=2.6552894144427155, w0=72.62673267326743, w1=15.973882876556477\n",
      "SubGD iter. 412/499: loss=2.6552875637229745, w0=72.62673267326743, w1=15.97227321583539\n",
      "SubGD iter. 413/499: loss=2.6552915959318173, w0=72.62673267326743, w1=15.970663555114303\n",
      "SubGD iter. 414/499: loss=2.655311564105669, w0=72.63366336633673, w1=15.975132254921707\n",
      "SubGD iter. 415/499: loss=2.655288406425549, w0=72.62673267326743, w1=15.97300615513597\n",
      "SubGD iter. 416/499: loss=2.655289256442024, w0=72.62673267326743, w1=15.971396494414883\n",
      "SubGD iter. 417/499: loss=2.6553126771785918, w0=72.63366336633673, w1=15.975865194222287\n",
      "SubGD iter. 418/499: loss=2.6552892491281224, w0=72.62673267326743, w1=15.97373909443655\n",
      "SubGD iter. 419/499: loss=2.655287398408381, w0=72.62673267326743, w1=15.972129433715462\n",
      "SubGD iter. 420/499: loss=2.655292054874053, w0=72.62673267326743, w1=15.970519772994376\n",
      "SubGD iter. 421/499: loss=2.655311345752003, w0=72.63366336633673, w1=15.97498847280178\n",
      "SubGD iter. 422/499: loss=2.6552882411109557, w0=72.62673267326743, w1=15.972862373016042\n",
      "SubGD iter. 423/499: loss=2.6552897153842605, w0=72.62673267326743, w1=15.971252712294955\n",
      "SubGD iter. 424/499: loss=2.655312458824922, w0=72.63366336633673, w1=15.97572141210236\n",
      "SubGD iter. 425/499: loss=2.655289083813528, w0=72.62673267326743, w1=15.973595312316622\n",
      "SubGD iter. 426/499: loss=2.655287375894467, w0=72.62673267326743, w1=15.971985651595535\n",
      "SubGD iter. 427/499: loss=2.655313571897845, w0=72.63366336633673, w1=15.97645435140294\n",
      "SubGD iter. 428/499: loss=2.655289926516102, w0=72.62673267326743, w1=15.974328251617202\n",
      "SubGD iter. 429/499: loss=2.6552880757963617, w0=72.62673267326743, w1=15.972718590896115\n",
      "SubGD iter. 430/499: loss=2.655290174326498, w0=72.62673267326743, w1=15.971108930175028\n",
      "SubGD iter. 431/499: loss=2.655312240471256, w0=72.63366336633673, w1=15.975577629982432\n",
      "SubGD iter. 432/499: loss=2.655288918498935, w0=72.62673267326743, w1=15.973451530196694\n",
      "SubGD iter. 433/499: loss=2.655287834836702, w0=72.62673267326743, w1=15.971841869475607\n",
      "SubGD iter. 434/499: loss=2.655313353544177, w0=72.63366336633673, w1=15.976310569283012\n",
      "SubGD iter. 435/499: loss=2.655289761201509, w0=72.62673267326743, w1=15.974184469497274\n",
      "SubGD iter. 436/499: loss=2.655287910481768, w0=72.62673267326743, w1=15.972574808776187\n",
      "SubGD iter. 437/499: loss=2.6552906332687343, w0=72.62673267326743, w1=15.9709651480551\n",
      "SubGD iter. 438/499: loss=2.655312022117588, w0=72.63366336633673, w1=15.975433847862504\n",
      "SubGD iter. 439/499: loss=2.65528875318434, w0=72.62673267326743, w1=15.973307748076767\n",
      "SubGD iter. 440/499: loss=2.6552882937789413, w0=72.62673267326743, w1=15.97169808735568\n",
      "SubGD iter. 441/499: loss=2.655313135190509, w0=72.63366336633673, w1=15.976166787163084\n",
      "SubGD iter. 442/499: loss=2.6552895958869143, w0=72.62673267326743, w1=15.974040687377347\n",
      "SubGD iter. 443/499: loss=2.655287745167174, w0=72.62673267326743, w1=15.97243102665626\n",
      "SubGD iter. 444/499: loss=2.6552910922109696, w0=72.62673267326743, w1=15.970821365935173\n",
      "SubGD iter. 445/499: loss=2.6553118037639196, w0=72.63366336633673, w1=15.975290065742577\n",
      "SubGD iter. 446/499: loss=2.655288587869748, w0=72.62673267326743, w1=15.97316396595684\n",
      "SubGD iter. 447/499: loss=2.6552887527211766, w0=72.62673267326743, w1=15.971554305235752\n",
      "SubGD iter. 448/499: loss=2.655312916836842, w0=72.63366336633673, w1=15.976023005043157\n",
      "SubGD iter. 449/499: loss=2.655289430572321, w0=72.62673267326743, w1=15.97389690525742\n",
      "SubGD iter. 450/499: loss=2.655287579852583, w0=72.62673267326743, w1=15.972287244536332\n",
      "SubGD iter. 451/499: loss=2.6552915511532063, w0=72.62673267326743, w1=15.970677583815245\n",
      "SubGD iter. 452/499: loss=2.655311585410253, w0=72.63366336633673, w1=15.97514628362265\n",
      "SubGD iter. 453/499: loss=2.6552884225551527, w0=72.62673267326743, w1=15.973020183836912\n",
      "SubGD iter. 454/499: loss=2.655289211663416, w0=72.62673267326743, w1=15.971410523115825\n",
      "SubGD iter. 455/499: loss=2.655312698483175, w0=72.63366336633673, w1=15.97587922292323\n",
      "SubGD iter. 456/499: loss=2.655289265257728, w0=72.62673267326743, w1=15.973753123137492\n",
      "SubGD iter. 457/499: loss=2.655287414537987, w0=72.62673267326743, w1=15.972143462416405\n",
      "SubGD iter. 458/499: loss=2.6552920100954442, w0=72.62673267326743, w1=15.970533801695318\n",
      "SubGD iter. 459/499: loss=2.655311367056587, w0=72.63366336633673, w1=15.975002501502722\n",
      "SubGD iter. 460/499: loss=2.65528825724056, w0=72.62673267326743, w1=15.972876401716984\n",
      "SubGD iter. 461/499: loss=2.6552896706056517, w0=72.62673267326743, w1=15.971266740995897\n",
      "SubGD iter. 462/499: loss=2.655312480129508, w0=72.63366336633673, w1=15.975735440803302\n",
      "SubGD iter. 463/499: loss=2.655289099943134, w0=72.62673267326743, w1=15.973609341017564\n",
      "SubGD iter. 464/499: loss=2.6552873311158574, w0=72.62673267326743, w1=15.971999680296477\n",
      "SubGD iter. 465/499: loss=2.655313593202429, w0=72.63366336633673, w1=15.976468380103881\n",
      "SubGD iter. 466/499: loss=2.655289942645707, w0=72.62673267326743, w1=15.974342280318144\n",
      "SubGD iter. 467/499: loss=2.655288091925969, w0=72.62673267326743, w1=15.972732619597057\n",
      "SubGD iter. 468/499: loss=2.6552901295478883, w0=72.62673267326743, w1=15.97112295887597\n",
      "SubGD iter. 469/499: loss=2.6553122617758405, w0=72.63366336633673, w1=15.975591658683374\n",
      "SubGD iter. 470/499: loss=2.6552889346285413, w0=72.62673267326743, w1=15.973465558897637\n",
      "SubGD iter. 471/499: loss=2.6552877900580936, w0=72.62673267326743, w1=15.97185589817655\n",
      "SubGD iter. 472/499: loss=2.655313374848762, w0=72.63366336633673, w1=15.976324597983954\n",
      "SubGD iter. 473/499: loss=2.6552897773311144, w0=72.62673267326743, w1=15.974198498198216\n",
      "SubGD iter. 474/499: loss=2.655287926611373, w0=72.62673267326743, w1=15.97258883747713\n",
      "SubGD iter. 475/499: loss=2.655290588490126, w0=72.62673267326743, w1=15.970979176756043\n",
      "SubGD iter. 476/499: loss=2.655312043422172, w0=72.63366336633673, w1=15.975447876563447\n",
      "SubGD iter. 477/499: loss=2.6552887693139486, w0=72.62673267326743, w1=15.97332177677771\n",
      "SubGD iter. 478/499: loss=2.6552882490003302, w0=72.62673267326743, w1=15.971712116056622\n",
      "SubGD iter. 479/499: loss=2.6553131564950934, w0=72.63366336633673, w1=15.976180815864026\n",
      "SubGD iter. 480/499: loss=2.6552896120165213, w0=72.62673267326743, w1=15.974054716078289\n",
      "SubGD iter. 481/499: loss=2.6552877612967802, w0=72.62673267326743, w1=15.972445055357202\n",
      "SubGD iter. 482/499: loss=2.655291047432361, w0=72.62673267326743, w1=15.970835394636115\n",
      "SubGD iter. 483/499: loss=2.655311825068504, w0=72.63366336633673, w1=15.97530409444352\n",
      "SubGD iter. 484/499: loss=2.655288603999354, w0=72.62673267326743, w1=15.973177994657782\n",
      "SubGD iter. 485/499: loss=2.655288707942567, w0=72.62673267326743, w1=15.971568333936695\n",
      "SubGD iter. 486/499: loss=2.655312938141426, w0=72.63366336633673, w1=15.976037033744099\n",
      "SubGD iter. 487/499: loss=2.6552894467019286, w0=72.62673267326743, w1=15.973910933958361\n",
      "SubGD iter. 488/499: loss=2.6552875959821867, w0=72.62673267326743, w1=15.972301273237274\n",
      "SubGD iter. 489/499: loss=2.6552915063745988, w0=72.62673267326743, w1=15.970691612516188\n",
      "SubGD iter. 490/499: loss=2.6553116067148377, w0=72.63366336633673, w1=15.975160312323592\n",
      "SubGD iter. 491/499: loss=2.6552884386847615, w0=72.62673267326743, w1=15.973034212537854\n",
      "SubGD iter. 492/499: loss=2.655289166884805, w0=72.62673267326743, w1=15.971424551816767\n",
      "SubGD iter. 493/499: loss=2.6553127197877595, w0=72.63366336633673, w1=15.975893251624171\n",
      "SubGD iter. 494/499: loss=2.6552892813873354, w0=72.62673267326743, w1=15.973767151838434\n",
      "SubGD iter. 495/499: loss=2.6552874306675935, w0=72.62673267326743, w1=15.972157491117347\n",
      "SubGD iter. 496/499: loss=2.6552919653168354, w0=72.62673267326743, w1=15.97054783039626\n",
      "SubGD iter. 497/499: loss=2.6553113883611705, w0=72.63366336633673, w1=15.975016530203664\n",
      "SubGD iter. 498/499: loss=2.6552882733701666, w0=72.62673267326743, w1=15.972890430417927\n",
      "SubGD iter. 499/499: loss=2.6552896258270424, w0=72.62673267326743, w1=15.97128076969684\n",
      "SubGD: execution time=0.038 seconds\n"
     ]
    }
   ],
   "source": [
    "# Define the parameters of the algorithm.\n",
    "max_iters = 500\n",
    "gamma = 0.7\n",
    "batch_size = 1\n",
    "\n",
    "# Initialization\n",
    "w_initial = np.array([0, 0])\n",
    "\n",
    "# Start SubSGD.\n",
    "start_time = datetime.datetime.now()\n",
    "subgd_losses, subgd_ws = subgradient_descent(y, tx, w_initial, max_iters, gamma)\n",
    "end_time = datetime.datetime.now()\n",
    "\n",
    "# Print result\n",
    "exection_time = (end_time - start_time).total_seconds()\n",
    "print(\"SubGD: execution time={t:.3f} seconds\".format(t=exection_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "313e56811d5f4979a7634abc9775dc24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=1, description='n_iter', max=501, min=1), Output()), _dom_classes=('widg"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.plot_figure(n_iter)>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ipywidgets import IntSlider, interact\n",
    "\n",
    "\n",
    "def plot_figure(n_iter):\n",
    "    fig = gradient_descent_visualization(\n",
    "        subgd_losses,\n",
    "        subgd_ws,\n",
    "        grid_losses,\n",
    "        grid_w0,\n",
    "        grid_w1,\n",
    "        mean_x,\n",
    "        std_x,\n",
    "        height,\n",
    "        weight,\n",
    "        n_iter,\n",
    "    )\n",
    "    fig.set_size_inches(10.0, 6.0)\n",
    "\n",
    "\n",
    "interact(plot_figure, n_iter=IntSlider(min=1, max=len(subgd_ws)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stochastic Subgradient Descent\n",
    "\n",
    "**NB** for the computation of the subgradient you can reuse the `compute_subgradient` method that you implemented above, just making sure that you pass in a minibatch as opposed to the full data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stochastic_subgradient_descent(y, tx, initial_w, batch_size, max_iters, gamma):\n",
    "    \"\"\"Compute a stochastic subgradient at w from a data sample batch of size B, where B < N, and their corresponding labels.\n",
    "\n",
    "    Args:\n",
    "        y: numpy array of shape=(B, )\n",
    "        tx: numpy array of shape=(B,2)\n",
    "        initial_w: numpy array of shape=(2, ). The initial guess (or the initialization) for the model parameters\n",
    "        batch_size: a scalar denoting the number of data points in a mini-batch used for computing the stochastic subgradient\n",
    "        max_iters: a scalar denoting the total number of iterations of SubSGD\n",
    "        gamma: a scalar denoting the stepsize\n",
    "\n",
    "    Returns:\n",
    "        losses: a list of length max_iters containing the loss value (scalar) for each iteration of SubSGD\n",
    "        ws: a list of length max_iters containing the model parameters as numpy arrays of shape (2, ), for each iteration of SubSGD\n",
    "    \"\"\"\n",
    "\n",
    "    # Define parameters to store w and loss\n",
    "    ws = [initial_w]\n",
    "    losses = []\n",
    "    w = initial_w\n",
    "\n",
    "    for n_iter in range(max_iters):\n",
    "        # ***************************************************\n",
    "        # INSERT YOUR CODE HERE\n",
    "        # TODO: implement stochastic subgradient descent.\n",
    "        for y_batched, tx_batched in batch_iter(y=y,tx=tx,batch_size=batch_size):\n",
    "            loss = compute_loss(y_batched,tx_batched,w, MSE=False)\n",
    "            w = w - gamma * compute_subgradient_mae(y_batched,tx_batched,w)\n",
    "        ws.append(w)\n",
    "        losses.append(loss)\n",
    "        # ***************************************************\n",
    "\n",
    "        print(\n",
    "            \"SubSGD iter. {bi}/{ti}: loss={l}, w0={w0}, w1={w1}\".format(\n",
    "                bi=n_iter, ti=max_iters - 1, l=loss, w0=w[0], w1=w[1]\n",
    "            )\n",
    "        )\n",
    "    return losses, ws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SubSGD iter. 0/499: loss=29.742046300567097, w0=0.7, w1=-0.6965847512407627\n",
      "SubSGD iter. 1/499: loss=44.60724097773134, w0=1.4, w1=0.06477219937830658\n",
      "SubSGD iter. 2/499: loss=39.70958453833837, w0=2.0999999999999996, w1=0.40848482056169716\n",
      "SubSGD iter. 3/499: loss=28.682608057322557, w0=2.8, w1=-0.01475460421081709\n",
      "SubSGD iter. 4/499: loss=47.11211486541779, w0=3.5, w1=1.1912616855596299\n",
      "SubSGD iter. 5/499: loss=38.563029970215716, w0=4.2, w1=1.848444388754615\n",
      "SubSGD iter. 6/499: loss=36.99519958674307, w0=4.9, w1=1.9917749793491313\n",
      "SubSGD iter. 7/499: loss=28.60392430945605, w0=5.6000000000000005, w1=1.552086574263947\n",
      "SubSGD iter. 8/499: loss=41.73322844429849, w0=6.300000000000001, w1=2.1667475553943336\n",
      "SubSGD iter. 9/499: loss=25.25421780241269, w0=7.000000000000001, w1=1.1899500764524147\n",
      "SubSGD iter. 10/499: loss=31.414799312928437, w0=7.700000000000001, w1=1.4506622978342785\n",
      "SubSGD iter. 11/499: loss=21.083403492791618, w0=8.4, w1=0.7700631201781958\n",
      "SubSGD iter. 12/499: loss=50.090966636456415, w0=9.1, w1=1.8951930803085029\n",
      "SubSGD iter. 13/499: loss=23.664750854798953, w0=9.799999999999999, w1=0.918395601366584\n",
      "SubSGD iter. 14/499: loss=42.047065765984385, w0=10.499999999999998, w1=2.1131344384710093\n",
      "SubSGD iter. 15/499: loss=23.529078174300196, w0=11.199999999999998, w1=1.9932426249826782\n",
      "SubSGD iter. 16/499: loss=29.809967624323697, w0=11.899999999999997, w1=1.6568796673066015\n",
      "SubSGD iter. 17/499: loss=38.042988371142926, w0=12.599999999999996, w1=2.53660979713908\n",
      "SubSGD iter. 18/499: loss=25.378007130380894, w0=13.299999999999995, w1=2.179884278783243\n",
      "SubSGD iter. 19/499: loss=31.298866402791962, w0=13.999999999999995, w1=2.4446693879740113\n",
      "SubSGD iter. 20/499: loss=37.9856675265732, w0=14.699999999999994, w1=3.323841700204818\n",
      "SubSGD iter. 21/499: loss=32.81275638022083, w0=15.399999999999993, w1=3.772500738989528\n",
      "SubSGD iter. 22/499: loss=22.9608207669014, w0=16.099999999999994, w1=3.4273236512645298\n",
      "SubSGD iter. 23/499: loss=28.286555662678964, w0=16.799999999999994, w1=3.3003092060365047\n",
      "SubSGD iter. 24/499: loss=27.92503232746712, w0=17.499999999999993, w1=3.1732947608084796\n",
      "SubSGD iter. 25/499: loss=21.213239856418863, w0=18.199999999999992, w1=2.8933657683720164\n",
      "SubSGD iter. 26/499: loss=33.90757526340181, w0=18.89999999999999, w1=3.6183859584528206\n",
      "SubSGD iter. 27/499: loss=36.53877742167961, w0=19.59999999999999, w1=3.9628542053232882\n",
      "SubSGD iter. 28/499: loss=19.11255287922195, w0=20.29999999999999, w1=3.415691903089418\n",
      "SubSGD iter. 29/499: loss=19.850644505879693, w0=20.99999999999999, w1=2.910674171265096\n",
      "SubSGD iter. 30/499: loss=17.77601123195054, w0=21.69999999999999, w1=2.176559848264107\n",
      "SubSGD iter. 31/499: loss=21.426986187600825, w0=22.399999999999988, w1=1.8062917577353104\n",
      "SubSGD iter. 32/499: loss=22.305235342916262, w0=23.099999999999987, w1=1.440371027004913\n",
      "SubSGD iter. 33/499: loss=33.63931197095548, w0=23.799999999999986, w1=2.6087018275223817\n",
      "SubSGD iter. 34/499: loss=17.832761928858606, w0=24.499999999999986, w1=2.594946631546891\n",
      "SubSGD iter. 35/499: loss=23.70324094861222, w0=25.199999999999985, w1=2.4114808524964717\n",
      "SubSGD iter. 36/499: loss=29.611894429134864, w0=25.899999999999984, w1=2.8389979377138896\n",
      "SubSGD iter. 37/499: loss=18.89004612871483, w0=26.599999999999984, w1=2.235231867747376\n",
      "SubSGD iter. 38/499: loss=20.2321810872483, w0=27.299999999999983, w1=1.495899068303432\n",
      "SubSGD iter. 39/499: loss=16.051035022447174, w0=27.999999999999982, w1=0.968942032534584\n",
      "SubSGD iter. 40/499: loss=31.738451128386828, w0=28.69999999999998, w1=1.802279615094161\n",
      "SubSGD iter. 41/499: loss=40.792381638203665, w0=29.39999999999998, w1=3.041595916072162\n",
      "SubSGD iter. 42/499: loss=25.717986199900466, w0=30.09999999999998, w1=3.999731006973969\n",
      "SubSGD iter. 43/499: loss=15.31678380503632, w0=30.79999999999998, w1=3.3428500392210054\n",
      "SubSGD iter. 44/499: loss=13.054893877161296, w0=31.49999999999998, w1=2.911057460937585\n",
      "SubSGD iter. 45/499: loss=15.682456731987887, w0=32.19999999999998, w1=2.057211190512316\n",
      "SubSGD iter. 46/499: loss=11.160614575359219, w0=32.899999999999984, w1=1.2385528207066878\n",
      "SubSGD iter. 47/499: loss=24.93268676115494, w0=33.59999999999999, w1=1.843084926560847\n",
      "SubSGD iter. 48/499: loss=29.466273605556754, w0=34.29999999999999, w1=2.699306979065385\n",
      "SubSGD iter. 49/499: loss=13.275155380623442, w0=34.99999999999999, w1=2.276067554292871\n",
      "SubSGD iter. 50/499: loss=24.34674469180235, w0=35.699999999999996, w1=2.726247300499165\n",
      "SubSGD iter. 51/499: loss=11.919264369660027, w0=36.4, w1=2.0693663327462013\n",
      "SubSGD iter. 52/499: loss=22.10180660253488, w0=37.1, w1=2.234819124678827\n",
      "SubSGD iter. 53/499: loss=6.797406762929516, w0=37.800000000000004, w1=1.1450241016056069\n",
      "SubSGD iter. 54/499: loss=14.266118776104733, w0=38.50000000000001, w1=0.960863323287287\n",
      "SubSGD iter. 55/499: loss=25.303527449425612, w0=39.20000000000001, w1=1.5931377517689778\n",
      "SubSGD iter. 56/499: loss=24.644397105847975, w0=39.90000000000001, w1=2.4983128549560414\n",
      "SubSGD iter. 57/499: loss=23.909177432314678, w0=40.600000000000016, w1=3.130587283437732\n",
      "SubSGD iter. 58/499: loss=19.924688766554837, w0=41.30000000000002, w1=3.5792463222224424\n",
      "SubSGD iter. 59/499: loss=13.81985736166125, w0=42.00000000000002, w1=3.839958543604306\n",
      "SubSGD iter. 60/499: loss=9.903118740431719, w0=42.700000000000024, w1=3.622701539424556\n",
      "SubSGD iter. 61/499: loss=10.25582162361437, w0=43.40000000000003, w1=3.22726474748155\n",
      "SubSGD iter. 62/499: loss=9.168779971890544, w0=44.10000000000003, w1=2.6842482861164516\n",
      "SubSGD iter. 63/499: loss=20.14992999543842, w0=44.80000000000003, w1=2.949731988340682\n",
      "SubSGD iter. 64/499: loss=16.06955198731038, w0=45.500000000000036, w1=2.965039655052818\n",
      "SubSGD iter. 65/499: loss=8.740151152252707, w0=46.20000000000004, w1=2.539253507762079\n",
      "SubSGD iter. 66/499: loss=16.210976996582882, w0=46.90000000000004, w1=2.5656261583869\n",
      "SubSGD iter. 67/499: loss=11.915027667061892, w0=47.600000000000044, w1=2.0409932336751604\n",
      "SubSGD iter. 68/499: loss=21.300322159573525, w0=48.30000000000005, w1=2.874330816234737\n",
      "SubSGD iter. 69/499: loss=5.655360971464447, w0=49.00000000000005, w1=2.369313084410415\n",
      "SubSGD iter. 70/499: loss=16.663183800123072, w0=49.70000000000005, w1=3.3162253461528453\n",
      "SubSGD iter. 71/499: loss=15.428801518198686, w0=50.400000000000055, w1=3.6947651295095767\n",
      "SubSGD iter. 72/499: loss=6.993789439468628, w0=51.10000000000006, w1=3.544308453058449\n",
      "SubSGD iter. 73/499: loss=11.031999473427636, w0=51.80000000000006, w1=3.509617593716978\n",
      "SubSGD iter. 74/499: loss=13.663843938295713, w0=52.500000000000064, w1=3.8533302149003683\n",
      "SubSGD iter. 75/499: loss=0.1485580725399629, w0=51.80000000000006, w1=4.533929392556451\n",
      "SubSGD iter. 76/499: loss=5.271232487351284, w0=52.500000000000064, w1=4.1868454069364605\n",
      "SubSGD iter. 77/499: loss=7.316250332601115, w0=53.20000000000007, w1=4.00268462861814\n",
      "SubSGD iter. 78/499: loss=16.919445882567896, w0=53.90000000000007, w1=4.626172750904318\n",
      "SubSGD iter. 79/499: loss=6.674040950887999, w0=54.60000000000007, w1=4.4420119725859974\n",
      "SubSGD iter. 80/499: loss=14.069392921936608, w0=55.300000000000075, w1=5.055926385963581\n",
      "SubSGD iter. 81/499: loss=4.053384706694391, w0=56.00000000000008, w1=4.81189956125443\n",
      "SubSGD iter. 82/499: loss=24.47818802461436, w0=56.70000000000008, w1=6.051215862232431\n",
      "SubSGD iter. 83/499: loss=10.894820027881451, w0=57.400000000000084, w1=6.077588512857252\n",
      "SubSGD iter. 84/499: loss=14.563925549664212, w0=58.10000000000009, w1=7.283604802627699\n",
      "SubSGD iter. 85/499: loss=7.636415242024405, w0=58.80000000000009, w1=7.156590357399674\n",
      "SubSGD iter. 86/499: loss=9.755798444347587, w0=59.50000000000009, w1=7.406188820086852\n",
      "SubSGD iter. 87/499: loss=5.079463040920935, w0=60.200000000000095, w1=8.011591971530837\n",
      "SubSGD iter. 88/499: loss=8.358029889097466, w0=60.9000000000001, w1=8.616124077384997\n",
      "SubSGD iter. 89/499: loss=0.24289367771101666, w0=61.6000000000001, w1=7.776096505925186\n",
      "SubSGD iter. 90/499: loss=4.1339278257167535, w0=62.300000000000104, w1=8.324491009682998\n",
      "SubSGD iter. 91/499: loss=1.4424753185138606, w0=63.00000000000011, w1=8.299193244294155\n",
      "SubSGD iter. 92/499: loss=6.264054888882914, w0=63.70000000000011, w1=8.266764236526795\n",
      "SubSGD iter. 93/499: loss=3.603001239855466, w0=63.00000000000011, w1=8.947363414182878\n",
      "SubSGD iter. 94/499: loss=1.0057504251913194, w0=63.70000000000011, w1=8.420406378414029\n",
      "SubSGD iter. 95/499: loss=1.8150269941910686, w0=64.4000000000001, w1=7.649583312345841\n",
      "SubSGD iter. 96/499: loss=3.2932849263017374, w0=65.10000000000011, w1=7.076573229331218\n",
      "SubSGD iter. 97/499: loss=11.226951718777052, w0=65.80000000000011, w1=7.689565726514777\n",
      "SubSGD iter. 98/499: loss=9.049665015375624, w0=66.50000000000011, w1=7.900730121080981\n",
      "SubSGD iter. 99/499: loss=5.230681757787984, w0=67.20000000000012, w1=8.493048082349159\n",
      "SubSGD iter. 100/499: loss=0.6738983043022344, w0=66.50000000000011, w1=9.114099655919752\n",
      "SubSGD iter. 101/499: loss=3.0151184429019473, w0=65.80000000000011, w1=9.545892234203173\n",
      "SubSGD iter. 102/499: loss=0.7233248267864312, w0=65.10000000000011, w1=10.489398717740293\n",
      "SubSGD iter. 103/499: loss=1.1544090947208545, w0=65.80000000000011, w1=10.132673199384456\n",
      "SubSGD iter. 104/499: loss=5.482490716655004, w0=66.50000000000011, w1=9.736696956162623\n",
      "SubSGD iter. 105/499: loss=2.345347322177332, w0=67.20000000000012, w1=8.882850685737354\n",
      "SubSGD iter. 106/499: loss=11.039734710496894, w0=67.90000000000012, w1=10.42291302412454\n",
      "SubSGD iter. 107/499: loss=1.6195579338278137, w0=68.60000000000012, w1=10.04732718583797\n",
      "SubSGD iter. 108/499: loss=5.131929095822876, w0=69.30000000000013, w1=10.08461449745584\n",
      "SubSGD iter. 109/499: loss=1.3013062485511497, w0=70.00000000000013, w1=10.439641974985665\n",
      "SubSGD iter. 110/499: loss=6.416330561314226, w0=70.70000000000013, w1=11.452080312852086\n",
      "SubSGD iter. 111/499: loss=4.1583590071909775, w0=70.00000000000013, w1=12.288119170124903\n",
      "SubSGD iter. 112/499: loss=3.36744561687631, w0=70.70000000000013, w1=12.303426836837039\n",
      "SubSGD iter. 113/499: loss=2.606660619299646, w0=70.00000000000013, w1=12.855398268774717\n",
      "SubSGD iter. 114/499: loss=2.5519512792318366, w0=70.70000000000013, w1=13.913313575602276\n",
      "SubSGD iter. 115/499: loss=4.34931597382214, w0=71.40000000000013, w1=13.17398077615833\n",
      "SubSGD iter. 116/499: loss=0.1853449482325189, w0=72.10000000000014, w1=12.969147256283108\n",
      "SubSGD iter. 117/499: loss=3.7357128396253927, w0=72.80000000000014, w1=14.334516708946719\n",
      "SubSGD iter. 118/499: loss=0.3935879029441196, w0=72.10000000000014, w1=13.429341605759655\n",
      "SubSGD iter. 119/499: loss=2.0430169769840703, w0=72.80000000000014, w1=13.173909724658085\n",
      "SubSGD iter. 120/499: loss=1.716091587224284, w0=72.10000000000014, w1=14.075541989070842\n",
      "SubSGD iter. 121/499: loss=2.774452324931797, w0=71.40000000000013, w1=14.319568813779993\n",
      "SubSGD iter. 122/499: loss=0.7455452568267447, w0=72.10000000000014, w1=15.377484120607551\n",
      "SubSGD iter. 123/499: loss=1.3869488494309152, w0=72.80000000000014, w1=16.742853573271162\n",
      "SubSGD iter. 124/499: loss=0.3471705257154767, w0=73.50000000000014, w1=16.90865983283866\n",
      "SubSGD iter. 125/499: loss=5.822385618979787, w0=72.80000000000014, w1=15.950524741936851\n",
      "SubSGD iter. 126/499: loss=4.237766245206213, w0=73.50000000000014, w1=15.263830106430715\n",
      "SubSGD iter. 127/499: loss=2.5429938315688148, w0=74.20000000000014, w1=15.301117418048586\n",
      "SubSGD iter. 128/499: loss=1.4658567183093751, w0=73.50000000000014, w1=15.294689537170239\n",
      "SubSGD iter. 129/499: loss=0.3583095740707094, w0=72.80000000000014, w1=14.76663372165959\n",
      "SubSGD iter. 130/499: loss=4.211612188133273, w0=73.50000000000014, w1=14.36717594927301\n",
      "SubSGD iter. 131/499: loss=3.3570004449980146, w0=72.80000000000014, w1=13.943634696218995\n",
      "SubSGD iter. 132/499: loss=2.1887282174971965, w0=72.10000000000014, w1=14.762293066024624\n",
      "SubSGD iter. 133/499: loss=1.3600128414594757, w0=71.40000000000013, w1=15.580951435830253\n",
      "SubSGD iter. 134/499: loss=3.1821596260832337, w0=72.10000000000014, w1=14.996638898284361\n",
      "SubSGD iter. 135/499: loss=5.456621273388507, w0=72.80000000000014, w1=16.177443598984258\n",
      "SubSGD iter. 136/499: loss=5.508605648005243, w0=73.50000000000014, w1=17.302573559114563\n",
      "SubSGD iter. 137/499: loss=3.8221053575055564, w0=74.20000000000014, w1=17.061593644447914\n",
      "SubSGD iter. 138/499: loss=0.6238792781498788, w0=74.90000000000015, w1=17.676254625578302\n",
      "SubSGD iter. 139/499: loss=3.99180553439669, w0=75.60000000000015, w1=17.276796853191723\n",
      "SubSGD iter. 140/499: loss=1.1303969829102556, w0=74.90000000000015, w1=17.2953763120906\n",
      "SubSGD iter. 141/499: loss=3.3266946275475746, w0=74.20000000000014, w1=17.84253861432447\n",
      "SubSGD iter. 142/499: loss=0.4830685195412272, w0=73.50000000000014, w1=17.676732354756975\n",
      "SubSGD iter. 143/499: loss=1.3983099169518596, w0=72.80000000000014, w1=16.95171216467617\n",
      "SubSGD iter. 144/499: loss=0.8229782919980693, w0=73.50000000000014, w1=17.603769062118626\n",
      "SubSGD iter. 145/499: loss=2.42482043822724, w0=74.20000000000014, w1=16.626971583176708\n",
      "SubSGD iter. 146/499: loss=7.078000214304829, w0=73.50000000000014, w1=16.746863396665038\n",
      "SubSGD iter. 147/499: loss=1.2789665152483138, w0=72.80000000000014, w1=15.985506446045969\n",
      "SubSGD iter. 148/499: loss=3.4965931067542613, w0=72.10000000000014, w1=15.561965192991954\n",
      "SubSGD iter. 149/499: loss=1.0716535848944133, w0=71.40000000000013, w1=16.450797017158447\n",
      "SubSGD iter. 150/499: loss=5.117042553251988, w0=70.70000000000013, w1=16.394487402113143\n",
      "SubSGD iter. 151/499: loss=5.286686790108504, w0=71.40000000000013, w1=16.605651796679346\n",
      "SubSGD iter. 152/499: loss=3.4962374763024116, w0=72.10000000000014, w1=16.75854555379393\n",
      "SubSGD iter. 153/499: loss=5.479420554415345, w0=71.40000000000013, w1=16.702235938748625\n",
      "SubSGD iter. 154/499: loss=2.034377468725115, w0=70.70000000000013, w1=17.21073705648846\n",
      "SubSGD iter. 155/499: loss=0.24301579713914379, w0=71.40000000000013, w1=17.935757246569263\n",
      "SubSGD iter. 156/499: loss=0.024247003830232927, w0=70.70000000000013, w1=17.406056272507147\n",
      "SubSGD iter. 157/499: loss=1.567866688516446, w0=71.40000000000013, w1=18.05220350589437\n",
      "SubSGD iter. 158/499: loss=7.305189747988262, w0=72.10000000000014, w1=17.433062350479986\n",
      "SubSGD iter. 159/499: loss=1.8503251743383409, w0=72.80000000000014, w1=16.638693005989207\n",
      "SubSGD iter. 160/499: loss=1.3155207106387437, w0=73.50000000000014, w1=17.255079954826456\n",
      "SubSGD iter. 161/499: loss=1.2806447306906676, w0=72.80000000000014, w1=16.96658269026904\n",
      "SubSGD iter. 162/499: loss=3.743229946238749, w0=72.10000000000014, w1=17.39837526855246\n",
      "SubSGD iter. 163/499: loss=0.4048013695162389, w0=71.40000000000013, w1=18.101880186943323\n",
      "SubSGD iter. 164/499: loss=3.489556920928923, w0=70.70000000000013, w1=18.3733603689259\n",
      "SubSGD iter. 165/499: loss=5.792965607942335, w0=71.40000000000013, w1=18.023422437445586\n",
      "SubSGD iter. 166/499: loss=4.680853582133203, w0=72.10000000000014, w1=18.463346880329766\n",
      "SubSGD iter. 167/499: loss=4.721907540286821, w0=72.80000000000014, w1=18.222366965663117\n",
      "SubSGD iter. 168/499: loss=0.701095632117493, w0=73.50000000000014, w1=18.122089866422908\n",
      "SubSGD iter. 169/499: loss=0.19322501951454996, w0=74.20000000000014, w1=18.087399007081437\n",
      "SubSGD iter. 170/499: loss=0.6934883438304524, w0=73.50000000000014, w1=18.89551274812337\n",
      "SubSGD iter. 171/499: loss=2.029481625855624, w0=72.80000000000014, w1=18.170492558042564\n",
      "SubSGD iter. 172/499: loss=1.5818024116366018, w0=73.50000000000014, w1=18.367012640821066\n",
      "SubSGD iter. 173/499: loss=0.0659286833265611, w0=72.80000000000014, w1=18.385592099719943\n",
      "SubSGD iter. 174/499: loss=5.894862243459546, w0=72.10000000000014, w1=18.32928248467464\n",
      "SubSGD iter. 175/499: loss=4.3269388478929045, w0=71.40000000000013, w1=18.068570263292774\n",
      "SubSGD iter. 176/499: loss=0.44523907005739005, w0=72.10000000000014, w1=18.178870296753566\n",
      "SubSGD iter. 177/499: loss=0.6830877613953419, w0=72.80000000000014, w1=18.62905004295986\n",
      "SubSGD iter. 178/499: loss=2.335098025714224, w0=73.50000000000014, w1=19.29219436000291\n",
      "SubSGD iter. 179/499: loss=1.540862724995307, w0=74.20000000000014, w1=19.307502026715046\n",
      "SubSGD iter. 180/499: loss=2.5463048617984327, w0=74.90000000000015, w1=20.546818327693046\n",
      "SubSGD iter. 181/499: loss=2.248570620834979, w0=75.60000000000015, w1=19.420885914191874\n",
      "SubSGD iter. 182/499: loss=1.3822756634853377, w0=76.30000000000015, w1=19.458173225809745\n",
      "SubSGD iter. 183/499: loss=6.635053560868265, w0=75.60000000000015, w1=18.401771994430856\n",
      "SubSGD iter. 184/499: loss=0.5005986455704488, w0=76.30000000000015, w1=18.417079661142992\n",
      "SubSGD iter. 185/499: loss=6.443288702827289, w0=75.60000000000015, w1=18.156367439761127\n",
      "SubSGD iter. 186/499: loss=2.2563122006128893, w0=76.30000000000015, w1=18.27018776657544\n",
      "SubSGD iter. 187/499: loss=0.5956056364964084, w0=77.00000000000016, w1=19.450992467275334\n",
      "SubSGD iter. 188/499: loss=5.801663954729285, w0=76.30000000000015, w1=18.545817364088272\n",
      "SubSGD iter. 189/499: loss=0.958182421192749, w0=75.60000000000015, w1=19.202698331841237\n",
      "SubSGD iter. 190/499: loss=2.908923179042201, w0=76.30000000000015, w1=18.018696131447346\n",
      "SubSGD iter. 191/499: loss=0.18161666714669877, w0=75.60000000000015, w1=18.37181188301466\n",
      "SubSGD iter. 192/499: loss=0.9993251339596192, w0=74.90000000000015, w1=19.19047025282029\n",
      "SubSGD iter. 193/499: loss=0.6634023412336845, w0=74.20000000000014, w1=18.177791911467523\n",
      "SubSGD iter. 194/499: loss=3.2323457929493244, w0=74.90000000000015, w1=18.617716354351703\n",
      "SubSGD iter. 195/499: loss=1.753667116099443, w0=75.60000000000015, w1=18.655003665969573\n",
      "SubSGD iter. 196/499: loss=0.11379086661022342, w0=76.30000000000015, w1=18.851523748748075\n",
      "SubSGD iter. 197/499: loss=2.654707826530476, w0=75.60000000000015, w1=19.035684527066394\n",
      "SubSGD iter. 198/499: loss=1.4134517084128646, w0=76.30000000000015, w1=18.33909977582563\n",
      "SubSGD iter. 199/499: loss=2.312063425913056, w0=75.60000000000015, w1=18.951897946827042\n",
      "SubSGD iter. 200/499: loss=6.135796001702047, w0=74.90000000000015, w1=17.589146551435295\n",
      "SubSGD iter. 201/499: loss=1.2039783886493822, w0=74.20000000000014, w1=16.576708213568875\n",
      "SubSGD iter. 202/499: loss=4.456757269980816, w0=73.50000000000014, w1=16.856637206005338\n",
      "SubSGD iter. 203/499: loss=0.7265148754873252, w0=72.80000000000014, w1=16.62751551371858\n",
      "SubSGD iter. 204/499: loss=1.9199984504765908, w0=73.50000000000014, w1=16.642823180430717\n",
      "SubSGD iter. 205/499: loss=5.255147669706595, w0=74.20000000000014, w1=17.882139481408718\n",
      "SubSGD iter. 206/499: loss=0.9734408248431947, w0=73.50000000000014, w1=18.616253804409705\n",
      "SubSGD iter. 207/499: loss=0.36318966157698185, w0=72.80000000000014, w1=18.413816914368706\n",
      "SubSGD iter. 208/499: loss=0.05275115233403227, w0=73.50000000000014, w1=19.059964147755927\n",
      "SubSGD iter. 209/499: loss=0.30023410019620655, w0=72.80000000000014, w1=18.609784401549632\n",
      "SubSGD iter. 210/499: loss=1.7727439387811756, w0=72.10000000000014, w1=17.990651005604967\n",
      "SubSGD iter. 211/499: loss=1.6078077659543766, w0=72.80000000000014, w1=17.863636560376943\n",
      "SubSGD iter. 212/499: loss=1.8328383364623626, w0=72.10000000000014, w1=18.421760264125982\n",
      "SubSGD iter. 213/499: loss=4.841070737856121, w0=72.80000000000014, w1=18.769727310516398\n",
      "SubSGD iter. 214/499: loss=3.402301045151269, w0=72.10000000000014, w1=18.068793313081645\n",
      "SubSGD iter. 215/499: loss=0.330380073041173, w0=71.40000000000013, w1=18.681591484083057\n",
      "SubSGD iter. 216/499: loss=1.9288102185518738, w0=70.70000000000013, w1=18.32656400655323\n",
      "SubSGD iter. 217/499: loss=4.617962486912486, w0=71.40000000000013, w1=17.14256180615934\n",
      "SubSGD iter. 218/499: loss=0.7569748201443431, w0=72.10000000000014, w1=17.032387689278597\n",
      "SubSGD iter. 219/499: loss=2.1824721839969854, w0=71.40000000000013, w1=16.331453691843844\n",
      "SubSGD iter. 220/499: loss=1.9534247133115095, w0=70.70000000000013, w1=16.878615994077716\n",
      "SubSGD iter. 221/499: loss=0.9041352523535622, w0=70.00000000000013, w1=16.543387938774462\n",
      "SubSGD iter. 222/499: loss=2.590746059759134, w0=70.70000000000013, w1=16.686718529368978\n",
      "SubSGD iter. 223/499: loss=0.5303453276698562, w0=71.40000000000013, w1=17.13537756815369\n",
      "SubSGD iter. 224/499: loss=0.9106201821615265, w0=70.70000000000013, w1=17.558616992926204\n",
      "SubSGD iter. 225/499: loss=2.564184834543667, w0=71.40000000000013, w1=17.375151213875785\n",
      "SubSGD iter. 226/499: loss=1.6853768929113109, w0=70.70000000000013, w1=17.720328301600784\n",
      "SubSGD iter. 227/499: loss=3.8528699768613492, w0=71.40000000000013, w1=18.261285353571925\n",
      "SubSGD iter. 228/499: loss=5.698098459168264, w0=70.70000000000013, w1=17.30315026267012\n",
      "SubSGD iter. 229/499: loss=5.648359118621478, w0=71.40000000000013, w1=17.547462986379255\n",
      "SubSGD iter. 230/499: loss=0.9518781848581597, w0=72.10000000000014, w1=17.71326924594675\n",
      "SubSGD iter. 231/499: loss=1.8413468726944515, w0=72.80000000000014, w1=17.360153494379436\n",
      "SubSGD iter. 232/499: loss=0.5471532459031963, w0=72.10000000000014, w1=18.094267817380423\n",
      "SubSGD iter. 233/499: loss=1.3908949283487324, w0=71.40000000000013, w1=18.652391521129463\n",
      "SubSGD iter. 234/499: loss=2.4750016590382344, w0=72.10000000000014, w1=17.52645910762829\n",
      "SubSGD iter. 235/499: loss=5.439173163710805, w0=72.80000000000014, w1=17.144333123077956\n",
      "SubSGD iter. 236/499: loss=0.6861951901707002, w0=72.10000000000014, w1=15.778963670414345\n",
      "SubSGD iter. 237/499: loss=2.7705827218976395, w0=72.80000000000014, w1=15.205953587399723\n",
      "SubSGD iter. 238/499: loss=3.8961815355509373, w0=73.50000000000014, w1=15.319773914214036\n",
      "SubSGD iter. 239/499: loss=4.594476317072605, w0=74.20000000000014, w1=15.56408663792317\n",
      "SubSGD iter. 240/499: loss=0.5568711967283946, w0=74.90000000000015, w1=15.813685100610348\n",
      "SubSGD iter. 241/499: loss=1.0976021923394086, w0=74.20000000000014, w1=15.923859217491088\n",
      "SubSGD iter. 242/499: loss=0.5789971087229446, w0=73.50000000000014, w1=15.044686905260281\n",
      "SubSGD iter. 243/499: loss=1.8580976947387668, w0=72.80000000000014, w1=13.849948068155856\n",
      "SubSGD iter. 244/499: loss=0.08028828192334458, w0=72.10000000000014, w1=12.944772964968791\n",
      "SubSGD iter. 245/499: loss=8.456587491979697, w0=72.80000000000014, w1=14.069902925099099\n",
      "SubSGD iter. 246/499: loss=2.13241307498361, w0=72.10000000000014, w1=13.412720221904113\n",
      "SubSGD iter. 247/499: loss=2.94441052375452, w0=72.80000000000014, w1=14.531030442515595\n",
      "SubSGD iter. 248/499: loss=0.5639580708287752, w0=73.50000000000014, w1=15.060731416577712\n",
      "SubSGD iter. 249/499: loss=1.2373168228156146, w0=72.80000000000014, w1=14.795946307386943\n",
      "SubSGD iter. 250/499: loss=3.0212929202454895, w0=72.10000000000014, w1=15.141123395111942\n",
      "SubSGD iter. 251/499: loss=1.363915053288288, w0=71.40000000000013, w1=15.711083519647927\n",
      "SubSGD iter. 252/499: loss=0.6245774185470196, w0=72.10000000000014, w1=15.763243865177637\n",
      "SubSGD iter. 253/499: loss=4.260673936162604, w0=72.80000000000014, w1=15.238610940465898\n",
      "SubSGD iter. 254/499: loss=0.7655697296007844, w0=72.10000000000014, w1=15.232183059587552\n",
      "SubSGD iter. 255/499: loss=1.4389740096587502, w0=72.80000000000014, w1=15.320710573076678\n",
      "SubSGD iter. 256/499: loss=2.0244160617018707, w0=73.50000000000014, w1=15.787292699043252\n",
      "SubSGD iter. 257/499: loss=1.5189168615079467, w0=74.20000000000014, w1=16.253874825009827\n",
      "SubSGD iter. 258/499: loss=0.4232503314213787, w0=74.90000000000015, w1=15.900759073442513\n",
      "SubSGD iter. 259/499: loss=3.8563080895717228, w0=74.20000000000014, w1=16.144785898151664\n",
      "SubSGD iter. 260/499: loss=2.8118306326166262, w0=74.90000000000015, w1=16.807930215194713\n",
      "SubSGD iter. 261/499: loss=3.517535330665954, w0=75.60000000000015, w1=15.770416021381171\n",
      "SubSGD iter. 262/499: loss=3.942987589911951, w0=74.90000000000015, w1=16.210611276088144\n",
      "SubSGD iter. 263/499: loss=1.789379783020756, w0=75.60000000000015, w1=16.363505033202728\n",
      "SubSGD iter. 264/499: loss=0.8283590367920723, w0=76.30000000000015, w1=16.108073152101156\n",
      "SubSGD iter. 265/499: loss=5.21498891915715, w0=75.60000000000015, w1=15.909312286282631\n",
      "SubSGD iter. 266/499: loss=2.1686491498549714, w0=74.90000000000015, w1=15.902884405404285\n",
      "SubSGD iter. 267/499: loss=7.586620866360963, w0=74.20000000000014, w1=15.916639601379774\n",
      "SubSGD iter. 268/499: loss=5.018204499024208, w0=74.90000000000015, w1=17.04176956151008\n",
      "SubSGD iter. 269/499: loss=1.4568133316232448, w0=74.20000000000014, w1=16.812647869223323\n",
      "SubSGD iter. 270/499: loss=3.0836862042144872, w0=73.50000000000014, w1=15.606631579452875\n",
      "SubSGD iter. 271/499: loss=1.1172594387637673, w0=72.80000000000014, w1=15.600203698574528\n",
      "SubSGD iter. 272/499: loss=4.597555449560204, w0=73.50000000000014, w1=16.781008399274423\n",
      "SubSGD iter. 273/499: loss=0.08003470880148456, w0=72.80000000000014, w1=17.906940812775595\n",
      "SubSGD iter. 274/499: loss=3.4529487369030285, w0=73.50000000000014, w1=17.322628275229704\n",
      "SubSGD iter. 275/499: loss=1.0288899361914616, w0=72.80000000000014, w1=16.70871386185212\n",
      "SubSGD iter. 276/499: loss=3.062642294776367, w0=73.50000000000014, w1=15.497290973925942\n",
      "SubSGD iter. 277/499: loss=4.424644279805399, w0=74.20000000000014, w1=15.937215416810124\n",
      "SubSGD iter. 278/499: loss=0.6680830367393114, w0=73.50000000000014, w1=15.407514442748008\n",
      "SubSGD iter. 279/499: loss=2.4235819088216957, w0=72.80000000000014, w1=15.91253217457233\n",
      "SubSGD iter. 280/499: loss=0.45298405274663267, w0=72.10000000000014, w1=16.343542859320944\n",
      "SubSGD iter. 281/499: loss=4.573386421275547, w0=72.80000000000014, w1=15.306028665507403\n",
      "SubSGD iter. 282/499: loss=2.3374903605171227, w0=73.50000000000014, w1=15.47148145744003\n",
      "SubSGD iter. 283/499: loss=4.494750523551687, w0=72.80000000000014, w1=15.210769236058166\n",
      "SubSGD iter. 284/499: loss=3.8957900221908446, w0=73.50000000000014, w1=15.324589562872479\n",
      "SubSGD iter. 285/499: loss=0.3695873472535567, w0=72.80000000000014, w1=14.79653374736183\n",
      "SubSGD iter. 286/499: loss=2.0184811134945164, w0=73.50000000000014, w1=14.223523664347207\n",
      "SubSGD iter. 287/499: loss=1.8634907533879783, w0=72.80000000000014, w1=14.407684442665527\n",
      "SubSGD iter. 288/499: loss=0.4193453006393568, w0=72.10000000000014, w1=13.52795431283305\n",
      "SubSGD iter. 289/499: loss=2.401589904276751, w0=71.40000000000013, w1=14.032972044657372\n",
      "SubSGD iter. 290/499: loss=5.198710564064399, w0=72.10000000000014, w1=14.31109901345906\n",
      "SubSGD iter. 291/499: loss=1.3664283058731144, w0=71.40000000000013, w1=15.437031426960232\n",
      "SubSGD iter. 292/499: loss=0.5808334806329682, w0=72.10000000000014, w1=15.885690465744942\n",
      "SubSGD iter. 293/499: loss=0.944843659216346, w0=71.40000000000013, w1=16.069851244063262\n",
      "SubSGD iter. 294/499: loss=1.9337093604770743, w0=72.10000000000014, w1=16.72190814150572\n",
      "SubSGD iter. 295/499: loss=0.8664180030569355, w0=71.40000000000013, w1=15.629283627179923\n",
      "SubSGD iter. 296/499: loss=0.12337793338974379, w0=72.10000000000014, w1=14.97240265942696\n",
      "SubSGD iter. 297/499: loss=0.11025461955490101, w0=71.40000000000013, w1=14.683905394869544\n",
      "SubSGD iter. 298/499: loss=3.7061110674410713, w0=72.10000000000014, w1=14.836799151984126\n",
      "SubSGD iter. 299/499: loss=0.6782426778028281, w0=71.40000000000013, w1=15.379815613349225\n",
      "SubSGD iter. 300/499: loss=5.9471396631517734, w0=72.10000000000014, w1=15.727782659739638\n",
      "SubSGD iter. 301/499: loss=0.8173884624072087, w0=72.80000000000014, w1=15.893588919307135\n",
      "SubSGD iter. 302/499: loss=0.6268176740656592, w0=73.50000000000014, w1=15.099219574816354\n",
      "SubSGD iter. 303/499: loss=0.9583302141327863, w0=74.20000000000014, w1=16.464589027479967\n",
      "SubSGD iter. 304/499: loss=1.4677486805500166, w0=73.50000000000014, w1=16.17609176292255\n",
      "SubSGD iter. 305/499: loss=0.6907592677225267, w0=72.80000000000014, w1=15.6480359474119\n",
      "SubSGD iter. 306/499: loss=1.2408144951872373, w0=72.10000000000014, w1=15.016870607417047\n",
      "SubSGD iter. 307/499: loss=0.3770442791221633, w0=71.40000000000013, w1=15.387138697945844\n",
      "SubSGD iter. 308/499: loss=4.168664651125756, w0=72.10000000000014, w1=14.99116245472401\n",
      "SubSGD iter. 309/499: loss=0.11121380353729293, w0=71.40000000000013, w1=15.775395182763335\n",
      "SubSGD iter. 310/499: loss=2.618005793388349, w0=72.10000000000014, w1=15.971915265541837\n",
      "SubSGD iter. 311/499: loss=1.2830575349900073, w0=72.80000000000014, w1=16.767084990659185\n",
      "SubSGD iter. 312/499: loss=4.238907810526513, w0=72.10000000000014, w1=17.05225948520848\n",
      "SubSGD iter. 313/499: loss=1.031155842298105, w0=72.80000000000014, w1=17.698406718595702\n",
      "SubSGD iter. 314/499: loss=1.2709253683240078, w0=73.50000000000014, w1=16.75490023505858\n",
      "SubSGD iter. 315/499: loss=3.832325106063635, w0=74.20000000000014, w1=16.966064629624785\n",
      "SubSGD iter. 316/499: loss=3.450474819254694, w0=74.90000000000015, w1=17.17722902419099\n",
      "SubSGD iter. 317/499: loss=0.46137924845059075, w0=74.20000000000014, w1=18.30316143769216\n",
      "SubSGD iter. 318/499: loss=0.050747715791722214, w0=74.90000000000015, w1=18.926649559978337\n",
      "SubSGD iter. 319/499: loss=4.849013000167837, w0=74.20000000000014, w1=19.211824054527632\n",
      "SubSGD iter. 320/499: loss=1.0909550931150847, w0=73.50000000000014, w1=19.607260846470638\n",
      "SubSGD iter. 321/499: loss=3.4000549293417563, w0=72.80000000000014, w1=19.824517850650388\n",
      "SubSGD iter. 322/499: loss=2.602676236780802, w0=72.10000000000014, w1=19.063160900031317\n",
      "SubSGD iter. 323/499: loss=1.1967261936255866, w0=72.80000000000014, w1=19.151688413520443\n",
      "SubSGD iter. 324/499: loss=0.5535331657678171, w0=73.50000000000014, w1=19.421826863810114\n",
      "SubSGD iter. 325/499: loss=5.189864389985221, w0=74.20000000000014, w1=19.022369091423535\n",
      "SubSGD iter. 326/499: loss=0.8020387697850921, w0=73.50000000000014, w1=19.549326127192383\n",
      "SubSGD iter. 327/499: loss=0.05023815130825682, w0=72.80000000000014, w1=19.56790558609126\n",
      "SubSGD iter. 328/499: loss=0.8810989878638011, w0=73.50000000000014, w1=19.711236176685777\n",
      "SubSGD iter. 329/499: loss=1.8160531343538047, w0=72.80000000000014, w1=20.05832016230577\n",
      "SubSGD iter. 330/499: loss=2.715510998606952, w0=72.10000000000014, w1=19.723092107002515\n",
      "SubSGD iter. 331/499: loss=3.1913202124957962, w0=72.80000000000014, w1=19.467660225900943\n",
      "SubSGD iter. 332/499: loss=4.88893098338346, w0=72.10000000000014, w1=19.206948004519077\n",
      "SubSGD iter. 333/499: loss=2.415645486480699, w0=72.80000000000014, w1=19.819940501702636\n",
      "SubSGD iter. 334/499: loss=0.31813208069004517, w0=72.10000000000014, w1=20.176666020058473\n",
      "SubSGD iter. 335/499: loss=0.6580873028025565, w0=72.80000000000014, w1=20.158086561159596\n",
      "SubSGD iter. 336/499: loss=1.8609253186404615, w0=73.50000000000014, w1=20.699043613130737\n",
      "SubSGD iter. 337/499: loss=1.3501408033609295, w0=74.20000000000014, w1=20.864496405063363\n",
      "SubSGD iter. 338/499: loss=3.802055246508221, w0=74.90000000000015, w1=20.29148632204874\n",
      "SubSGD iter. 339/499: loss=4.09322187516149, w0=74.20000000000014, w1=19.55721057855694\n",
      "SubSGD iter. 340/499: loss=1.4853979039114407, w0=73.50000000000014, w1=19.550782697678596\n",
      "SubSGD iter. 341/499: loss=3.043277566268383, w0=74.20000000000014, w1=18.77995963161041\n",
      "SubSGD iter. 342/499: loss=2.5480019159906107, w0=73.50000000000014, w1=18.160826235665745\n",
      "SubSGD iter. 343/499: loss=2.6744972269773157, w0=72.80000000000014, w1=17.556294129811587\n",
      "SubSGD iter. 344/499: loss=2.628091878194219, w0=73.50000000000014, w1=17.58266678043641\n",
      "SubSGD iter. 345/499: loss=1.1263320951090137, w0=72.80000000000014, w1=17.576238899558064\n",
      "SubSGD iter. 346/499: loss=2.690239827183774, w0=73.50000000000014, w1=17.729132656672647\n",
      "SubSGD iter. 347/499: loss=3.719855475387501, w0=74.20000000000014, w1=16.875286386247378\n",
      "SubSGD iter. 348/499: loss=3.130138937269649, w0=73.50000000000014, w1=17.057150229822547\n",
      "SubSGD iter. 349/499: loss=1.1023587684610874, w0=72.80000000000014, w1=15.517087891435361\n",
      "SubSGD iter. 350/499: loss=1.5663921269684593, w0=72.10000000000014, w1=16.357115462895173\n",
      "SubSGD iter. 351/499: loss=3.9645404827851642, w0=72.80000000000014, w1=15.003158568861945\n",
      "SubSGD iter. 352/499: loss=1.9801619965517645, w0=73.50000000000014, w1=14.747726687760375\n",
      "SubSGD iter. 353/499: loss=2.378024000895959, w0=72.80000000000014, w1=15.587754259220185\n",
      "SubSGD iter. 354/499: loss=2.928082262298812, w0=72.10000000000014, w1=15.738210935671313\n",
      "SubSGD iter. 355/499: loss=0.928390991991499, w0=71.40000000000013, w1=15.133678829817153\n",
      "SubSGD iter. 356/499: loss=2.276881319417452, w0=70.70000000000013, w1=15.284135506268282\n",
      "SubSGD iter. 357/499: loss=4.781133922170852, w0=71.40000000000013, w1=14.759502581556543\n",
      "SubSGD iter. 358/499: loss=0.10796124876173607, w0=70.70000000000013, w1=15.190513266305157\n",
      "SubSGD iter. 359/499: loss=0.9533568030109336, w0=71.40000000000013, w1=15.080339149424416\n",
      "SubSGD iter. 360/499: loss=0.7007823200972538, w0=70.70000000000013, w1=15.264499927742737\n",
      "SubSGD iter. 361/499: loss=3.5283418837181344, w0=71.40000000000013, w1=15.982663251773925\n",
      "SubSGD iter. 362/499: loss=0.476512278663634, w0=70.70000000000013, w1=16.183412788823176\n",
      "SubSGD iter. 363/499: loss=1.0080083816657748, w0=71.40000000000013, w1=17.062585101053983\n",
      "SubSGD iter. 364/499: loss=3.800543287969159, w0=72.10000000000014, w1=16.478272563508092\n",
      "SubSGD iter. 365/499: loss=0.6762735708554075, w0=71.40000000000013, w1=15.385648049182297\n",
      "SubSGD iter. 366/499: loss=3.8203010830532236, w0=70.70000000000013, w1=15.67082254373159\n",
      "SubSGD iter. 367/499: loss=2.6247777017597187, w0=70.00000000000013, w1=15.696120309120433\n",
      "SubSGD iter. 368/499: loss=0.31892984247820877, w0=69.30000000000013, w1=16.308918480121847\n",
      "SubSGD iter. 369/499: loss=0.9851639152951925, w0=68.60000000000012, w1=16.552945304831\n",
      "SubSGD iter. 370/499: loss=2.9140960144512924, w0=69.30000000000013, w1=16.17735946654443\n",
      "SubSGD iter. 371/499: loss=1.8046342986857624, w0=68.60000000000012, w1=15.753818213490415\n",
      "SubSGD iter. 372/499: loss=2.6036085990648417, w0=69.30000000000013, w1=16.263004057436667\n",
      "SubSGD iter. 373/499: loss=4.426968681603526, w0=70.00000000000013, w1=15.051581169510488\n",
      "SubSGD iter. 374/499: loss=0.576043734284923, w0=70.70000000000013, w1=15.931311299342966\n",
      "SubSGD iter. 375/499: loss=59.75277737764568, w0=71.40000000000013, w1=12.558167621753288\n",
      "SubSGD iter. 376/499: loss=2.302449208521878, w0=72.10000000000014, w1=13.283187811834091\n",
      "SubSGD iter. 377/499: loss=2.9203748562098077, w0=71.40000000000013, w1=13.83515924377177\n",
      "SubSGD iter. 378/499: loss=5.856936555519315, w0=70.70000000000013, w1=13.84891443974726\n",
      "SubSGD iter. 379/499: loss=0.43247591165916077, w0=70.00000000000013, w1=14.049663976796511\n",
      "SubSGD iter. 380/499: loss=0.6398891342943216, w0=70.70000000000013, w1=14.056091857674858\n",
      "SubSGD iter. 381/499: loss=0.28985962168533064, w0=71.40000000000013, w1=14.062519738553204\n",
      "SubSGD iter. 382/499: loss=5.0209832859807655, w0=70.70000000000013, w1=14.0062101235079\n",
      "SubSGD iter. 383/499: loss=3.653811198974772, w0=71.40000000000013, w1=15.546272461895086\n",
      "SubSGD iter. 384/499: loss=1.7779975962735932, w0=70.70000000000013, w1=15.666777013374128\n",
      "SubSGD iter. 385/499: loss=0.17180800446291045, w0=70.00000000000013, w1=15.86752655042338\n",
      "SubSGD iter. 386/499: loss=3.8294801929202436, w0=69.30000000000013, w1=15.262123398979394\n",
      "SubSGD iter. 387/499: loss=8.577378916784738, w0=70.00000000000013, w1=16.501439699957395\n",
      "SubSGD iter. 388/499: loss=3.9443342118066376, w0=70.70000000000013, w1=15.947332625960813\n",
      "SubSGD iter. 389/499: loss=2.3268096792874715, w0=71.40000000000013, w1=15.25074787472005\n",
      "SubSGD iter. 390/499: loss=0.2491083738810218, w0=70.70000000000013, w1=14.371017744887572\n",
      "SubSGD iter. 391/499: loss=1.1214928299728442, w0=71.40000000000013, w1=15.117003398474969\n",
      "SubSGD iter. 392/499: loss=0.8698114968864701, w0=70.70000000000013, w1=13.922264561370543\n",
      "SubSGD iter. 393/499: loss=0.22394220889011862, w0=70.00000000000013, w1=14.865771044907664\n",
      "SubSGD iter. 394/499: loss=1.8606744162211584, w0=70.70000000000013, w1=14.765493945667455\n",
      "SubSGD iter. 395/499: loss=0.2564723233424644, w0=71.40000000000013, w1=14.395225855138658\n",
      "SubSGD iter. 396/499: loss=0.25519788950989053, w0=70.70000000000013, w1=15.33873233867578\n",
      "SubSGD iter. 397/499: loss=7.755000871458094, w0=71.40000000000013, w1=15.683200585546247\n",
      "SubSGD iter. 398/499: loss=4.034922865803516, w0=72.10000000000014, w1=15.948684287770478\n",
      "SubSGD iter. 399/499: loss=3.9163774677751704, w0=72.80000000000014, w1=15.421495649023251\n",
      "SubSGD iter. 400/499: loss=2.8064217154064863, w0=72.10000000000014, w1=15.979619352772291\n",
      "SubSGD iter. 401/499: loss=3.5994594393768793, w0=72.80000000000014, w1=14.625662458739063\n",
      "SubSGD iter. 402/499: loss=2.2018105370213803, w0=73.50000000000014, w1=15.242049407576312\n",
      "SubSGD iter. 403/499: loss=3.467430404501087, w0=74.20000000000014, w1=15.001069492909664\n",
      "SubSGD iter. 404/499: loss=3.5228015132819834, w0=74.90000000000015, w1=15.197414086426893\n",
      "SubSGD iter. 405/499: loss=5.9897029089735625, w0=74.20000000000014, w1=14.592010934982907\n",
      "SubSGD iter. 406/499: loss=2.2253583981196456, w0=74.90000000000015, w1=13.554496741169366\n",
      "SubSGD iter. 407/499: loss=4.1965945255382415, w0=74.20000000000014, w1=13.704953417620494\n",
      "SubSGD iter. 408/499: loss=0.8717050168072191, w0=74.90000000000015, w1=13.131943334605872\n",
      "SubSGD iter. 409/499: loss=5.629365049792646, w0=75.60000000000015, w1=14.312748035305768\n",
      "SubSGD iter. 410/499: loss=1.1697329994718118, w0=74.90000000000015, w1=14.331327494204645\n",
      "SubSGD iter. 411/499: loss=3.511791545801916, w0=74.20000000000014, w1=14.836345226028968\n",
      "SubSGD iter. 412/499: loss=0.31696980737025626, w0=73.50000000000014, w1=14.492632604845577\n",
      "SubSGD iter. 413/499: loss=4.168899570612361, w0=72.80000000000014, w1=13.53449751394377\n",
      "SubSGD iter. 414/499: loss=1.5275609490130932, w0=72.10000000000014, w1=13.73524705099302\n",
      "SubSGD iter. 415/499: loss=2.3268138268130336, w0=71.40000000000013, w1=14.240264782817343\n",
      "SubSGD iter. 416/499: loss=4.667287562136309, w0=72.10000000000014, w1=15.25294312417011\n",
      "SubSGD iter. 417/499: loss=4.242361275242324, w0=72.80000000000014, w1=15.366763450984424\n",
      "SubSGD iter. 418/499: loss=0.8674234430229077, w0=72.10000000000014, w1=16.492695864485594\n",
      "SubSGD iter. 419/499: loss=2.6979124856926333, w0=71.40000000000013, w1=16.31434374310578\n",
      "SubSGD iter. 420/499: loss=1.1190210456714809, w0=70.70000000000013, w1=15.979115687802526\n",
      "SubSGD iter. 421/499: loss=0.6375193780560231, w0=71.40000000000013, w1=15.322234720049563\n",
      "SubSGD iter. 422/499: loss=5.529652511919657, w0=72.10000000000014, w1=15.762159162933745\n",
      "SubSGD iter. 423/499: loss=1.4601980505931493, w0=72.80000000000014, w1=16.21233890914004\n",
      "SubSGD iter. 424/499: loss=1.23736318649593, w0=72.10000000000014, w1=16.569064427495878\n",
      "SubSGD iter. 425/499: loss=0.34843728776269245, w0=71.40000000000013, w1=16.526737870892386\n",
      "SubSGD iter. 426/499: loss=1.6751600891818228, w0=70.70000000000013, w1=15.16398647550064\n",
      "SubSGD iter. 427/499: loss=1.6836643102053088, w0=70.00000000000013, w1=15.60418173020761\n",
      "SubSGD iter. 428/499: loss=3.7022544626757536, w0=70.70000000000013, w1=15.769634522140237\n",
      "SubSGD iter. 429/499: loss=59.36323523562106, w0=71.40000000000013, w1=12.39649084455056\n",
      "SubSGD iter. 430/499: loss=1.6843374448671113, w0=70.70000000000013, w1=11.438355753648752\n",
      "SubSGD iter. 431/499: loss=2.4487353273257852, w0=71.40000000000013, w1=12.057489149593419\n",
      "SubSGD iter. 432/499: loss=1.5525105045043368, w0=70.70000000000013, w1=12.714370117346382\n",
      "SubSGD iter. 433/499: loss=6.699126356535075, w0=71.40000000000013, w1=13.154294560230564\n",
      "SubSGD iter. 434/499: loss=0.9148931157236149, w0=72.10000000000014, w1=13.135715101331687\n",
      "SubSGD iter. 435/499: loss=1.0598561486593994, w0=72.80000000000014, w1=13.869990844823487\n",
      "SubSGD iter. 436/499: loss=3.7604534111015724, w0=72.10000000000014, w1=14.49277725164378\n",
      "SubSGD iter. 437/499: loss=1.8309986835145757, w0=71.40000000000013, w1=15.33280482310359\n",
      "SubSGD iter. 438/499: loss=5.190421518541477, w0=72.10000000000014, w1=14.950678838553255\n",
      "SubSGD iter. 439/499: loss=2.332807733446849, w0=72.80000000000014, w1=15.378195923770674\n",
      "SubSGD iter. 440/499: loss=1.1229333967890724, w0=72.10000000000014, w1=14.773663817916514\n",
      "SubSGD iter. 441/499: loss=3.0084568083492726, w0=71.40000000000013, w1=15.396450224736807\n",
      "SubSGD iter. 442/499: loss=3.5894616546559064, w0=72.10000000000014, w1=15.433737536354677\n",
      "SubSGD iter. 443/499: loss=2.480630324913008, w0=71.40000000000013, w1=16.26977639362749\n",
      "SubSGD iter. 444/499: loss=5.231904838449438, w0=72.10000000000014, w1=16.709700836511672\n",
      "SubSGD iter. 445/499: loss=1.3455447418537005, w0=72.80000000000014, w1=16.798228350000798\n",
      "SubSGD iter. 446/499: loss=0.29385402916157943, w0=72.10000000000014, w1=16.26852737593868\n",
      "SubSGD iter. 447/499: loss=3.1191305134548415, w0=72.80000000000014, w1=15.68421483839279\n",
      "SubSGD iter. 448/499: loss=2.922818314081745, w0=73.50000000000014, w1=16.696893179745558\n",
      "SubSGD iter. 449/499: loss=0.6374484596444425, w0=74.20000000000014, w1=15.897062445682849\n",
      "SubSGD iter. 450/499: loss=4.952092229345158, w0=74.90000000000015, w1=15.277921290268466\n",
      "SubSGD iter. 451/499: loss=2.9192430735075234, w0=75.60000000000015, w1=14.927983358788149\n",
      "SubSGD iter. 452/499: loss=2.320648104647937, w0=74.90000000000015, w1=13.844107962096846\n",
      "SubSGD iter. 453/499: loss=3.203844299366885, w0=75.60000000000015, w1=14.856786303449613\n",
      "SubSGD iter. 454/499: loss=1.5038349523715837, w0=76.30000000000015, w1=14.894073615067484\n",
      "SubSGD iter. 455/499: loss=2.265599693241594, w0=75.60000000000015, w1=15.678306343106808\n",
      "SubSGD iter. 456/499: loss=1.7478569867771867, w0=74.90000000000015, w1=14.916949392487739\n",
      "SubSGD iter. 457/499: loss=3.3269149715024042, w0=75.60000000000015, w1=14.534823407937404\n",
      "SubSGD iter. 458/499: loss=0.4205596830569718, w0=74.90000000000015, w1=14.558789247740496\n",
      "SubSGD iter. 459/499: loss=1.1852225708823738, w0=74.20000000000014, w1=13.500873940912937\n",
      "SubSGD iter. 460/499: loss=0.2307909859434929, w0=73.50000000000014, w1=12.29485765114249\n",
      "SubSGD iter. 461/499: loss=3.9879489906058403, w0=72.80000000000014, w1=12.640034738867488\n",
      "SubSGD iter. 462/499: loss=1.2412254884762213, w0=72.10000000000014, w1=13.82403693926138\n",
      "SubSGD iter. 463/499: loss=3.0932642666053844, w0=71.40000000000013, w1=14.382160643010419\n",
      "SubSGD iter. 464/499: loss=2.3115337563995624, w0=70.70000000000013, w1=13.958619389956404\n",
      "SubSGD iter. 465/499: loss=0.5400520256451387, w0=71.40000000000013, w1=14.563151495810564\n",
      "SubSGD iter. 466/499: loss=2.7103996063359617, w0=72.10000000000014, w1=15.195425924292254\n",
      "SubSGD iter. 467/499: loss=4.403160301035033, w0=71.40000000000013, w1=15.466906106274832\n",
      "SubSGD iter. 468/499: loss=4.5561346531186615, w0=72.10000000000014, w1=15.225926191608185\n",
      "SubSGD iter. 469/499: loss=3.6442132843042145, w0=72.80000000000014, w1=14.698737552860958\n",
      "SubSGD iter. 470/499: loss=4.177742389731691, w0=72.10000000000014, w1=14.150343049103148\n",
      "SubSGD iter. 471/499: loss=2.434116557853649, w0=71.40000000000013, w1=14.332206892678316\n",
      "SubSGD iter. 472/499: loss=6.207520600512268, w0=72.10000000000014, w1=14.68017393906873\n",
      "SubSGD iter. 473/499: loss=0.41300575351289126, w0=71.40000000000013, w1=14.673746058190384\n",
      "SubSGD iter. 474/499: loss=3.112213876710726, w0=72.10000000000014, w1=14.83919885012301\n",
      "SubSGD iter. 475/499: loss=2.2680169354029687, w0=72.80000000000014, w1=15.695420902627548\n",
      "SubSGD iter. 476/499: loss=0.4153000595991614, w0=72.10000000000014, w1=14.602796388301753\n",
      "SubSGD iter. 477/499: loss=2.4571499279983584, w0=71.40000000000013, w1=14.424444266921938\n",
      "SubSGD iter. 478/499: loss=2.9972995483543485, w0=70.70000000000013, w1=14.44974203231078\n",
      "SubSGD iter. 479/499: loss=8.596519967015595, w0=71.40000000000013, w1=15.68905833328878\n",
      "SubSGD iter. 480/499: loss=0.7908428635733671, w0=70.70000000000013, w1=16.259018457824766\n",
      "SubSGD iter. 481/499: loss=0.758002536947366, w0=70.00000000000013, w1=16.883834557635712\n",
      "SubSGD iter. 482/499: loss=1.6483239413917374, w0=70.70000000000013, w1=16.26278298406512\n",
      "SubSGD iter. 483/499: loss=3.554315863996756, w0=71.40000000000013, w1=17.275461325417886\n",
      "SubSGD iter. 484/499: loss=0.04179325689749902, w0=72.10000000000014, w1=17.88937573879547\n",
      "SubSGD iter. 485/499: loss=1.1148746294688223, w0=72.80000000000014, w1=18.505762687632718\n",
      "SubSGD iter. 486/499: loss=2.020869478442325, w0=73.50000000000014, w1=17.70593195357001\n",
      "SubSGD iter. 487/499: loss=1.1969725453584275, w0=72.80000000000014, w1=17.092017540192426\n",
      "SubSGD iter. 488/499: loss=2.844302264041282, w0=73.50000000000014, w1=17.129304851810296\n",
      "SubSGD iter. 489/499: loss=0.00721659315027523, w0=74.20000000000014, w1=16.508253278239703\n",
      "SubSGD iter. 490/499: loss=0.5782796584889027, w0=73.50000000000014, w1=15.389943057628221\n",
      "SubSGD iter. 491/499: loss=3.2453458112501075, w0=72.80000000000014, w1=15.633969882337372\n",
      "SubSGD iter. 492/499: loss=1.526791689658161, w0=73.50000000000014, w1=16.26624431081906\n",
      "SubSGD iter. 493/499: loss=3.028910509774917, w0=72.80000000000014, w1=16.813406613052933\n",
      "SubSGD iter. 494/499: loss=2.223374689871722, w0=73.50000000000014, w1=15.836609134111015\n",
      "SubSGD iter. 495/499: loss=0.6599084916589604, w0=74.20000000000014, w1=16.631778859228362\n",
      "SubSGD iter. 496/499: loss=3.1774063416305225, w0=73.50000000000014, w1=15.269027463836615\n",
      "SubSGD iter. 497/499: loss=2.1260193763103814, w0=74.20000000000014, w1=15.987190787867803\n",
      "SubSGD iter. 498/499: loss=1.0146491625394738, w0=74.90000000000015, w1=15.30884379189326\n",
      "SubSGD iter. 499/499: loss=1.4782248676177474, w0=74.20000000000014, w1=14.562858138305863\n",
      "SubSGD: execution time=0.039 seconds\n"
     ]
    }
   ],
   "source": [
    "# Define the parameters of the algorithm.\n",
    "max_iters = 500\n",
    "gamma = 0.7\n",
    "batch_size = 1\n",
    "\n",
    "# Initialization\n",
    "w_initial = np.array([0, 0])\n",
    "\n",
    "# Start SubSGD.\n",
    "start_time = datetime.datetime.now()\n",
    "subsgd_losses, subsgd_ws = stochastic_subgradient_descent(\n",
    "    y, tx, w_initial, batch_size, max_iters, gamma\n",
    ")\n",
    "end_time = datetime.datetime.now()\n",
    "\n",
    "# Print result\n",
    "exection_time = (end_time - start_time).total_seconds()\n",
    "print(\"SubSGD: execution time={t:.3f} seconds\".format(t=exection_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96d944bd4d6b4c51bf84666f6aec1b9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=1, description='n_iter', max=501, min=1), Output()), _dom_classes=('widg"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.plot_figure(n_iter)>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ipywidgets import IntSlider, interact\n",
    "\n",
    "\n",
    "def plot_figure(n_iter):\n",
    "    fig = gradient_descent_visualization(\n",
    "        subsgd_losses,\n",
    "        subsgd_ws,\n",
    "        grid_losses,\n",
    "        grid_w0,\n",
    "        grid_w1,\n",
    "        mean_x,\n",
    "        std_x,\n",
    "        height,\n",
    "        weight,\n",
    "        n_iter,\n",
    "    )\n",
    "    fig.set_size_inches(10.0, 6.0)\n",
    "\n",
    "\n",
    "interact(plot_figure, n_iter=IntSlider(min=1, max=len(subsgd_ws)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
